{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from ydata_profiling import ProfileReport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_0407.xlsx')\n",
    "profile = ProfileReport(df, title=\"Profiling Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8731b398064b2aa6774e19ea462bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8976f9f8943e4ba895ed1c1ce19bf024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b6c5b6bd43416d9b59fee2634f0b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63fc46fdb824632bad9a7a93d5fec83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile.to_file(r'your_report.html')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data (df): \n",
    "    df.replace('\"\"', np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    df[\"LivingSpace\"] = pd.to_numeric(df[\"LivingSpace\"], errors=\"coerce\")\n",
    "    df[\"Rooms\"] = pd.to_numeric(df[\"Rooms\"], errors=\"coerce\")\n",
    "    df.dropna(subset=['ConstructionYear'], inplace=True)\n",
    "    df.dropna(subset=['Object_price'], inplace=True)\n",
    "    df.dropna(subset=['Rooms'], inplace=True)\n",
    "    df.dropna(subset=['LivingSpace'], inplace=True)\n",
    "    df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    df['ZipCode']= df['ZipCode'].astype(str)\n",
    "    df['LivingSpace']= df['LivingSpace'].astype(float)\n",
    "    df = df.reindex()\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # keep only the most promising features\n",
    "    sns.heatmap(df.corr(), cmap=\"RdBu\")\n",
    "    important_num_cols = list(df.corr()[\"Object_price\"][(df.corr()[\"Object_price\"]>0.20) | (df.corr()[\"Object_price\"]<-0.20)].index)\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    important_cols = important_num_cols + cat_cols\n",
    "    df = df[important_cols]\n",
    "\n",
    "    # one-hot encoding\n",
    "    y = df['Object_price']\n",
    "    X = df.drop('Object_price', axis=1)\n",
    "    X = pd.get_dummies(X, columns=cat_cols)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_0407.xlsx')\n",
    "X, y = preprocess_data(df)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df.corr(), cmap=\"RdBu\")\n",
    "plt.title(\"Correlations between variables\", size=15)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X, y, train_size=0.8, random_state=42):\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
    "                                                  train_size=train_size, \n",
    "                                                  random_state = random_state)\n",
    "    train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, \n",
    "                                                  train_size=train_size, \n",
    "                                                  random_state = random_state)\n",
    "    return train_X, test_X, train_y, test_y, val_X, val_y\n",
    "\n",
    "train_X, test_X, train_y, test_y, val_X, val_y = data_split(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Different Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_avf_rental_prices():\n",
    "    url = \"https://www.wohnungsboerse.net/mietspiegel-Wuerzburg/2772\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    script_tag = soup.find('script', text=lambda text: 'pdfData' in text)\n",
    "    rental_price = 0\n",
    "    if script_tag:\n",
    "        script_content = script_tag.string\n",
    "        start_index = script_content.find('avg_rent_price: ') + len('avg_rent_price: \\'')\n",
    "        end_index = script_content.find('\\',', start_index)\n",
    "        rental_price = script_content[start_index:end_index]\n",
    "        print('The average rental price in Würzburg is:', rental_price)\n",
    "        rental_price = rental_price.replace('€/m2', '').replace('.', '').replace(',', '.')\n",
    "        rental_price = rental_price.strip()\n",
    "        rental_price = float(rental_price)\n",
    "        print(f\"Extrcated rental price as float: {rental_price}\")\n",
    "    else:\n",
    "        print('The script tag containing the rental price was not found.')\n",
    "    return rental_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_avg_rent_price(val_X, val_y, runname=\"baseline\"):\n",
    "    avg_price_per_sqm_rent = scrape_recent_rental_prices()\n",
    "    mlflow.end_run()\n",
    "\n",
    "    baseline_preds = val_X['LivingSpace'] * avg_price_per_sqm_rent\n",
    "    baseline_mae = mean_absolute_error(val_y, baseline_preds)\n",
    "    baseline_r2 = r2_score(val_y, baseline_preds)\n",
    "    baseline_mse = mean_squared_error(val_y, baseline_preds)\n",
    "\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        mlflow.log_metric(\"mse\", baseline_mse)\n",
    "        mlflow.log_metric(\"mae\", baseline_mae)\n",
    "        mlflow.log_metric(\"r2\", baseline_r2)\n",
    "\n",
    "    print(f\"Baseline Mae: {baseline_mae}\")\n",
    "    print(f\"Baseline MSE: {baseline_mse}\")    \n",
    "    print(f\"Baseline R2 Score: {baseline_r2}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear-Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_xgb(train_X, train_y, val_X, val_y, test_X, test_y, early_stopping_rounds=30, max_depth=6, n_estimators=1000):\n",
    "    mlflow.xgboost.autolog()\n",
    "    with mlflow.start_run():\n",
    "        model = xgb.XGBRegressor(eval_metric=['rmse', 'mae'], early_stopping_rounds=early_stopping_rounds, random_state=42, max_depth=max_depth, n_estimators=n_estimators)\n",
    "        mlflow.log_param(\"early_stopping_rounds\", early_stopping_rounds)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        model.fit(X=train_X, \n",
    "                  y=train_y,\n",
    "                  eval_set=[(val_X, val_y)],\n",
    "                  verbose=True\n",
    "        )\n",
    "        preds= model.predict(val_X)\n",
    "        mae = mean_absolute_error(val_y, preds)\n",
    "        mse = mean_squared_error(val_y, preds)\n",
    "        r2 = r2_score(val_y, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)        \n",
    "        return model, mae, mse, r2\n",
    "\n",
    "train_and_eval_xgb(train_X, train_y, val_X, val_y, test_X, test_y, early_stopping_rounds=30, max_depth=6, n_estimators=1000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_rf(train_X, train_y, val_X, val_y, n_estimators=50, random_state=0):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run():\n",
    "        model = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state)\n",
    "        model.fit(train_X, train_y)\n",
    "        pred_train = model.predict(train_X)\n",
    "        mae_train = mean_absolute_error(train_y, pred_train)\n",
    "        mse_train = mean_squared_error(train_y, pred_train)\n",
    "        r2_train = r2_score(train_y, pred_train)\n",
    "        preds= model.predict(val_X)\n",
    "        mae = mean_absolute_error(val_y, preds)\n",
    "        mse = mean_squared_error(val_y, preds)\n",
    "        r2 = r2_score(val_y, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train\n",
    "    \n",
    "train_and_eval_rf(train_X, train_y, val_X, val_y, n_estimators=50, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 13:19:32 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/11 13:19:37 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/11 13:19:56 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/11 13:19:58 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(ElasticNet(max_iter=30),\n",
       " 240.95171039123125,\n",
       " 118514.00451704123,\n",
       " 0.4971844010433488,\n",
       " 195.29754000458772,\n",
       " 54045.200002599486,\n",
       " 0.8402515028199589)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_and_eval_elasticnet(train_X, train_y, val_X, val_y):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run():\n",
    "        model = ElasticNet(max_iter=30)\n",
    "        model.fit(train_X, train_y)\n",
    "        pred_train = model.predict(train_X)\n",
    "        mae_train = mean_absolute_error(train_y, pred_train)\n",
    "        mse_train = mean_squared_error(train_y, pred_train)\n",
    "        r2_train = r2_score(train_y, pred_train)\n",
    "        preds= model.predict(val_X)\n",
    "        mae = mean_absolute_error(val_y, preds)\n",
    "        mse = mean_squared_error(val_y, preds)\n",
    "        r2 = r2_score(val_y, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train\n",
    "\n",
    "train_and_eval_elasticnet(train_X, train_y, val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
    "                                                  train_size=0.8, \n",
    "                                                  random_state = 42)\n",
    "rf_model = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "rf_model.fit(train_X, train_y)\n",
    "preds_test_rf = rf_model.predict(test_X)\n",
    "score = mean_absolute_error(test_y, preds_test_rf)\n",
    "print(\"MAE: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
    "                                                  train_size=0.8, \n",
    "                                                  random_state = 42)\n",
    "elastic_net = ElasticNet(max_iter=30)\n",
    "elastic_net.fit(train_X, train_y)\n",
    "test_preds = elastic_net.predict(test_X)\n",
    "test_score = mean_absolute_error(test_y, test_preds)\n",
    "print(\"MAE auf Testdaten:\", test_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
