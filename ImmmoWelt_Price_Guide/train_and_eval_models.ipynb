{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "from ctgan import CTGAN\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression, ElasticNet\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "# profile = ProfileReport(df, title=\"Flats -  Würzburg - Rent - Overview\", explorative=True)\n",
    "# profile.to_file(\"eda-wue-rent-all.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(r'data\\houses_to_buy_wue_preprocessed_1207.xlsx')\n",
    "# profile = ProfileReport(df, title=\"Houses -  Würzburg - Buy - Overview\", explorative=True)\n",
    "# profile.to_file(\"eda-wue-houses.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineHighCorrCols(df):\n",
    "    df.columns = [re.sub(r\"\\\\u([0-9a-fA-F]{4})\", lambda m: chr(int(m.group(1), 16)), col) for col in df.columns]\n",
    "    df.columns = [col.replace(\"ö\", \"oe\").replace(\"ä\", \"ae\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\") for col in df.columns]\n",
    "    important_num_cols = list(df.corr()[\"Object_price\"][(df.corr()[\"Object_price\"]>0.20) | (df.corr()[\"Object_price\"]<-0.20)].index)\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    important_cols = important_num_cols + cat_cols +   [\"ConstructionYear\"] + [\"ZipCode\"]\n",
    "    #   df = df[important_cols]\n",
    "    print(important_cols)\n",
    "    return important_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, feature_set):\n",
    "    print(f\"Used feature set for preprocessing:{feature_set}\")\n",
    "    df.columns = [\n",
    "        re.sub(r\"\\\\u([0-9a-fA-F]{4})\", lambda m: chr(int(m.group(1), 16)), col)\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    df.columns = [\n",
    "        col.replace(\"ö\", \"oe\").replace(\"ä\", \"ae\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\")\n",
    "        for col in df.columns\n",
    "    ]\n",
    "\n",
    "    df = df.replace('\"\"', np.nan)\n",
    "    df = df.dropna()\n",
    "    df[\"LivingSpace\"] = df[\"LivingSpace\"].astype(float)\n",
    "    df[\"Rooms\"] = df[\"Rooms\"].astype(float)\n",
    "    # df = df.dropna(subset=[\"ConstructionYear\"])\n",
    "    # df = df.dropna(subset=[\"Object_price\"])\n",
    "    # df = df.dropna(subset=[\"Rooms\"])\n",
    "    # df = df.dropna(subset=[\"LivingSpace\"])\n",
    "    df[\"ZipCode\"] = df[\"ZipCode\"].astype(str)\n",
    "    df[\"LivingSpace\"] = df[\"LivingSpace\"].astype(float)\n",
    "    df = df[feature_set]\n",
    "    df = df.reindex()\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # one-hot encoding\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == \"object\"]\n",
    "    y = df[\"Object_price\"]\n",
    "    X = df.drop(\"Object_price\", axis=1)\n",
    "    X = pd.get_dummies(X, columns=cat_cols)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X, y, train_size=0.8, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=train_size, random_state=random_state\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, train_size=train_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # X_train.to_excel(\"data/X_train.xlsx\")\n",
    "    # X_val.to_excel(\"data/X_val.xlsx\")\n",
    "    # X_test.to_excel(\"data/X_test.xlsx\")\n",
    "    # y_train.to_excel(\"data/y_train.xlsx\")\n",
    "    # y_val.to_excel(\"data/y_val.xlsx\")\n",
    "    # y_test.to_excel(\"data/y_test.xlsx\")\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "\n",
    "X = df.drop(\"Object_price\", axis=1)\n",
    "y = df[\"Object_price\"]\n",
    "\n",
    "data_split(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Evaluation and Logging Of Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_avg_rental_prices():\n",
    "    url = \"https://www.wohnungsboerse.net/mietspiegel-Wuerzburg/2772\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    script_tag = soup.find(\"script\", string=lambda text: \"pdfData\" in text)\n",
    "    rental_price = 0\n",
    "    if script_tag:\n",
    "        script_content = script_tag.string\n",
    "        start_index = script_content.find(\"avg_rent_price: \") + len(\"avg_rent_price: '\")\n",
    "        end_index = script_content.find(\"',\", start_index)\n",
    "        rental_price = script_content[start_index:end_index]\n",
    "        rental_price = (\n",
    "            rental_price.replace(\"€/m2\", \"\").replace(\".\", \"\").replace(\",\", \".\")\n",
    "        )\n",
    "        rental_price = rental_price.strip()\n",
    "        rental_price = float(rental_price)\n",
    "        print(f\"Extrcated rental price per square meter via scraper: {rental_price}\")\n",
    "    else:\n",
    "        print(\"The script tag containing the rental price was not found.\")\n",
    "    return rental_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_avg_buy_prices():\n",
    "    url = \"https://www.wohnungsboerse.net/immobilienpreise-Wuerzburg/2772\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    p_element = soup.find(\"p\", class_=\"mb-8\")\n",
    "    buy_price = 0\n",
    "    if p_element:\n",
    "        pattern = r\"\\d{1,3}(?:\\.\\d{3})*(?:,\\d{2})?€/m²\"\n",
    "        match = re.search(pattern, p_element.text)\n",
    "        if match:\n",
    "            buy_price = match.group()\n",
    "            buy_price = buy_price.replace(\"€/m²\", \"\").replace(\".\", \"\").replace(\",\", \".\")\n",
    "            print(f\"Extrcated buy price per square meter via scraper: {buy_price}\")\n",
    "        else:\n",
    "            print(\"Price not found\")\n",
    "    else:\n",
    "        print(\"The element ontaining the buy price was not found.\")\n",
    "    return buy_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_rent(val_X, val_y, runname=\"baseline_rent\"):\n",
    "    avg_price_per_sqm_rent = scrape_avg_rental_prices()\n",
    "    print(f\"Average rental price per sqm: {avg_price_per_sqm_rent}\")\n",
    "    baseline_preds = val_X[\"LivingSpace\"] * avg_price_per_sqm_rent\n",
    "    baseline_mae = mean_absolute_error(val_y, baseline_preds)\n",
    "    baseline_r2 = r2_score(val_y, baseline_preds)\n",
    "    baseline_mse = mean_squared_error(val_y, baseline_preds)\n",
    "\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        mlflow.log_metric(\"mse\", baseline_mse)\n",
    "        mlflow.log_metric(\"mae\", baseline_mae)\n",
    "        mlflow.log_metric(\"r2\", baseline_r2)\n",
    "\n",
    "    print(f\"Baseline Mae: {baseline_mae}\")\n",
    "    print(f\"Baseline MSE: {baseline_mse}\")\n",
    "    print(f\"Baseline R2 Score: {baseline_r2}\")\n",
    "    return avg_price_per_sqm_rent, baseline_mae, baseline_mse, baseline_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_buy(X_val, y_val, runname=\"baseline_buy\"):\n",
    "    avg_price_per_sqm_buy = scrape_avg_buy_prices()\n",
    "    print(f\"Average rental price per sqm: {avg_price_per_sqm_buy}\")\n",
    "\n",
    "    baseline_preds = X_val[\"LivingSpace\"] * avg_price_per_sqm_buy\n",
    "    baseline_mae = mean_absolute_error(y_val, baseline_preds)\n",
    "    baseline_r2 = r2_score(y_val, baseline_preds)\n",
    "    baseline_mse = mean_squared_error(y_val, baseline_preds)\n",
    "\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        mlflow.log_metric(\"mse\", baseline_mse)\n",
    "        mlflow.log_metric(\"mae\", baseline_mae)\n",
    "        mlflow.log_metric(\"r2\", baseline_r2)\n",
    "\n",
    "    print(f\"Baseline Mae: {baseline_mae}\")\n",
    "    print(f\"Baseline MSE: {baseline_mse}\")\n",
    "    print(f\"Baseline R2 Score: {baseline_r2}\")\n",
    "\n",
    "    return avg_price_per_sqm_buy, baseline_mae, baseline_mse, baseline_r2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_linear(X_train, y_train, X_val, y_val, runname=\"linear-regression\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"mae\", mae_train)\n",
    "        mlflow.log_metric(\"mse\", mse_train)\n",
    "        mlflow.log_metric(\"r2\", r2_train)\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_lasso(X_train, y_train, X_val, y_val, runname=\"lasso-regression\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = Lasso()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"mae\", mae_train)\n",
    "        mlflow.log_metric(\"mse\", mse_train)\n",
    "        mlflow.log_metric(\"r2\", r2_train)\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_ridge(X_train, y_train, X_val, y_val, runname=\"ridge-regression\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = Ridge()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"mae\", mae_train)\n",
    "        mlflow.log_metric(\"mse\", mse_train)\n",
    "        mlflow.log_metric(\"r2\", r2_train)\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_rf(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    n_estimators=50,\n",
    "    random_state=0,\n",
    "    run_name=\"random-forest\",\n",
    "):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=n_estimators, random_state=random_state\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        preds = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_xgb(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    run_name=\"xgb\",\n",
    "    early_stopping_rounds=30,\n",
    "    max_depth=6,\n",
    "    n_estimators=1000,\n",
    "):\n",
    "    mlflow.xgboost.autolog()\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        model = xgb.XGBRegressor(\n",
    "            eval_metric=[\"rmse\", \"mae\"],\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            random_state=42,\n",
    "            max_depth=max_depth,\n",
    "            n_estimators=n_estimators,\n",
    "        )\n",
    "        mlflow.log_param(\"early_stopping_rounds\", early_stopping_rounds)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        model.fit(X=X_train, y=y_train, eval_set=[(X_val, y_val)], verbose=True)\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        preds = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_elasticnet(X_train, y_train, X_val, y_val, runname=\"elasticNet\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = ElasticNet()\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        preds = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_from_extracted(df, feature_set, model_name=\"lasso\"):\n",
    "    X, y = preprocess_data(df, feature_set)\n",
    "    print(\"Done with preprocessing\")\n",
    "    X_train, y_train, X_val, y_val, test_X, test_y = data_split(X, y)\n",
    "    print(\"Done with data split\")\n",
    "\n",
    "    model, mae, mse, r2, mae_train, mse_train, r2_train = (\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "\n",
    "    if model_name == \"lasso\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_lasso(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"ridge\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_ridge(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"rf\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_rf(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"xgb\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_xgb(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"elasticnet\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_elasticnet(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"linear\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_linear(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"baseline-rent\":\n",
    "        avg_price, mae, mse, r2 = baseline_rent(X_val, y_val)\n",
    "    else:\n",
    "        print(\n",
    "            \"Model not found. Model_name must be 'lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline_buy' or 'baseline_rent'\"\n",
    "        )\n",
    "    print(\"Done with train\")\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Data Approach With CTGan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.autolog(disable=True)\n",
    "def complete_from_extracted_with_augemented_training_data(\n",
    "    df,\n",
    "    feature_set,\n",
    "    model_name,\n",
    "    augmentation_epochs=30,\n",
    "    n_added_fake_train_data=1000,\n",
    "):\n",
    "    df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "    X = df.drop(columns=[\"Object_price\"])\n",
    "    y = df[\"Object_price\"]\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = data_split(X, y)\n",
    "    \n",
    "    train = pd.concat(\n",
    "        [X_train, y_train], axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "    val = pd.concat(\n",
    "        [X_val, y_val], axis=1\n",
    "    )\n",
    "    # only the feature set columns in val \n",
    "    val = val[feature_set]\n",
    "\n",
    "    df_cttrain = train.copy()\n",
    "    df_cttrain = df_cttrain[feature_set]\n",
    "    df_cttrain = df_cttrain.dropna()\n",
    "\n",
    "    numerical_features = [\"Rooms\", \"LivingSpace\", \"Object_price\"]\n",
    "\n",
    "    df_cttrain[numerical_features] = df_cttrain[numerical_features].astype(\"int64\")\n",
    "    categorical_features = [\n",
    "        col for col in df_cttrain.columns if col not in numerical_features\n",
    "    ]\n",
    "    ctgan = CTGAN(verbose=True)\n",
    "    ctgan.fit(df_cttrain, categorical_features, epochs=augmentation_epochs)\n",
    "\n",
    "    samples = ctgan.sample(n_added_fake_train_data * 3)\n",
    "    samples[\"Object_price\"] = samples[\"Object_price\"].clip(lower=0)\n",
    "    samples = samples[samples[\"LivingSpace\"] > 20]\n",
    "    samples = samples[samples[\"Object_price\"] > 120]\n",
    "    samples = samples.head(n_added_fake_train_data)\n",
    "\n",
    "    X_sample_train = samples.drop(columns=[\"Object_price\"])\n",
    "    y_sample_train = samples[\"Object_price\"]\n",
    "    X_train = pd.concat([X_train, X_sample_train])\n",
    "    y_train = pd.concat([y_train, y_sample_train])\n",
    "\n",
    "    train_extended = pd.concat(\n",
    "        [X_train, y_train], axis=1\n",
    "    )\n",
    "    X_train, y_train = preprocess_data(train_extended, feature_set_selected)\n",
    "    X_val, y_val = preprocess_data(val, feature_set_selected)\n",
    "    print(f\"X_val shape: {X_val.shape}\")\n",
    "    print(f\"val shape: {val.shape}\")\n",
    "    print(f\"X_val head: {X_train.head()}\")\n",
    "    print(f\"val head: {val.head()}\")\n",
    "\n",
    "    X_train, X_val = X_train.align(X_val, join=\"outer\", axis=1, fill_value=0)\n",
    "\n",
    "    model, mae, mse, r2, mae_train, mse_train, r2_train = (\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "\n",
    "    if model_name == \"lasso\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_lasso(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"ridge\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_ridge(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_val,\n",
    "            y_val,\n",
    "        )\n",
    "    elif model_name == \"rf\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_rf(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"xgb\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_xgb(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"elasticnet\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_elasticnet(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"linear\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_linear(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"baseline-rent\":\n",
    "        avg_price, mae, mse, r2 = baseline_rent(X_val, y_val)\n",
    "    else:\n",
    "        print(\n",
    "            \"Model not found. Model_name must be 'lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline_buy' or 'baseline_rent'\"\n",
    "        )\n",
    "    print(\"Done with train\")\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution of complete pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "feature_set_high_corr = determineHighCorrCols(df) + [\"ZipCode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with model:  baseline-rent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 17:36:05 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0d25f6eb2c1247748fea49f5e3407faa', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 17:36:09 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2023/07/13 17:36:28 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: INVALID_PARAMETER_VALUE: The run 0d25f6eb2c1247748fea49f5e3407faa must be in 'active' lifecycle_stage.\n",
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 17:36:30 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'a56f9c928b994384a2cf22a17766594d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 17:36:35 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 17:36:56 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '5af0150d7a9f4c259b034b921736efe4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 17:37:00 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "2023/07/13 17:37:20 WARNING mlflow.sklearn: Failed to log evaluation dataset information to MLflow Tracking. Reason: INVALID_PARAMETER_VALUE: The run 0d25f6eb2c1247748fea49f5e3407faa must be in 'active' lifecycle_stage.\n",
      "2023/07/13 17:37:22 WARNING mlflow.sklearn: Failed to log evaluation dataset information to MLflow Tracking. Reason: INVALID_PARAMETER_VALUE: The run a56f9c928b994384a2cf22a17766594d must be in 'active' lifecycle_stage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G:  0.8619,Loss D:  0.0509\n",
      "Epoch 2, Loss G:  0.8794,Loss D: -0.0048\n",
      "Epoch 3, Loss G:  0.8991,Loss D: -0.0359\n",
      "Epoch 4, Loss G:  0.8695,Loss D: -0.0492\n",
      "Epoch 5, Loss G:  0.8333,Loss D: -0.0844\n",
      "Epoch 6, Loss G:  0.8554,Loss D: -0.1134\n",
      "Epoch 7, Loss G:  0.9004,Loss D: -0.1628\n",
      "Epoch 8, Loss G:  0.8554,Loss D: -0.1452\n",
      "Epoch 9, Loss G:  0.8015,Loss D: -0.1280\n",
      "Epoch 10, Loss G:  0.8384,Loss D: -0.1953\n",
      "Epoch 11, Loss G:  0.8492,Loss D: -0.3070\n",
      "Epoch 12, Loss G:  0.7360,Loss D: -0.3293\n",
      "Epoch 13, Loss G:  0.7439,Loss D: -0.2836\n",
      "Epoch 14, Loss G:  0.7855,Loss D: -0.3387\n",
      "Epoch 15, Loss G:  0.6984,Loss D: -0.3315\n",
      "Epoch 16, Loss G:  0.6574,Loss D: -0.3344\n",
      "Epoch 17, Loss G:  0.5121,Loss D: -0.2881\n",
      "Epoch 18, Loss G:  0.5141,Loss D: -0.3512\n",
      "Epoch 19, Loss G:  0.3637,Loss D: -0.2841\n",
      "Epoch 20, Loss G:  0.5070,Loss D: -0.3070\n",
      "Epoch 21, Loss G:  0.3172,Loss D: -0.2476\n",
      "Epoch 22, Loss G:  0.3406,Loss D: -0.2109\n",
      "Epoch 23, Loss G:  0.2769,Loss D: -0.1833\n",
      "Epoch 24, Loss G:  0.3083,Loss D: -0.0648\n",
      "Epoch 25, Loss G:  0.2163,Loss D:  0.0113\n",
      "Epoch 26, Loss G:  0.0761,Loss D:  0.0403\n",
      "Epoch 27, Loss G:  0.0820,Loss D: -0.1159\n",
      "Epoch 28, Loss G:  0.0481,Loss D:  0.2350\n",
      "Epoch 29, Loss G:  0.1361,Loss D:  0.1266\n",
      "Epoch 30, Loss G:  0.0590,Loss D:  0.1676\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['ConstructionYear']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mflats_to_rent_wue_preprocessed_combined.xlsx\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStarting with model: \u001b[39m\u001b[39m\"\u001b[39m, model_name)\n\u001b[1;32m---> 45\u001b[0m complete_from_extracted_with_augemented_training_data(df, model_name\u001b[39m=\u001b[39;49mmodel_name, feature_set\u001b[39m=\u001b[39;49mfeature_set_selected)\n\u001b[0;32m     46\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone with model: \u001b[39m\u001b[39m\"\u001b[39m, model_name)\n\u001b[0;32m     47\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m--------------------------------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[66], line 55\u001b[0m, in \u001b[0;36mcomplete_from_extracted_with_augemented_training_data\u001b[1;34m(df, feature_set, model_name, augmentation_epochs, n_added_fake_train_data)\u001b[0m\n\u001b[0;32m     51\u001b[0m train_extended \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(\n\u001b[0;32m     52\u001b[0m     [X_train, y_train], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     53\u001b[0m )\n\u001b[0;32m     54\u001b[0m X_train, y_train \u001b[39m=\u001b[39m preprocess_data(train_extended, feature_set_selected)\n\u001b[1;32m---> 55\u001b[0m X_val, y_val \u001b[39m=\u001b[39m preprocess_data(val, feature_set_selected)\n\u001b[0;32m     56\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX_val shape: \u001b[39m\u001b[39m{\u001b[39;00mX_val\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval shape: \u001b[39m\u001b[39m{\u001b[39;00mval\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(df, feature_set)\u001b[0m\n\u001b[0;32m     14\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mLivingSpace\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mLivingSpace\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n\u001b[0;32m     15\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mRooms\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mRooms\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mdropna(subset\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mConstructionYear\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     17\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdropna(subset\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mObject_price\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     18\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdropna(subset\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mRooms\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\core\\frame.py:6561\u001b[0m, in \u001b[0;36mDataFrame.dropna\u001b[1;34m(self, axis, how, thresh, subset, inplace)\u001b[0m\n\u001b[0;32m   6559\u001b[0m     check \u001b[39m=\u001b[39m indices \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   6560\u001b[0m     \u001b[39mif\u001b[39;00m check\u001b[39m.\u001b[39many():\n\u001b[1;32m-> 6561\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(np\u001b[39m.\u001b[39marray(subset)[check]\u001b[39m.\u001b[39mtolist())\n\u001b[0;32m   6562\u001b[0m     agg_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indices, axis\u001b[39m=\u001b[39magg_axis)\n\u001b[0;32m   6564\u001b[0m \u001b[39mif\u001b[39;00m thresh \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m no_default:\n",
      "\u001b[1;31mKeyError\u001b[0m: ['ConstructionYear']"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"wue-rent-selected-features-aug\")\n",
    "model_names = ['lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline-rent']\n",
    "model_names = ['baseline-rent']\n",
    "\n",
    "feature_set_selected = [\n",
    "    \"Object_price\",\n",
    "    \"LivingSpace\",\n",
    "    \"ZipCode\", \n",
    "    \"Rooms\",\n",
    "    \"altbau_(bis_1945)\",\n",
    "    \"balkon\",\n",
    "    \"barriefrei\",\n",
    "    \"dachgeschoss\",\n",
    "    \"einbaukueche\",\n",
    "    \"neubau\",\n",
    "    \"parkett\",\n",
    "    \"stellplatz\", \n",
    "    \"bad/wc_getrennt\",\n",
    "    \"personenaufzug\",\n",
    "    \"garten\",\n",
    "    \"garage\",\n",
    "    \"renoviert\", \n",
    "    \"terrasse\", \n",
    "    \"wanne\", \n",
    "    \"zentralheizung\",\n",
    "    \"abstellraum\",\n",
    "    \"ferne\",\n",
    "    \"fussbodenheizung\",\n",
    "    \"gartennutzung\",\n",
    "    \"kelleranteil\"\n",
    "]\n",
    "\n",
    "df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "    \n",
    "# for model_name in model_names:\n",
    "#     df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "#     print(\"Starting with model: \", model_name)\n",
    "#     pipeline_from_extracted(df, model_name=model_name, feature_set=feature_set_selected)\n",
    "#     print(\"Done with model: \", model_name)\n",
    "#     print(\"--------------------------------------------------------\")\n",
    "\n",
    "for model_name in model_names:\n",
    "    df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "    print(\"Starting with model: \", model_name)\n",
    "    complete_from_extracted_with_augemented_training_data(df, model_name=model_name, feature_set=feature_set_selected)\n",
    "    print(\"Done with model: \", model_name)\n",
    "    print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "# complete_from_extracted_with_augemented_training_data(df, feature_set_selected, model_name=\"lasso\", augmentation_epochs=20, n_added_fake_train_data=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all runs and make result plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_selected_features = mlflow.search_runs(experiment_names=[\"wue-rent-selected-features\"])\n",
    "results_selected_features = results_selected_features[[\"tags.mlflow.runName\",\"metrics.mae\",\"metrics.r2\"]]\n",
    "results_selected_features = results_selected_features.sort_values(by=\"metrics.mae\", ascending=False)\n",
    "results_selected_features[\"experiment\"] = \"wue-rent-selected-features\"\n",
    "\n",
    "# do the same for experiment wue-rent-selected_features-aug\n",
    "results_selected_features_aug = mlflow.search_runs(experiment_names=[\"wue-rent-selected-features-aug\"])\n",
    "results_selected_features_aug = results_selected_features_aug[[\"tags.mlflow.runName\",\"metrics.mae\",\"metrics.r2\"]]\n",
    "results_selected_features_aug = results_selected_features_aug.sort_values(by=\"metrics.mae\", ascending=False)\n",
    "results_selected_features_aug[\"experiment\"] = \"wue-rent-selected-features-aug\"\n",
    "\n",
    "\n",
    "# add both dataframes together\n",
    "results = pd.concat([results_selected_features, results_selected_features_aug])\n",
    "print(results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(mae_runs.shape)\n",
    "# fig, ax = plt.subplots(figsize=(10, 6))\n",
    "# ax.bar(mae_runs[\"tags.mlflow.runName\"], mae_runs[\"metrics.mae\"], color='lightblue')\n",
    "# ax.set_xlabel(\"Model\", fontsize=14)\n",
    "# ax.set_ylabel(\"MAE\", fontsize=14)\n",
    "# ax.set_title(\"MAE: wue-rent-combined-high-corr-features\", fontsize=16)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
