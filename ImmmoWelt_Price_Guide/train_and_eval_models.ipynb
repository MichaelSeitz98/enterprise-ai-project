{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "from ctgan import CTGAN\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression, ElasticNet\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "# profile = ProfileReport(df, title=\"Flats -  Würzburg - Rent - Overview\", explorative=True)\n",
    "# profile.to_file(\"eda-wue-rent-all.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(r'data\\houses_to_buy_wue_preprocessed_1207.xlsx')\n",
    "# profile = ProfileReport(df, title=\"Houses -  Würzburg - Buy - Overview\", explorative=True)\n",
    "# profile.to_file(\"eda-wue-houses.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineHighCorrCols(df):\n",
    "    df.columns = [re.sub(r\"\\\\u([0-9a-fA-F]{4})\", lambda m: chr(int(m.group(1), 16)), col) for col in df.columns]\n",
    "    df.columns = [col.replace(\"ö\", \"oe\").replace(\"ä\", \"ae\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\") for col in df.columns]\n",
    "    important_num_cols = list(df.corr()[\"Object_price\"][(df.corr()[\"Object_price\"]>0.20) | (df.corr()[\"Object_price\"]<-0.20)].index)\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    important_cols = important_num_cols + cat_cols +   [\"ConstructionYear\"] + [\"ZipCode\"]\n",
    "    #   df = df[important_cols]\n",
    "    print(important_cols)\n",
    "    return important_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, feature_set):\n",
    "    print(f\"Used feature set for preprocessing:{feature_set}\")\n",
    "    df.columns = [\n",
    "        re.sub(r\"\\\\u([0-9a-fA-F]{4})\", lambda m: chr(int(m.group(1), 16)), col)\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    df.columns = [\n",
    "        col.replace(\"ö\", \"oe\").replace(\"ä\", \"ae\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\")\n",
    "        for col in df.columns\n",
    "    ]\n",
    "\n",
    "    df = df.replace('\"\"', np.nan)\n",
    "    df = df.dropna()\n",
    "    df[\"LivingSpace\"] = df[\"LivingSpace\"].astype(float)\n",
    "    df[\"Rooms\"] = df[\"Rooms\"].astype(float)\n",
    "    df = df.dropna(subset=[\"ConstructionYear\"])\n",
    "    df = df.dropna(subset=[\"Object_price\"])\n",
    "    df = df.dropna(subset=[\"Rooms\"])\n",
    "    df = df.dropna(subset=[\"LivingSpace\"])\n",
    "    df[\"ZipCode\"] = df[\"ZipCode\"].astype(str)\n",
    "    df[\"LivingSpace\"] = df[\"LivingSpace\"].astype(float)\n",
    "    df = df[feature_set]\n",
    "    df = df.reindex()\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # one-hot encoding\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == \"object\"]\n",
    "    y = df[\"Object_price\"]\n",
    "    X = df.drop(\"Object_price\", axis=1)\n",
    "    X = pd.get_dummies(X, columns=cat_cols)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X, y, train_size=0.8, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=train_size, random_state=random_state\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, train_size=train_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # X_train.to_excel(\"data/X_train.xlsx\")\n",
    "    # X_val.to_excel(\"data/X_val.xlsx\")\n",
    "    # X_test.to_excel(\"data/X_test.xlsx\")\n",
    "    # y_train.to_excel(\"data/y_train.xlsx\")\n",
    "    # y_val.to_excel(\"data/y_val.xlsx\")\n",
    "    # y_test.to_excel(\"data/y_test.xlsx\")\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "\n",
    "X = df.drop(\"Object_price\", axis=1)\n",
    "y = df[\"Object_price\"]\n",
    "\n",
    "data_split(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Evaluation and Logging Of Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_avg_rental_prices():\n",
    "    url = \"https://www.wohnungsboerse.net/mietspiegel-Wuerzburg/2772\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    script_tag = soup.find(\"script\", string=lambda text: \"pdfData\" in text)\n",
    "    rental_price = 0\n",
    "    if script_tag:\n",
    "        script_content = script_tag.string\n",
    "        start_index = script_content.find(\"avg_rent_price: \") + len(\"avg_rent_price: '\")\n",
    "        end_index = script_content.find(\"',\", start_index)\n",
    "        rental_price = script_content[start_index:end_index]\n",
    "        rental_price = (\n",
    "            rental_price.replace(\"€/m2\", \"\").replace(\".\", \"\").replace(\",\", \".\")\n",
    "        )\n",
    "        rental_price = rental_price.strip()\n",
    "        rental_price = float(rental_price)\n",
    "        print(f\"Extrcated rental price per square meter via scraper: {rental_price}\")\n",
    "    else:\n",
    "        print(\"The script tag containing the rental price was not found.\")\n",
    "    return rental_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_avg_buy_prices():\n",
    "    url = \"https://www.wohnungsboerse.net/immobilienpreise-Wuerzburg/2772\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    p_element = soup.find(\"p\", class_=\"mb-8\")\n",
    "    buy_price = 0\n",
    "    if p_element:\n",
    "        pattern = r\"\\d{1,3}(?:\\.\\d{3})*(?:,\\d{2})?€/m²\"\n",
    "        match = re.search(pattern, p_element.text)\n",
    "        if match:\n",
    "            buy_price = match.group()\n",
    "            buy_price = buy_price.replace(\"€/m²\", \"\").replace(\".\", \"\").replace(\",\", \".\")\n",
    "            print(f\"Extrcated buy price per square meter via scraper: {buy_price}\")\n",
    "        else:\n",
    "            print(\"Price not found\")\n",
    "    else:\n",
    "        print(\"The element ontaining the buy price was not found.\")\n",
    "    return buy_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_rent(val_X, val_y, runname=\"baseline_rent\"):\n",
    "    avg_price_per_sqm_rent = scrape_avg_rental_prices()\n",
    "    print(f\"Average rental price per sqm: {avg_price_per_sqm_rent}\")\n",
    "    baseline_preds = val_X[\"LivingSpace\"] * avg_price_per_sqm_rent\n",
    "    baseline_mae = mean_absolute_error(val_y, baseline_preds)\n",
    "    baseline_r2 = r2_score(val_y, baseline_preds)\n",
    "    baseline_mse = mean_squared_error(val_y, baseline_preds)\n",
    "\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        mlflow.log_metric(\"mse\", baseline_mse)\n",
    "        mlflow.log_metric(\"mae\", baseline_mae)\n",
    "        mlflow.log_metric(\"r2\", baseline_r2)\n",
    "\n",
    "    print(f\"Baseline Mae: {baseline_mae}\")\n",
    "    print(f\"Baseline MSE: {baseline_mse}\")\n",
    "    print(f\"Baseline R2 Score: {baseline_r2}\")\n",
    "    return avg_price_per_sqm_rent, baseline_mae, baseline_mse, baseline_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_buy(X_val, y_val, runname=\"baseline_buy\"):\n",
    "    avg_price_per_sqm_buy = scrape_avg_buy_prices()\n",
    "    print(f\"Average rental price per sqm: {avg_price_per_sqm_buy}\")\n",
    "\n",
    "    baseline_preds = X_val[\"LivingSpace\"] * avg_price_per_sqm_buy\n",
    "    baseline_mae = mean_absolute_error(y_val, baseline_preds)\n",
    "    baseline_r2 = r2_score(y_val, baseline_preds)\n",
    "    baseline_mse = mean_squared_error(y_val, baseline_preds)\n",
    "\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        mlflow.log_metric(\"mse\", baseline_mse)\n",
    "        mlflow.log_metric(\"mae\", baseline_mae)\n",
    "        mlflow.log_metric(\"r2\", baseline_r2)\n",
    "\n",
    "    print(f\"Baseline Mae: {baseline_mae}\")\n",
    "    print(f\"Baseline MSE: {baseline_mse}\")\n",
    "    print(f\"Baseline R2 Score: {baseline_r2}\")\n",
    "\n",
    "    return avg_price_per_sqm_buy, baseline_mae, baseline_mse, baseline_r2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_linear(X_train, y_train, X_val, y_val, runname=\"linear-regression\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"mae\", mae_train)\n",
    "        mlflow.log_metric(\"mse\", mse_train)\n",
    "        mlflow.log_metric(\"r2\", r2_train)\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_lasso(X_train, y_train, X_val, y_val, runname=\"lasso-regression\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = Lasso()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"mae\", mae_train)\n",
    "        mlflow.log_metric(\"mse\", mse_train)\n",
    "        mlflow.log_metric(\"r2\", r2_train)\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_ridge(X_train, y_train, X_val, y_val, runname=\"ridge-regression\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = Ridge()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"mae\", mae_train)\n",
    "        mlflow.log_metric(\"mse\", mse_train)\n",
    "        mlflow.log_metric(\"r2\", r2_train)\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_rf(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    n_estimators=50,\n",
    "    random_state=0,\n",
    "    run_name=\"random-forest\",\n",
    "):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=n_estimators, random_state=random_state\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        preds = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_xgb(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    run_name=\"xgb\",\n",
    "    early_stopping_rounds=30,\n",
    "    max_depth=6,\n",
    "    n_estimators=1000,\n",
    "):\n",
    "    mlflow.xgboost.autolog()\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        model = xgb.XGBRegressor(\n",
    "            eval_metric=[\"rmse\", \"mae\"],\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            random_state=42,\n",
    "            max_depth=max_depth,\n",
    "            n_estimators=n_estimators,\n",
    "        )\n",
    "        mlflow.log_param(\"early_stopping_rounds\", early_stopping_rounds)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        model.fit(X=X_train, y=y_train, eval_set=[(X_val, y_val)], verbose=True)\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        preds = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_elasticnet(X_train, y_train, X_val, y_val, runname=\"elasticNet\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = ElasticNet()\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        preds = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_from_extracted(df, feature_set, model_name=\"lasso\"):\n",
    "    X, y = preprocess_data(df, feature_set)\n",
    "    print(\"Done with preprocessing.\")\n",
    "    X_train, y_train, X_val, y_val, test_X, test_y = data_split(X, y)\n",
    "    print(\"Done with data split\")\n",
    "    model, mae, mse, r2, mae_train, mse_train, r2_train = (\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "\n",
    "    if model_name == \"lasso\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_lasso(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"ridge\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_ridge(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"rf\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_rf(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"xgb\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_xgb(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"elasticnet\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_elasticnet(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"linear\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_linear(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"baseline-rent\":\n",
    "        avg_price, mae, mse, r2 = baseline_rent(X_val, y_val)\n",
    "    else:\n",
    "        print(\n",
    "            \"Model not found. Model_name must be 'lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline_buy' or 'baseline_rent'\"\n",
    "        )\n",
    "    print(\"Done with train\")\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_from_extracted(df, feature_set, model_name=\"lasso\"):\n",
    "    X, y = preprocess_data(df, feature_set)\n",
    "    print(\"Done with preprocessing\")\n",
    "    X_train, y_train, X_val, y_val, test_X, test_y = data_split(X,y)\n",
    "    print(\"Done with data split\")\n",
    "\n",
    "    model, mae, mse, r2, mae_train, mse_train, r2_train = None, None, None, None, None, None, None\n",
    "\n",
    "    if model_name == \"lasso\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_lasso(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"ridge\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_ridge(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"rf\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_rf(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"xgb\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_xgb(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"elasticnet\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_elasticnet(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"linear\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_linear(X_train, y_train, X_val, y_val)\n",
    "    elif model_name ==\"baseline-rent\":\n",
    "        avg_price, mae, mse, r2 = baseline_rent(X_val, y_val)\n",
    "    else:\n",
    "        print(\"Model not found. Model_name must be 'lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline_buy' or 'baseline_rent'\")\n",
    "    print(\"Done with train\")\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Data Approach With CTGan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_from_extracted_with_augemented_training_data(\n",
    "    df,\n",
    "    feature_set,\n",
    "    model_name=\"lasso\",\n",
    "    augmentation_epochs=30,\n",
    "    n_added_fake_train_data=1000,\n",
    "):\n",
    "    df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "    X = df.drop(columns=[\"Object_price\"])\n",
    "    y = df[\"Object_price\"]\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = data_split(X, y)\n",
    "    train_extended = pd.concat(\n",
    "        [X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1\n",
    "    )\n",
    "    val = pd.concat(\n",
    "        [X_val.reset_index(drop=True), y_val.reset_index(drop=True)], axis=1\n",
    "    )\n",
    "\n",
    "    df_cttrain = X_train.copy()\n",
    "    df_cttrain[\"Object_price\"] = y_train\n",
    "    df_cttrain = df_cttrain[feature_set]\n",
    "    df_cttrain = df_cttrain.dropna()\n",
    "\n",
    "    #numerical_features = [\"ConstructionYear\", \"Rooms\", \"LivingSpace\", \"Object_price\"]\n",
    "    numerical_features = [\"ConstructionYear\", \"Rooms\", \"LivingSpace\", \"Object_price\"]\n",
    "\n",
    "    df_cttrain[numerical_features] = df_cttrain[numerical_features].astype(\"int64\")\n",
    "    categorical_features = [\n",
    "        col for col in df_cttrain.columns if col not in numerical_features\n",
    "    ]\n",
    "    ctgan = CTGAN(verbose=True)\n",
    "    ctgan.fit(df_cttrain, categorical_features, epochs=augmentation_epochs)\n",
    "\n",
    "    samples = ctgan.sample(n_added_fake_train_data * 3)\n",
    "    samples[\"Object_price\"] = samples[\"Object_price\"].clip(lower=0)\n",
    "    #samples = samples[samples[\"ConstructionYear\"] < 2023]\n",
    "    samples = samples[samples[\"LivingSpace\"] > 20]\n",
    "    samples = samples[samples[\"Object_price\"] > 100]\n",
    "    samples = samples.head(n_added_fake_train_data)\n",
    "\n",
    "    X_sample_train = samples.drop(columns=[\"Object_price\"])\n",
    "    y_sample_train = samples[\"Object_price\"]\n",
    "    X_train = pd.concat([X_train, X_sample_train])\n",
    "    y_train = pd.concat([y_train, y_sample_train])\n",
    "\n",
    "    train_extended = pd.concat(\n",
    "        [X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1\n",
    "    )\n",
    "    X_train, y_train = preprocess_data(train_extended, feature_set_selected)\n",
    "    X_val, y_val = preprocess_data(val, feature_set_selected)\n",
    "\n",
    "    X_train, X_val = X_train.align(X_val, join=\"outer\", axis=1, fill_value=0)\n",
    "\n",
    "    model, mae, mse, r2, mae_train, mse_train, r2_train = (\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "\n",
    "    if model_name == \"lasso\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_lasso(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"ridge\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_ridge(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_val,\n",
    "            y_val,\n",
    "        )\n",
    "    elif model_name == \"rf\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_rf(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"xgb\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_xgb(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"elasticnet\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_elasticnet(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"linear\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_linear(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"baseline-rent\":\n",
    "        avg_price, mae, mse, r2 = baseline_rent(X_val, y_val)\n",
    "    else:\n",
    "        print(\n",
    "            \"Model not found. Model_name must be 'lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline_buy' or 'baseline_rent'\"\n",
    "        )\n",
    "    print(\"Done with train\")\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution of complete pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "feature_set_high_corr = determineHighCorrCols(df) + [\"ZipCode\"]\n",
    "feature_set_selected = [\n",
    "    \"Object_price\",\n",
    "    \"LivingSpace\",\n",
    "    \"ZipCode\", \n",
    "    \"Rooms\",\n",
    "    \"altbau_(bis_1945)\",\n",
    "    \"balkon\",\n",
    "    \"barriefrei\",\n",
    "    \"dachgeschoss\",\n",
    "    \"einbaukueche\",\n",
    "    \"neubau\",\n",
    "    \"parkett\",\n",
    "    \"stellplatz\", \n",
    "    \"bad/wc_getrennt\",\n",
    "    \"personenaufzug\",\n",
    "    \"garten\",\n",
    "    \"garage\",\n",
    "    \"renoviert\", \n",
    "    \"terrasse\", \n",
    "    \"wanne\", \n",
    "    \"zentralheizung\",\n",
    "    \"abstellraum\",\n",
    "    \"fernwaerme\",\n",
    "    \"fussbodenheizung\",\n",
    "    \"gartennutzung\",\n",
    "    \"kelleranteil\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with model:  lasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 16:05:27 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '7e022bfc232348078395fc249b97f2bb', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 16:05:31 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 16:05:52 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '512c5e87739a431e838e3f6854abcce0', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 16:05:56 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 16:06:16 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b52f5ce44be84a88baa633c8c0cbddfb', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 16:06:21 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G:  0.8782,Loss D: -0.0311\n",
      "Epoch 2, Loss G:  0.8460,Loss D: -0.0289\n",
      "Epoch 3, Loss G:  0.8557,Loss D: -0.0585\n",
      "Epoch 4, Loss G:  0.8261,Loss D: -0.0975\n",
      "Epoch 5, Loss G:  0.7986,Loss D: -0.1650\n",
      "Epoch 6, Loss G:  0.8213,Loss D: -0.1682\n",
      "Epoch 7, Loss G:  0.7812,Loss D: -0.2548\n",
      "Epoch 8, Loss G:  0.7377,Loss D: -0.2984\n",
      "Epoch 9, Loss G:  0.6819,Loss D: -0.3851\n",
      "Epoch 10, Loss G:  0.6098,Loss D: -0.4423\n",
      "Epoch 11, Loss G:  0.6335,Loss D: -0.4628\n",
      "Epoch 12, Loss G:  0.5517,Loss D: -0.4418\n",
      "Epoch 13, Loss G:  0.3800,Loss D: -0.4747\n",
      "Epoch 14, Loss G:  0.2625,Loss D: -0.4738\n",
      "Epoch 15, Loss G:  0.2553,Loss D: -0.4973\n",
      "Epoch 16, Loss G:  0.1414,Loss D: -0.4786\n",
      "Epoch 17, Loss G: -0.0678,Loss D: -0.4419\n",
      "Epoch 18, Loss G: -0.1833,Loss D: -0.4753\n",
      "Epoch 19, Loss G: -0.2648,Loss D: -0.4098\n",
      "Epoch 20, Loss G: -0.2825,Loss D: -0.3713\n",
      "Epoch 21, Loss G: -0.6251,Loss D: -0.2031\n",
      "Epoch 22, Loss G: -0.4100,Loss D: -0.1981\n",
      "Epoch 23, Loss G: -0.6536,Loss D: -0.2603\n",
      "Epoch 24, Loss G: -0.6562,Loss D: -0.0443\n",
      "Epoch 25, Loss G: -0.6820,Loss D:  0.0382\n",
      "Epoch 26, Loss G: -0.6750,Loss D:  0.0172\n",
      "Epoch 27, Loss G: -0.7018,Loss D:  0.0002\n",
      "Epoch 28, Loss G: -0.6812,Loss D: -0.0056\n",
      "Epoch 29, Loss G: -0.7150,Loss D:  0.0397\n",
      "Epoch 30, Loss G: -0.6629,Loss D:  0.1462\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ConstructionYear'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ConstructionYear'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mflats_to_rent_wue_preprocessed_combined.xlsx\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStarting with model: \u001b[39m\u001b[39m\"\u001b[39m, model_name)\n\u001b[1;32m---> 43\u001b[0m complete_from_extracted_with_augemented_training_data(df, model_name\u001b[39m=\u001b[39;49mmodel_name, feature_set\u001b[39m=\u001b[39;49mfeature_set_selected, n_added_fake_train_data\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n\u001b[0;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone with model: \u001b[39m\u001b[39m\"\u001b[39m, model_name)\n\u001b[0;32m     45\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m--------------------------------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[30], line 34\u001b[0m, in \u001b[0;36mcomplete_from_extracted_with_augemented_training_data\u001b[1;34m(df, feature_set, model_name, augmentation_epochs, n_added_fake_train_data)\u001b[0m\n\u001b[0;32m     32\u001b[0m samples \u001b[39m=\u001b[39m ctgan\u001b[39m.\u001b[39msample(n_added_fake_train_data \u001b[39m*\u001b[39m \u001b[39m3\u001b[39m)\n\u001b[0;32m     33\u001b[0m samples[\u001b[39m\"\u001b[39m\u001b[39mObject_price\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m samples[\u001b[39m\"\u001b[39m\u001b[39mObject_price\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mclip(lower\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m samples \u001b[39m=\u001b[39m samples[samples[\u001b[39m\"\u001b[39;49m\u001b[39mConstructionYear\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m<\u001b[39m \u001b[39m2023\u001b[39m]\n\u001b[0;32m     35\u001b[0m samples \u001b[39m=\u001b[39m samples[samples[\u001b[39m\"\u001b[39m\u001b[39mLivingSpace\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m20\u001b[39m]\n\u001b[0;32m     36\u001b[0m samples \u001b[39m=\u001b[39m samples[samples[\u001b[39m\"\u001b[39m\u001b[39mObject_price\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m100\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ConstructionYear'"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"wue-rent-selected-features-aug\")\n",
    "model_names = ['lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline-rent']\n",
    "feature_set_selected = [\n",
    "    \"Object_price\",\n",
    "    \"LivingSpace\",\n",
    "    \"ZipCode\", \n",
    "    \"Rooms\",\n",
    "    \"altbau_(bis_1945)\",\n",
    "    \"balkon\",\n",
    "    \"barriefrei\",\n",
    "    \"dachgeschoss\",\n",
    "    \"einbaukueche\",\n",
    "    \"neubau\",\n",
    "    \"parkett\",\n",
    "    \"stellplatz\", \n",
    "    \"bad/wc_getrennt\",\n",
    "    \"personenaufzug\",\n",
    "    \"garten\",\n",
    "    \"garage\",\n",
    "    \"renoviert\", \n",
    "    \"terrasse\", \n",
    "    \"wanne\", \n",
    "    \"zentralheizung\",\n",
    "    \"abstellraum\",\n",
    "    \"ferne\",\n",
    "    \"fussbodenheizung\",\n",
    "    \"gartennutzung\",\n",
    "    \"kelleranteil\"\n",
    "]\n",
    "\n",
    "df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "    \n",
    "# for model_name in model_names:\n",
    "#     df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "#     print(\"Starting with model: \", model_name)\n",
    "#     pipeline_from_extracted(df, model_name=model_name, feature_set=feature_set_selected)\n",
    "#     print(\"Done with model: \", model_name)\n",
    "#     print(\"--------------------------------------------------------\")\n",
    "\n",
    "for model_name in model_names:\n",
    "    df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "    print(\"Starting with model: \", model_name)\n",
    "    complete_from_extracted_with_augemented_training_data(df, model_name=model_name, feature_set=feature_set_selected, n_added_fake_train_data=1000)\n",
    "    print(\"Done with model: \", model_name)\n",
    "    print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "# complete_from_extracted_with_augemented_training_data(df, feature_set_selected, model_name=\"lasso\", augmentation_epochs=20, n_added_fake_train_data=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all runs and make result plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.search_runs(experiment_names=[\"wue-rent-high-corr-features-comparison\"])\n",
    "runs = mlflow.search_runs(experiment_names=[\"wue-rent-high-corr-features-comparison\"])\n",
    "mae_runs = runs[runs[\"metrics.mae\"].notnull()]\n",
    "\n",
    "print(mae_runs)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(mae_runs[\"tags.mlflow.runName\"], mae_runs[\"metrics.mae\"], color='lightblue')\n",
    "ax.set_xlabel(\"Model\", fontsize=14)\n",
    "ax.set_ylabel(\"MAE\", fontsize=14)\n",
    "ax.set_title(\"MAE: wue-rent-combined-high-corr-features\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
