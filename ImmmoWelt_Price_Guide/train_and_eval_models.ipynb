{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression, ElasticNet\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "# profile = ProfileReport(df, title=\"Flats -  Würzburg - Rent - Overview\", explorative=True)\n",
    "# profile.to_file(\"eda-wue-rent-all.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineHighCorrCols(df):\n",
    "    important_num_cols = list(df.corr()[\"Object_price\"][(df.corr()[\"Object_price\"]>0.20) | (df.corr()[\"Object_price\"]<-0.20)].index)\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    important_cols = important_num_cols + cat_cols\n",
    "    df = df[important_cols]\n",
    "    print(df.columns)\n",
    "    return df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting different feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Object_price', 'LivingSpace', 'Rooms',\n",
      "       'ConstructionYear', 'ZipCode', 'EstateType', 'DistributionType',\n",
      "       'abstellraum', 'als_ferienimmobilie_geeignet', 'altbau_(bis_1945)',\n",
      "       'bad/wc_getrennt', 'balkon', 'barriefrei', 'bidet', 'carport',\n",
      "       'dachgeschoss', 'dielen', 'dsl', 'duplex', 'dusche', 'einbauk\\u00fcche',\n",
      "       'elektro', 'erdgeschoss', 'erdwaerme', 'erstbezug', 'estrich',\n",
      "       'etagenheizung', 'fenster', 'fern', 'ferne', 'fliesen', 'frei',\n",
      "       'fu\\u00dfbodenheizung', 'gaestewc', 'garage', 'garten', 'gartennutzung',\n",
      "       'gas', 'gepflegt', 'haustiere_erlaubt', 'holzfenster', 'kable_sat_tv',\n",
      "       'kamera', 'kamin', 'kelleranteil', 'kfw40', 'kfw55', 'klimatisiert',\n",
      "       'kontrollierte_be-_und_entl\\u00fcftungsanlage', 'kunststoff',\n",
      "       'kunststofffenster', 'laminat', 'linoleum', 'loggia', 'luftwp',\n",
      "       'marmor', 'massivhaus', 'moebliert', 'neubau', 'neuwertig', 'oel',\n",
      "       'ofenheizung', 'offene_k\\u00fcche', 'pantry', 'parkett', 'pellet',\n",
      "       'personenaufzug', 'reinigung', 'renoviert', 'rollstuhlgerecht', 'sat',\n",
      "       'speisekammer', 'stein', 'stellplatz', 'teilweise_m\\u00f6bliert',\n",
      "       'teppich', 'terrasse', 'tiefgarage', 'vermietet', 'wanne',\n",
      "       'wasch_trockenraum', 'wg_geeignet', 'wintergarten',\n",
      "       'wohnberechtigungsschein', 'zentralheizung'],\n",
      "      dtype='object')\n",
      "Index(['Object_price', 'LivingSpace', 'Rooms', 'abstellraum',\n",
      "       'bad/wc_getrennt', 'barriefrei', 'dusche', 'elektro', 'erdwaerme',\n",
      "       'fenster', 'ferne', 'fliesen', 'frei', 'fu\\u00dfbodenheizung',\n",
      "       'gaestewc', 'garage', 'kable_sat_tv',\n",
      "       'kontrollierte_be-_und_entl\\u00fcftungsanlage', 'kunststofffenster',\n",
      "       'luftwp', 'parkett', 'personenaufzug', 'reinigung', 'rollstuhlgerecht',\n",
      "       'speisekammer', 'terrasse', 'wanne', 'zentralheizung', 'EstateType',\n",
      "       'DistributionType'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michi\\AppData\\Local\\Temp\\ipykernel_4580\\2563616348.py:2: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  important_num_cols = list(df.corr()[\"Object_price\"][(df.corr()[\"Object_price\"]>0.20) | (df.corr()[\"Object_price\"]<-0.20)].index)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "print(df.columns)\n",
    "\n",
    "feature_set_high_corr = determineHighCorrCols(df)\n",
    "feature_set_selected = [\n",
    "    \"ConstructionYear\",\n",
    "    \"ZipCode\",\n",
    "    \"altbau_(bis_1945)\",\n",
    "    \"balkon\",\n",
    "    \"barriefrei\",\n",
    "    \"dachgeschoss\",\n",
    "    \"erstbezug\",\n",
    "    \"einbaukueche\",\n",
    "    \"fliesen\",\n",
    "    \"neubau\",\n",
    "    \"parkett\",\n",
    "    \"stellplatz\",\n",
    "    \"wg_geeignet\",\n",
    "    \"bad/wc_getrennt\",\n",
    "    \"kamin\",\n",
    "    \"personenaufzug\",\n",
    "    \"garten\", \n",
    "    \"garage\", \n",
    "    \"moebliert\", \n",
    "    \"renoviert\", \n",
    "    \"terrasse\",\n",
    "    \"wanne\", \n",
    "    \"zentralheizung\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Object_price', 'LivingSpace', 'Rooms',\n",
      "       'ConstructionYear', 'ZipCode', 'EstateType', 'DistributionType',\n",
      "       'abstellraum', 'als_ferienimmobilie_geeignet', 'altbau_(bis_1945)',\n",
      "       'bad/wc_getrennt', 'balkon', 'barriefrei', 'bidet', 'carport',\n",
      "       'dachgeschoss', 'dielen', 'dsl', 'duplex', 'dusche', 'einbaukueche',\n",
      "       'elektro', 'erdgeschoss', 'erdwaerme', 'erstbezug', 'estrich',\n",
      "       'etagenheizung', 'fenster', 'fern', 'ferne', 'fliesen', 'frei',\n",
      "       'fu\\u00dfbodenheizung', 'gaestewc', 'garage', 'garten', 'gartennutzung',\n",
      "       'gas', 'gepflegt', 'haustiere_erlaubt', 'holzfenster', 'kable_sat_tv',\n",
      "       'kamera', 'kamin', 'kelleranteil', 'kfw40', 'kfw55', 'klimatisiert',\n",
      "       'kontrollierte_be-_und_entl\\u00fcftungsanlage', 'kunststoff',\n",
      "       'kunststofffenster', 'laminat', 'linoleum', 'loggia', 'luftwp',\n",
      "       'marmor', 'massivhaus', 'moebliert', 'neubau', 'neuwertig', 'oel',\n",
      "       'ofenheizung', 'offene_k\\u00fcche', 'pantry', 'parkett', 'pellet',\n",
      "       'personenaufzug', 'reinigung', 'renoviert', 'rollstuhlgerecht', 'sat',\n",
      "       'speisekammer', 'stein', 'stellplatz', 'teilweise_m\\u00f6bliert',\n",
      "       'teppich', 'terrasse', 'tiefgarage', 'vermietet', 'wanne',\n",
      "       'wasch_trockenraum', 'wg_geeignet', 'wintergarten',\n",
      "       'wohnberechtigungsschein', 'zentralheizung'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michi\\AppData\\Local\\Temp\\ipykernel_4580\\4231741687.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.replace('\"\"', np.nan, inplace=True)\n",
      "C:\\Users\\michi\\AppData\\Local\\Temp\\ipykernel_4580\\4231741687.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(inplace=True)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'LivingSpace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'LivingSpace'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 30\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[39mreturn\u001b[39;00m X, y\n\u001b[0;32m     29\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mflats_to_rent_wue_preprocessed_combined.xlsx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m X, y \u001b[39m=\u001b[39m preprocess_data(df)\n\u001b[0;32m     31\u001b[0m \u001b[39mprint\u001b[39m(X\u001b[39m.\u001b[39mcolumns)\n",
      "Cell \u001b[1;32mIn[51], line 9\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(df, feature_set)\u001b[0m\n\u001b[0;32m      7\u001b[0m df\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39mnan, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m df\u001b[39m.\u001b[39mdropna(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 9\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mLivingSpace\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_numeric(df[\u001b[39m\"\u001b[39;49m\u001b[39mLivingSpace\u001b[39;49m\u001b[39m\"\u001b[39;49m], errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcoerce\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mRooms\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_numeric(df[\u001b[39m\"\u001b[39m\u001b[39mRooms\u001b[39m\u001b[39m\"\u001b[39m], errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcoerce\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m df\u001b[39m.\u001b[39mdropna(subset\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mConstructionYear\u001b[39m\u001b[39m'\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'LivingSpace'"
     ]
    }
   ],
   "source": [
    "def preprocess_data (df, feature_set=feature_set_selected): \n",
    "    df.rename(columns={'kontrollierte_be-_und_entl\\u00fcftungsanlage': 'kontrollierte_be-_und_entlueftungsanlage'}, inplace=True)\n",
    "    df.rename(columns={'einbauk\\\\u00fcche': 'einbaukueche'}, inplace=True)\n",
    "    df.rename(columns={'fu\\u00dfbodenheizung': 'fussbodenheizung'}, inplace=True)\n",
    "    print(df.columns)\n",
    "    df = df[feature_set]\n",
    "    df.replace('\"\"', np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    df[\"LivingSpace\"] = pd.to_numeric(df[\"LivingSpace\"], errors=\"coerce\")\n",
    "    df[\"Rooms\"] = pd.to_numeric(df[\"Rooms\"], errors=\"coerce\")\n",
    "    df.dropna(subset=['ConstructionYear'], inplace=True)\n",
    "    df.dropna(subset=['Object_price'], inplace=True)\n",
    "    df.dropna(subset=['Rooms'], inplace=True)\n",
    "    df.dropna(subset=['LivingSpace'], inplace=True)\n",
    "    df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    df['ZipCode']= df['ZipCode'].astype(str)\n",
    "    df['LivingSpace']= df['LivingSpace'].astype(float)\n",
    "    df = df.reindex()\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # one-hot encoding\n",
    "    y = df['Object_price']\n",
    "    X = df.drop('Object_price', axis=1)\n",
    "    X = pd.get_dummies(X, columns=cat_cols)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "X, y = preprocess_data(df)\n",
    "print(X.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X, y, train_size=0.8, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                  train_size=train_size, \n",
    "                                                  random_state = random_state)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                  train_size=train_size, \n",
    "                                                  random_state = random_state)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Evaluation and Logging Of Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_avg_rental_prices():\n",
    "    url = \"https://www.wohnungsboerse.net/mietspiegel-Wuerzburg/2772\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    script_tag = soup.find(\"script\", string=lambda text: \"pdfData\" in text)\n",
    "    rental_price = 0\n",
    "    if script_tag:\n",
    "        script_content = script_tag.string\n",
    "        start_index = script_content.find(\"avg_rent_price: \") + len(\"avg_rent_price: '\")\n",
    "        end_index = script_content.find(\"',\", start_index)\n",
    "        rental_price = script_content[start_index:end_index]\n",
    "        rental_price = (\n",
    "            rental_price.replace(\"€/m2\", \"\").replace(\".\", \"\").replace(\",\", \".\")\n",
    "        )\n",
    "        rental_price = rental_price.strip()\n",
    "        rental_price = float(rental_price)\n",
    "        print(f\"Extrcated rental price per square meter via scraper: {rental_price}\")\n",
    "    else:\n",
    "        print(\"The script tag containing the rental price was not found.\")\n",
    "    return rental_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_avg_buy_prices():\n",
    "    url = \"https://www.wohnungsboerse.net/immobilienpreise-Wuerzburg/2772\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    p_element = soup.find(\"p\", class_=\"mb-8\")\n",
    "    buy_price = 0\n",
    "    if p_element:\n",
    "        pattern = r\"\\d{1,3}(?:\\.\\d{3})*(?:,\\d{2})?€/m²\"\n",
    "        match = re.search(pattern, p_element.text)\n",
    "        if match:\n",
    "            buy_price = match.group()\n",
    "            buy_price = buy_price.replace(\"€/m²\", \"\").replace(\".\", \"\").replace(\",\", \".\")\n",
    "            print(f\"Extrcated buy price per square meter via scraper: {buy_price}\")\n",
    "        else:\n",
    "            print(\"Price not found\")\n",
    "    else:\n",
    "        print(\"The element ontaining the buy price was not found.\")\n",
    "    return buy_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_rent(val_X, val_y, runname=\"baseline_rent\"):\n",
    "    avg_price_per_sqm_rent = scrape_avg_rental_prices()\n",
    "    print(f\"Average rental price per sqm: {avg_price_per_sqm_rent}\")\n",
    "    baseline_preds = val_X['LivingSpace'] * avg_price_per_sqm_rent\n",
    "    baseline_mae = mean_absolute_error(val_y, baseline_preds)\n",
    "    baseline_r2 = r2_score(val_y, baseline_preds)\n",
    "    baseline_mse = mean_squared_error(val_y, baseline_preds)\n",
    "\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        mlflow.log_metric(\"mse\", baseline_mse)\n",
    "        mlflow.log_metric(\"mae\", baseline_mae)\n",
    "        mlflow.log_metric(\"r2\", baseline_r2)\n",
    "\n",
    "    print(f\"Baseline Mae: {baseline_mae}\")\n",
    "    print(f\"Baseline MSE: {baseline_mse}\")    \n",
    "    print(f\"Baseline R2 Score: {baseline_r2}\")\n",
    "    return avg_price_per_sqm_rent, baseline_mae, baseline_mse, baseline_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_buy(X_val, y_val, runname=\"baseline_buy\"):\n",
    "    avg_price_per_sqm_buy = scrape_avg_buy_prices()\n",
    "    print(f\"Average rental price per sqm: {avg_price_per_sqm_buy}\")\n",
    "    \n",
    "    baseline_preds = X_val['LivingSpace'] * avg_price_per_sqm_buy\n",
    "    baseline_mae = mean_absolute_error(y_val, baseline_preds)\n",
    "    baseline_r2 = r2_score(y_val, baseline_preds)\n",
    "    baseline_mse = mean_squared_error(y_val, baseline_preds)\n",
    "\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        mlflow.log_metric(\"mse\", baseline_mse)\n",
    "        mlflow.log_metric(\"mae\", baseline_mae)\n",
    "        mlflow.log_metric(\"r2\", baseline_r2)\n",
    "\n",
    "    print(f\"Baseline Mae: {baseline_mae}\")\n",
    "    print(f\"Baseline MSE: {baseline_mse}\")    \n",
    "    print(f\"Baseline R2 Score: {baseline_r2}\")\n",
    "\n",
    "    return avg_price_per_sqm_buy, baseline_mae, baseline_mse, baseline_r2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_linear(X_train, y_train, X_val, y_val, runname =\"linear-regression\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        \n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"mae\", mae_train)\n",
    "        mlflow.log_metric(\"mse\", mse_train)\n",
    "        mlflow.log_metric(\"r2\", r2_train)\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_lasso(X_train, y_train, X_val, y_val, runname =\"lasso-regression\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = Lasso()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        \n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"mae\", mae_train)\n",
    "        mlflow.log_metric(\"mse\", mse_train)\n",
    "        mlflow.log_metric(\"r2\", r2_train)\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_ridge(X_train, y_train, X_val, y_val, runname =\"ridge-regression\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = Ridge()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        \n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"mae\", mae_train)\n",
    "        mlflow.log_metric(\"mse\", mse_train)\n",
    "        mlflow.log_metric(\"r2\", r2_train)\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_rf(X_train, y_train, X_val, y_val, n_estimators=50, random_state=0, run_name=\"random-forest\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        model = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state)\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        preds= model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_xgb(X_train, y_train, X_val, y_val, run_name=\"xgb\", early_stopping_rounds=30, max_depth=6, n_estimators=1000):\n",
    "    mlflow.xgboost.autolog()\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        model = xgb.XGBRegressor(eval_metric=['rmse', 'mae'], early_stopping_rounds=early_stopping_rounds, random_state=42, max_depth=max_depth, n_estimators=n_estimators)\n",
    "        mlflow.log_param(\"early_stopping_rounds\", early_stopping_rounds)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        model.fit(X=X_train, \n",
    "                  y=y_train,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  verbose=True\n",
    "        )\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        preds= model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)        \n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_elasticnet(X_train, y_train, X_val, y_val, runname=\"elasticNet\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = ElasticNet()\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        preds= model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_from_extracted(df, model_name=\"lasso\"):\n",
    "    X, y = preprocess_data(df)\n",
    "    print(\"Done with preprocessing\")\n",
    "    X_train, y_train, X_val, y_val, test_X, test_y = data_split(X,y)\n",
    "    print(\"Done with data split\")\n",
    "\n",
    "    model, mae, mse, r2, mae_train, mse_train, r2_train = None, None, None, None, None, None, None\n",
    "\n",
    "    if model_name == \"lasso\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_lasso(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"ridge\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_ridge(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"rf\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_rf(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"xgb\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_xgb(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"elasticnet\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_elasticnet(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"linear\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_linear(X_train, y_train, X_val, y_val)\n",
    "    elif model_name ==\"baseline-rent\":\n",
    "        avg_price, mae, mse, r2 = baseline_rent(X_val, y_val)\n",
    "    else:\n",
    "        print(\"Model not found. Model_name must be 'lasso', 'ridge', 'rf', 'xgb', 'elasticnet' or 'linear'\")\n",
    "    print(\"Done with train\")\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute all models on same data and log to MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline-rent']\n",
    "mlflow.set_experiment(\"model_comparison\")\n",
    "    \n",
    "for model_name in model_names:\n",
    "    df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_0407.xlsx')\n",
    "    print(\"Starting with model: \", model_name)\n",
    "    pipeline_from_extracted(df, model_name=model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
