{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "from ctgan import CTGAN\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression, ElasticNet\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "# profile = ProfileReport(df, title=\"Flats -  Würzburg - Rent - Overview\", explorative=True)\n",
    "# profile.to_file(\"eda-wue-rent-all.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(r'data\\houses_to_buy_wue_preprocessed_1207.xlsx')\n",
    "# profile = ProfileReport(df, title=\"Houses -  Würzburg - Buy - Overview\", explorative=True)\n",
    "# profile.to_file(\"eda-wue-houses.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineHighCorrCols(df):\n",
    "    df.columns = [re.sub(r\"\\\\u([0-9a-fA-F]{4})\", lambda m: chr(int(m.group(1), 16)), col) for col in df.columns]\n",
    "    df.columns = [col.replace(\"ö\", \"oe\").replace(\"ä\", \"ae\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\") for col in df.columns]\n",
    "    important_num_cols = list(df.corr()[\"Object_price\"][(df.corr()[\"Object_price\"]>0.20) | (df.corr()[\"Object_price\"]<-0.20)].index)\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    important_cols = important_num_cols + cat_cols +   [\"ConstructionYear\"] + [\"ZipCode\"]\n",
    "    #   df = df[important_cols]\n",
    "    print(important_cols)\n",
    "    return important_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, feature_set):\n",
    "    print(f\"Used feature set for preprocessing:{feature_set}\")\n",
    "    df.columns = [\n",
    "        re.sub(r\"\\\\u([0-9a-fA-F]{4})\", lambda m: chr(int(m.group(1), 16)), col)\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    df.columns = [\n",
    "        col.replace(\"ö\", \"oe\").replace(\"ä\", \"ae\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\")\n",
    "        for col in df.columns\n",
    "    ]\n",
    "\n",
    "    df = df.replace('\"\"', np.nan)\n",
    "    df = df.dropna()\n",
    "    df[\"LivingSpace\"] = df[\"LivingSpace\"].astype(float)\n",
    "    df[\"Rooms\"] = df[\"Rooms\"].astype(float)\n",
    "    df = df.dropna(subset=[\"ConstructionYear\"])\n",
    "    df = df.dropna(subset=[\"Object_price\"])\n",
    "    df = df.dropna(subset=[\"Rooms\"])\n",
    "    df = df.dropna(subset=[\"LivingSpace\"])\n",
    "    df[\"ZipCode\"] = df[\"ZipCode\"].astype(str)\n",
    "    df[\"LivingSpace\"] = df[\"LivingSpace\"].astype(float)\n",
    "    df = df[feature_set]\n",
    "    df = df.reindex()\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # one-hot encoding\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == \"object\"]\n",
    "    y = df[\"Object_price\"]\n",
    "    X = df.drop(\"Object_price\", axis=1)\n",
    "    X = pd.get_dummies(X, columns=cat_cols)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X, y, train_size=0.8, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=train_size, random_state=random_state\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, train_size=train_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # X_train.to_excel(\"data/X_train.xlsx\")\n",
    "    # X_val.to_excel(\"data/X_val.xlsx\")\n",
    "    # X_test.to_excel(\"data/X_test.xlsx\")\n",
    "    # y_train.to_excel(\"data/y_train.xlsx\")\n",
    "    # y_val.to_excel(\"data/y_val.xlsx\")\n",
    "    # y_test.to_excel(\"data/y_test.xlsx\")\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "\n",
    "X = df.drop(\"Object_price\", axis=1)\n",
    "y = df[\"Object_price\"]\n",
    "\n",
    "data_split(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Evaluation and Logging Of Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_avg_rental_prices():\n",
    "    url = \"https://www.wohnungsboerse.net/mietspiegel-Wuerzburg/2772\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    script_tag = soup.find(\"script\", string=lambda text: \"pdfData\" in text)\n",
    "    rental_price = 0\n",
    "    if script_tag:\n",
    "        script_content = script_tag.string\n",
    "        start_index = script_content.find(\"avg_rent_price: \") + len(\"avg_rent_price: '\")\n",
    "        end_index = script_content.find(\"',\", start_index)\n",
    "        rental_price = script_content[start_index:end_index]\n",
    "        rental_price = (\n",
    "            rental_price.replace(\"€/m2\", \"\").replace(\".\", \"\").replace(\",\", \".\")\n",
    "        )\n",
    "        rental_price = rental_price.strip()\n",
    "        rental_price = float(rental_price)\n",
    "        print(f\"Extrcated rental price per square meter via scraper: {rental_price}\")\n",
    "    else:\n",
    "        print(\"The script tag containing the rental price was not found.\")\n",
    "    return rental_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_avg_buy_prices():\n",
    "    url = \"https://www.wohnungsboerse.net/immobilienpreise-Wuerzburg/2772\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    p_element = soup.find(\"p\", class_=\"mb-8\")\n",
    "    buy_price = 0\n",
    "    if p_element:\n",
    "        pattern = r\"\\d{1,3}(?:\\.\\d{3})*(?:,\\d{2})?€/m²\"\n",
    "        match = re.search(pattern, p_element.text)\n",
    "        if match:\n",
    "            buy_price = match.group()\n",
    "            buy_price = buy_price.replace(\"€/m²\", \"\").replace(\".\", \"\").replace(\",\", \".\")\n",
    "            print(f\"Extrcated buy price per square meter via scraper: {buy_price}\")\n",
    "        else:\n",
    "            print(\"Price not found\")\n",
    "    else:\n",
    "        print(\"The element ontaining the buy price was not found.\")\n",
    "    return buy_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_rent(val_X, val_y, runname=\"baseline_rent\"):\n",
    "    avg_price_per_sqm_rent = scrape_avg_rental_prices()\n",
    "    print(f\"Average rental price per sqm: {avg_price_per_sqm_rent}\")\n",
    "    baseline_preds = val_X[\"LivingSpace\"] * avg_price_per_sqm_rent\n",
    "    baseline_mae = mean_absolute_error(val_y, baseline_preds)\n",
    "    baseline_r2 = r2_score(val_y, baseline_preds)\n",
    "    baseline_mse = mean_squared_error(val_y, baseline_preds)\n",
    "\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        mlflow.log_metric(\"mse\", baseline_mse)\n",
    "        mlflow.log_metric(\"mae\", baseline_mae)\n",
    "        mlflow.log_metric(\"r2\", baseline_r2)\n",
    "\n",
    "    print(f\"Baseline Mae: {baseline_mae}\")\n",
    "    print(f\"Baseline MSE: {baseline_mse}\")\n",
    "    print(f\"Baseline R2 Score: {baseline_r2}\")\n",
    "    return avg_price_per_sqm_rent, baseline_mae, baseline_mse, baseline_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_buy(X_val, y_val, runname=\"baseline_buy\"):\n",
    "    avg_price_per_sqm_buy = scrape_avg_buy_prices()\n",
    "    print(f\"Average rental price per sqm: {avg_price_per_sqm_buy}\")\n",
    "\n",
    "    baseline_preds = X_val[\"LivingSpace\"] * avg_price_per_sqm_buy\n",
    "    baseline_mae = mean_absolute_error(y_val, baseline_preds)\n",
    "    baseline_r2 = r2_score(y_val, baseline_preds)\n",
    "    baseline_mse = mean_squared_error(y_val, baseline_preds)\n",
    "\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        mlflow.log_metric(\"mse\", baseline_mse)\n",
    "        mlflow.log_metric(\"mae\", baseline_mae)\n",
    "        mlflow.log_metric(\"r2\", baseline_r2)\n",
    "\n",
    "    print(f\"Baseline Mae: {baseline_mae}\")\n",
    "    print(f\"Baseline MSE: {baseline_mse}\")\n",
    "    print(f\"Baseline R2 Score: {baseline_r2}\")\n",
    "\n",
    "    return avg_price_per_sqm_buy, baseline_mae, baseline_mse, baseline_r2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_linear(X_train, y_train, X_val, y_val, runname=\"linear-regression\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"mae\", mae_train)\n",
    "        mlflow.log_metric(\"mse\", mse_train)\n",
    "        mlflow.log_metric(\"r2\", r2_train)\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_lasso(X_train, y_train, X_val, y_val, runname=\"lasso-regression\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = Lasso()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"mae\", mae_train)\n",
    "        mlflow.log_metric(\"mse\", mse_train)\n",
    "        mlflow.log_metric(\"r2\", r2_train)\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_ridge(X_train, y_train, X_val, y_val, runname=\"ridge-regression\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = Ridge()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"mae\", mae_train)\n",
    "        mlflow.log_metric(\"mse\", mse_train)\n",
    "        mlflow.log_metric(\"r2\", r2_train)\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_rf(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    n_estimators=50,\n",
    "    random_state=0,\n",
    "    run_name=\"random-forest\",\n",
    "):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=n_estimators, random_state=random_state\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        preds = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_xgb(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    run_name=\"xgb\",\n",
    "    early_stopping_rounds=30,\n",
    "    max_depth=6,\n",
    "    n_estimators=1000,\n",
    "):\n",
    "    mlflow.xgboost.autolog()\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        model = xgb.XGBRegressor(\n",
    "            eval_metric=[\"rmse\", \"mae\"],\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            random_state=42,\n",
    "            max_depth=max_depth,\n",
    "            n_estimators=n_estimators,\n",
    "        )\n",
    "        mlflow.log_param(\"early_stopping_rounds\", early_stopping_rounds)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        model.fit(X=X_train, y=y_train, eval_set=[(X_val, y_val)], verbose=True)\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        preds = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_elasticnet(X_train, y_train, X_val, y_val, runname=\"elasticNet\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = ElasticNet()\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        preds = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_from_extracted(df, feature_set, model_name=\"lasso\"):\n",
    "    X, y = preprocess_data(df, feature_set)\n",
    "    print(\"Done with preprocessing.\")\n",
    "    X_train, y_train, X_val, y_val, test_X, test_y = data_split(X, y)\n",
    "    print(\"Done with data split\")\n",
    "    model, mae, mse, r2, mae_train, mse_train, r2_train = (\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "\n",
    "    if model_name == \"lasso\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_lasso(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"ridge\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_ridge(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"rf\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_rf(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"xgb\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_xgb(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"elasticnet\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_elasticnet(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"linear\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_linear(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"baseline-rent\":\n",
    "        avg_price, mae, mse, r2 = baseline_rent(X_val, y_val)\n",
    "    else:\n",
    "        print(\n",
    "            \"Model not found. Model_name must be 'lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline_buy' or 'baseline_rent'\"\n",
    "        )\n",
    "    print(\"Done with train\")\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_from_extracted(df, feature_set, model_name=\"lasso\"):\n",
    "    X, y = preprocess_data(df, feature_set)\n",
    "    print(\"Done with preprocessing\")\n",
    "    X_train, y_train, X_val, y_val, test_X, test_y = data_split(X,y)\n",
    "    print(\"Done with data split\")\n",
    "\n",
    "    model, mae, mse, r2, mae_train, mse_train, r2_train = None, None, None, None, None, None, None\n",
    "\n",
    "    if model_name == \"lasso\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_lasso(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"ridge\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_ridge(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"rf\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_rf(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"xgb\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_xgb(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"elasticnet\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_elasticnet(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"linear\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_linear(X_train, y_train, X_val, y_val)\n",
    "    elif model_name ==\"baseline-rent\":\n",
    "        avg_price, mae, mse, r2 = baseline_rent(X_val, y_val)\n",
    "    else:\n",
    "        print(\"Model not found. Model_name must be 'lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline_buy' or 'baseline_rent'\")\n",
    "    print(\"Done with train\")\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Data Approach With CTGan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_from_extracted_with_augemented_training_data(\n",
    "    df,\n",
    "    feature_set,\n",
    "    model_name=\"lasso\",\n",
    "    augmentation_epochs=30,\n",
    "    n_added_fake_train_data=1000,\n",
    "):\n",
    "    df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "    X = df.drop(columns=[\"Object_price\"])\n",
    "    y = df[\"Object_price\"]\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = data_split(X, y)\n",
    "    train_extended = pd.concat(\n",
    "        [X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1\n",
    "    )\n",
    "    val = pd.concat(\n",
    "        [X_val.reset_index(drop=True), y_val.reset_index(drop=True)], axis=1\n",
    "    )\n",
    "\n",
    "    df_cttrain = X_train.copy()\n",
    "    df_cttrain[\"Object_price\"] = y_train\n",
    "    df_cttrain = df_cttrain[feature_set]\n",
    "    df_cttrain = df_cttrain.dropna()\n",
    "\n",
    "    #numerical_features = [\"ConstructionYear\", \"Rooms\", \"LivingSpace\", \"Object_price\"]\n",
    "    numerical_features = [\"Rooms\", \"LivingSpace\", \"Object_price\"]\n",
    "\n",
    "    df_cttrain[numerical_features] = df_cttrain[numerical_features].astype(\"int64\")\n",
    "    categorical_features = [\n",
    "        col for col in df_cttrain.columns if col not in numerical_features\n",
    "    ]\n",
    "    ctgan = CTGAN(verbose=True)\n",
    "    ctgan.fit(df_cttrain, categorical_features, epochs=augmentation_epochs)\n",
    "\n",
    "    samples = ctgan.sample(n_added_fake_train_data * 3)\n",
    "    samples[\"Object_price\"] = samples[\"Object_price\"].clip(lower=0)\n",
    "    #samples = samples[samples[\"ConstructionYear\"] < 2023]\n",
    "    samples = samples[samples[\"LivingSpace\"] > 20]\n",
    "    samples = samples[samples[\"Object_price\"] > 120]\n",
    "    samples = samples.head(n_added_fake_train_data)\n",
    "\n",
    "    X_sample_train = samples.drop(columns=[\"Object_price\"])\n",
    "    y_sample_train = samples[\"Object_price\"]\n",
    "    X_train = pd.concat([X_train, X_sample_train])\n",
    "    y_train = pd.concat([y_train, y_sample_train])\n",
    "\n",
    "    train_extended = pd.concat(\n",
    "        [X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1\n",
    "    )\n",
    "    X_train, y_train = preprocess_data(train_extended, feature_set_selected)\n",
    "    X_val, y_val = preprocess_data(val, feature_set_selected)\n",
    "\n",
    "    X_train, X_val = X_train.align(X_val, join=\"outer\", axis=1, fill_value=0)\n",
    "\n",
    "    model, mae, mse, r2, mae_train, mse_train, r2_train = (\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "\n",
    "    if model_name == \"lasso\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_lasso(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"ridge\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_ridge(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_val,\n",
    "            y_val,\n",
    "        )\n",
    "    elif model_name == \"rf\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_rf(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"xgb\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_xgb(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"elasticnet\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_elasticnet(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"linear\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_linear(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"baseline-rent\":\n",
    "        avg_price, mae, mse, r2 = baseline_rent(X_val, y_val)\n",
    "    else:\n",
    "        print(\n",
    "            \"Model not found. Model_name must be 'lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline_buy' or 'baseline_rent'\"\n",
    "        )\n",
    "    print(\"Done with train\")\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution of complete pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "feature_set_high_corr = determineHighCorrCols(df) + [\"ZipCode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with model:  lasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 16:09:09 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b487fad9c031440e85615b1d7916591f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 16:09:14 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 16:09:35 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '14e1059c577644d48cfb0cfc534cac97', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 16:09:40 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 16:10:00 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '075eebe0aa0f4b6f97050e7fc9bd743b', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 16:10:05 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G:  0.9356,Loss D:  0.0132\n",
      "Epoch 2, Loss G:  0.8102,Loss D: -0.0319\n",
      "Epoch 3, Loss G:  0.8747,Loss D: -0.0437\n",
      "Epoch 4, Loss G:  0.8638,Loss D: -0.0921\n",
      "Epoch 5, Loss G:  0.8298,Loss D: -0.1069\n",
      "Epoch 6, Loss G:  0.8150,Loss D: -0.1364\n",
      "Epoch 7, Loss G:  0.8580,Loss D: -0.2187\n",
      "Epoch 8, Loss G:  0.8764,Loss D: -0.1881\n",
      "Epoch 9, Loss G:  0.8820,Loss D: -0.2984\n",
      "Epoch 10, Loss G:  0.7535,Loss D: -0.2945\n",
      "Epoch 11, Loss G:  0.6756,Loss D: -0.3318\n",
      "Epoch 12, Loss G:  0.6349,Loss D: -0.4214\n",
      "Epoch 13, Loss G:  0.5858,Loss D: -0.3835\n",
      "Epoch 14, Loss G:  0.5471,Loss D: -0.4964\n",
      "Epoch 15, Loss G:  0.4915,Loss D: -0.4295\n",
      "Epoch 16, Loss G:  0.3013,Loss D: -0.3521\n",
      "Epoch 17, Loss G:  0.2984,Loss D: -0.3796\n",
      "Epoch 18, Loss G:  0.2261,Loss D: -0.3635\n",
      "Epoch 19, Loss G:  0.2516,Loss D: -0.3230\n",
      "Epoch 20, Loss G:  0.1268,Loss D: -0.3015\n",
      "Epoch 21, Loss G:  0.0283,Loss D: -0.1586\n",
      "Epoch 22, Loss G: -0.1515,Loss D: -0.1327\n",
      "Epoch 23, Loss G: -0.0641,Loss D: -0.1824\n",
      "Epoch 24, Loss G: -0.1546,Loss D: -0.1765\n",
      "Epoch 25, Loss G: -0.0067,Loss D: -0.0930\n",
      "Epoch 26, Loss G: -0.0294,Loss D: -0.0269\n",
      "Epoch 27, Loss G: -0.0872,Loss D:  0.0804\n",
      "Epoch 28, Loss G: -0.0634,Loss D:  0.1103\n",
      "Epoch 29, Loss G: -0.2348,Loss D:  0.1715\n",
      "Epoch 30, Loss G: -0.0961,Loss D:  0.1261\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/13 16:10:36 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/13 16:10:40 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/13 16:10:59 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/13 16:11:07 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with train\n",
      "Done with model:  lasso\n",
      "--------------------------------------------------------\n",
      "Starting with model:  ridge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 16:11:21 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '5a2a18d8132e4a6c819dfc483386d3ef', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 16:11:25 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 16:11:46 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '48a9b64bbd7547e4945ff96cefd88f33', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 16:11:50 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 16:12:11 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '2756ddfcd12e47f2b92758d850ab0021', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 16:12:15 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G:  0.8509,Loss D: -0.0025\n",
      "Epoch 2, Loss G:  0.8220,Loss D: -0.0206\n",
      "Epoch 3, Loss G:  0.8785,Loss D: -0.0566\n",
      "Epoch 4, Loss G:  0.7815,Loss D: -0.0748\n",
      "Epoch 5, Loss G:  0.8351,Loss D: -0.1210\n",
      "Epoch 6, Loss G:  0.8038,Loss D: -0.1719\n",
      "Epoch 7, Loss G:  0.7974,Loss D: -0.1782\n",
      "Epoch 8, Loss G:  0.8252,Loss D: -0.2373\n",
      "Epoch 9, Loss G:  0.7262,Loss D: -0.2453\n",
      "Epoch 10, Loss G:  0.7289,Loss D: -0.2839\n",
      "Epoch 11, Loss G:  0.6088,Loss D: -0.3332\n",
      "Epoch 12, Loss G:  0.6300,Loss D: -0.3947\n",
      "Epoch 13, Loss G:  0.5534,Loss D: -0.3832\n",
      "Epoch 14, Loss G:  0.4644,Loss D: -0.3685\n",
      "Epoch 15, Loss G:  0.3460,Loss D: -0.3976\n",
      "Epoch 16, Loss G:  0.2308,Loss D: -0.3396\n",
      "Epoch 17, Loss G:  0.2434,Loss D: -0.4494\n",
      "Epoch 18, Loss G:  0.1732,Loss D: -0.2264\n",
      "Epoch 19, Loss G:  0.0381,Loss D: -0.2638\n",
      "Epoch 20, Loss G: -0.0770,Loss D: -0.1496\n",
      "Epoch 21, Loss G: -0.1270,Loss D: -0.1717\n",
      "Epoch 22, Loss G: -0.1917,Loss D: -0.3175\n",
      "Epoch 23, Loss G: -0.1998,Loss D: -0.1860\n",
      "Epoch 24, Loss G: -0.1569,Loss D: -0.0326\n",
      "Epoch 25, Loss G: -0.1379,Loss D: -0.0261\n",
      "Epoch 26, Loss G: -0.2250,Loss D:  0.0590\n",
      "Epoch 27, Loss G: -0.1621,Loss D: -0.0996\n",
      "Epoch 28, Loss G: -0.2980,Loss D: -0.0344\n",
      "Epoch 29, Loss G: -0.1591,Loss D:  0.1565\n",
      "Epoch 30, Loss G: -0.2196,Loss D: -0.0301\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/13 16:12:46 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/13 16:12:50 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/13 16:13:09 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/13 16:13:17 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with train\n",
      "Done with model:  ridge\n",
      "--------------------------------------------------------\n",
      "Starting with model:  rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 16:13:31 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '72d0ee62b6b3496497a1195d1e3f3c57', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 16:13:35 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 16:13:56 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '121d0de08c684127996c0d06d0e6af9d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 16:14:00 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 16:14:21 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '352297f5183f43fa80bf86b0dfd5c366', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 16:14:25 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss G:  0.7787,Loss D:  0.0006\n",
      "Epoch 2, Loss G:  0.7542,Loss D: -0.0000\n",
      "Epoch 3, Loss G:  0.7276,Loss D: -0.0502\n",
      "Epoch 4, Loss G:  0.8083,Loss D: -0.1022\n",
      "Epoch 5, Loss G:  0.7509,Loss D: -0.1024\n",
      "Epoch 6, Loss G:  0.7972,Loss D: -0.1581\n",
      "Epoch 7, Loss G:  0.7280,Loss D: -0.1341\n",
      "Epoch 8, Loss G:  0.6097,Loss D: -0.2344\n",
      "Epoch 9, Loss G:  0.7093,Loss D: -0.2888\n",
      "Epoch 10, Loss G:  0.5670,Loss D: -0.2660\n",
      "Epoch 11, Loss G:  0.5979,Loss D: -0.2782\n",
      "Epoch 12, Loss G:  0.5079,Loss D: -0.3314\n",
      "Epoch 13, Loss G:  0.4540,Loss D: -0.3686\n",
      "Epoch 14, Loss G:  0.3658,Loss D: -0.3501\n",
      "Epoch 15, Loss G:  0.2919,Loss D: -0.4151\n",
      "Epoch 16, Loss G:  0.1176,Loss D: -0.2503\n",
      "Epoch 17, Loss G:  0.0171,Loss D: -0.3003\n",
      "Epoch 18, Loss G: -0.0389,Loss D: -0.1905\n",
      "Epoch 19, Loss G: -0.1591,Loss D: -0.1795\n",
      "Epoch 20, Loss G: -0.2679,Loss D: -0.1927\n",
      "Epoch 21, Loss G: -0.2223,Loss D: -0.0701\n",
      "Epoch 22, Loss G: -0.3629,Loss D: -0.1813\n",
      "Epoch 23, Loss G: -0.3770,Loss D:  0.0109\n",
      "Epoch 24, Loss G: -0.4688,Loss D: -0.0879\n",
      "Epoch 25, Loss G: -0.4757,Loss D: -0.0837\n",
      "Epoch 26, Loss G: -0.4906,Loss D: -0.0410\n",
      "Epoch 27, Loss G: -0.6709,Loss D:  0.0816\n",
      "Epoch 28, Loss G: -0.4260,Loss D: -0.0562\n",
      "Epoch 29, Loss G: -0.5610,Loss D:  0.0254\n",
      "Epoch 30, Loss G: -0.5001,Loss D:  0.0362\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/13 16:14:57 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/13 16:15:02 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/13 16:15:20 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/13 16:15:22 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with train\n",
      "Done with model:  rf\n",
      "--------------------------------------------------------\n",
      "Starting with model:  xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 16:15:42 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '91c06fd22eb3437680739a8145c143b7', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 16:15:46 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\rdt\\transformers\\base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "2023/07/13 16:16:07 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '02e942fad6b34555a9d6c58aaa5f155b', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2023/07/13 16:16:11 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"wue-rent-selected-features-aug\")\n",
    "model_names = ['lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline-rent']\n",
    "\n",
    "feature_set_selected = [\n",
    "    \"Object_price\",\n",
    "    \"LivingSpace\",\n",
    "    \"ZipCode\", \n",
    "    \"Rooms\",\n",
    "    \"altbau_(bis_1945)\",\n",
    "    \"balkon\",\n",
    "    \"barriefrei\",\n",
    "    \"dachgeschoss\",\n",
    "    \"einbaukueche\",\n",
    "    \"neubau\",\n",
    "    \"parkett\",\n",
    "    \"stellplatz\", \n",
    "    \"bad/wc_getrennt\",\n",
    "    \"personenaufzug\",\n",
    "    \"garten\",\n",
    "    \"garage\",\n",
    "    \"renoviert\", \n",
    "    \"terrasse\", \n",
    "    \"wanne\", \n",
    "    \"zentralheizung\",\n",
    "    \"abstellraum\",\n",
    "    \"ferne\",\n",
    "    \"fussbodenheizung\",\n",
    "    \"gartennutzung\",\n",
    "    \"kelleranteil\"\n",
    "]\n",
    "\n",
    "df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "    \n",
    "# for model_name in model_names:\n",
    "#     df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "#     print(\"Starting with model: \", model_name)\n",
    "#     pipeline_from_extracted(df, model_name=model_name, feature_set=feature_set_selected)\n",
    "#     print(\"Done with model: \", model_name)\n",
    "#     print(\"--------------------------------------------------------\")\n",
    "\n",
    "for model_name in model_names:\n",
    "    df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "    print(\"Starting with model: \", model_name)\n",
    "    complete_from_extracted_with_augemented_training_data(df, model_name=model_name, feature_set=feature_set_selected, n_added_fake_train_data=1000)\n",
    "    print(\"Done with model: \", model_name)\n",
    "    print(\"--------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "# complete_from_extracted_with_augemented_training_data(df, feature_set_selected, model_name=\"lasso\", augmentation_epochs=20, n_added_fake_train_data=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all runs and make result plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.search_runs(experiment_names=[\"wue-rent-high-corr-features-comparison\"])\n",
    "runs = mlflow.search_runs(experiment_names=[\"wue-rent-high-corr-features-comparison\"])\n",
    "mae_runs = runs[runs[\"metrics.mae\"].notnull()]\n",
    "\n",
    "print(mae_runs)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(mae_runs[\"tags.mlflow.runName\"], mae_runs[\"metrics.mae\"], color='lightblue')\n",
    "ax.set_xlabel(\"Model\", fontsize=14)\n",
    "ax.set_ylabel(\"MAE\", fontsize=14)\n",
    "ax.set_title(\"MAE: wue-rent-combined-high-corr-features\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
