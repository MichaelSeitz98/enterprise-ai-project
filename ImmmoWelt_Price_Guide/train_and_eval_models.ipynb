{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd#\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression, ElasticNet\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_0407.xlsx')\n",
    "# profile = ProfileReport(df, title=\"Flats -  Würzburg - Rent - Overview\", explorative=True)\n",
    "# profile.to_file(\"eda-wue-rent-all.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data (df): \n",
    "    df.replace('\"\"', np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    df[\"LivingSpace\"] = pd.to_numeric(df[\"LivingSpace\"], errors=\"coerce\")\n",
    "    df[\"Rooms\"] = pd.to_numeric(df[\"Rooms\"], errors=\"coerce\")\n",
    "    df.dropna(subset=['ConstructionYear'], inplace=True)\n",
    "    df.dropna(subset=['Object_price'], inplace=True)\n",
    "    df.dropna(subset=['Rooms'], inplace=True)\n",
    "    df.dropna(subset=['LivingSpace'], inplace=True)\n",
    "    df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    df['ZipCode']= df['ZipCode'].astype(str)\n",
    "    df['LivingSpace']= df['LivingSpace'].astype(float)\n",
    "    df = df.reindex()\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # keep only the most promising features\n",
    "    # sns.heatmap(df.corr(), cmap=\"RdBu\")\n",
    "    important_num_cols = list(df.corr()[\"Object_price\"][(df.corr()[\"Object_price\"]>0.20) | (df.corr()[\"Object_price\"]<-0.20)].index)\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    important_cols = important_num_cols + cat_cols\n",
    "    df = df[important_cols]\n",
    "\n",
    "    # one-hot encoding\n",
    "    y = df['Object_price']\n",
    "    X = df.drop('Object_price', axis=1)\n",
    "    X = pd.get_dummies(X, columns=cat_cols)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(X, y, train_size=0.8, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                  train_size=train_size, \n",
    "                                                  random_state = random_state)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                  train_size=train_size, \n",
    "                                                  random_state = random_state)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Evaluation and Logging Of Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_avg_rental_prices():\n",
    "    url = \"https://www.wohnungsboerse.net/mietspiegel-Wuerzburg/2772\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    script_tag = soup.find(\"script\", string=lambda text: \"pdfData\" in text)\n",
    "    rental_price = 0\n",
    "    if script_tag:\n",
    "        script_content = script_tag.string\n",
    "        start_index = script_content.find(\"avg_rent_price: \") + len(\"avg_rent_price: '\")\n",
    "        end_index = script_content.find(\"',\", start_index)\n",
    "        rental_price = script_content[start_index:end_index]\n",
    "        rental_price = (\n",
    "            rental_price.replace(\"€/m2\", \"\").replace(\".\", \"\").replace(\",\", \".\")\n",
    "        )\n",
    "        rental_price = rental_price.strip()\n",
    "        rental_price = float(rental_price)\n",
    "        print(f\"Extrcated rental price per square meter via scraper: {rental_price}\")\n",
    "    else:\n",
    "        print(\"The script tag containing the rental price was not found.\")\n",
    "    return rental_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_avg_buy_prices():\n",
    "    url = \"https://www.wohnungsboerse.net/immobilienpreise-Wuerzburg/2772\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    p_element = soup.find(\"p\", class_=\"mb-8\")\n",
    "    buy_price = 0\n",
    "    if p_element:\n",
    "        pattern = r\"\\d{1,3}(?:\\.\\d{3})*(?:,\\d{2})?€/m²\"\n",
    "        match = re.search(pattern, p_element.text)\n",
    "        if match:\n",
    "            buy_price = match.group()\n",
    "            buy_price = buy_price.replace(\"€/m²\", \"\").replace(\".\", \"\").replace(\",\", \".\")\n",
    "            print(f\"Extrcated buy price per square meter via scraper: {buy_price}\")\n",
    "        else:\n",
    "            print(\"Price not found\")\n",
    "    else:\n",
    "        print(\"The element ontaining the buy price was not found.\")\n",
    "    return buy_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_rent(val_X, val_y, runname=\"baseline_rent\"):\n",
    "    avg_price_per_sqm_rent = scrape_avg_rental_prices()\n",
    "    print(f\"Average rental price per sqm: {avg_price_per_sqm_rent}\")\n",
    "    baseline_preds = val_X['LivingSpace'] * avg_price_per_sqm_rent\n",
    "    baseline_mae = mean_absolute_error(val_y, baseline_preds)\n",
    "    baseline_r2 = r2_score(val_y, baseline_preds)\n",
    "    baseline_mse = mean_squared_error(val_y, baseline_preds)\n",
    "\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        mlflow.log_metric(\"mse\", baseline_mse)\n",
    "        mlflow.log_metric(\"mae\", baseline_mae)\n",
    "        mlflow.log_metric(\"r2\", baseline_r2)\n",
    "\n",
    "    print(f\"Baseline Mae: {baseline_mae}\")\n",
    "    print(f\"Baseline MSE: {baseline_mse}\")    \n",
    "    print(f\"Baseline R2 Score: {baseline_r2}\")\n",
    "    return avg_price_per_sqm_rent, baseline_mae, baseline_mse, baseline_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_buy(X_val, y_val, runname=\"baseline_buy\"):\n",
    "    avg_price_per_sqm_buy = scrape_avg_buy_prices()\n",
    "    print(f\"Average rental price per sqm: {avg_price_per_sqm_buy}\")\n",
    "    \n",
    "    baseline_preds = X_val['LivingSpace'] * avg_price_per_sqm_buy\n",
    "    baseline_mae = mean_absolute_error(y_val, baseline_preds)\n",
    "    baseline_r2 = r2_score(y_val, baseline_preds)\n",
    "    baseline_mse = mean_squared_error(y_val, baseline_preds)\n",
    "\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        mlflow.log_metric(\"mse\", baseline_mse)\n",
    "        mlflow.log_metric(\"mae\", baseline_mae)\n",
    "        mlflow.log_metric(\"r2\", baseline_r2)\n",
    "\n",
    "    print(f\"Baseline Mae: {baseline_mae}\")\n",
    "    print(f\"Baseline MSE: {baseline_mse}\")    \n",
    "    print(f\"Baseline R2 Score: {baseline_r2}\")\n",
    "\n",
    "    return avg_price_per_sqm_buy, baseline_mae, baseline_mse, baseline_r2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_linear(X_train, y_train, X_val, y_val, runname =\"linear-regression\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        \n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"mae\", mae_train)\n",
    "        mlflow.log_metric(\"mse\", mse_train)\n",
    "        mlflow.log_metric(\"r2\", r2_train)\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_lasso(X_train, y_train, X_val, y_val, runname =\"lasso-regression\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = Lasso()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        \n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"mae\", mae_train)\n",
    "        mlflow.log_metric(\"mse\", mse_train)\n",
    "        mlflow.log_metric(\"r2\", r2_train)\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_ridge(X_train, y_train, X_val, y_val, runname =\"ridge-regression\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = Ridge()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        \n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        mlflow.log_metric(\"mae\", mae_train)\n",
    "        mlflow.log_metric(\"mse\", mse_train)\n",
    "        mlflow.log_metric(\"r2\", r2_train)\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_rf(X_train, y_train, X_val, y_val, n_estimators=50, random_state=0, run_name=\"random-forest\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        model = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state)\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        preds= model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_xgb(X_train, y_train, X_val, y_val, run_name=\"xgb\", early_stopping_rounds=30, max_depth=6, n_estimators=1000):\n",
    "    mlflow.xgboost.autolog()\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        model = xgb.XGBRegressor(eval_metric=['rmse', 'mae'], early_stopping_rounds=early_stopping_rounds, random_state=42, max_depth=max_depth, n_estimators=n_estimators)\n",
    "        mlflow.log_param(\"early_stopping_rounds\", early_stopping_rounds)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        model.fit(X=X_train, \n",
    "                  y=y_train,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  verbose=True\n",
    "        )\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        preds= model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)        \n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_elasticnet(X_train, y_train, X_val, y_val, runname=\"elasticNet\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        model = ElasticNet()\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_train = model.predict(X_train)\n",
    "        mae_train = mean_absolute_error(y_train, pred_train)\n",
    "        mse_train = mean_squared_error(y_train, pred_train)\n",
    "        r2_train = r2_score(y_train, pred_train)\n",
    "        preds= model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"mse\", mse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mse_train)\n",
    "        mlflow.log_metric(\"r2_train\", r2_train)\n",
    "        return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_from_extracted(df, model_name=\"lasso\"):\n",
    "    X, y = preprocess_data(df)\n",
    "    print(\"Done with preprocessing\")\n",
    "    X_train, y_train, X_val, y_val, test_X, test_y = data_split(X,y)\n",
    "    print(\"Done with data split\")\n",
    "\n",
    "    model, mae, mse, r2, mae_train, mse_train, r2_train = None, None, None, None, None, None, None\n",
    "\n",
    "    if model_name == \"lasso\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_lasso(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"ridge\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_ridge(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"rf\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_rf(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"xgb\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_xgb(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"elasticnet\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_elasticnet(X_train, y_train, X_val, y_val)\n",
    "    elif model_name == \"linear\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_linear(X_train, train_y, X_val, val_y)\n",
    "    elif model_name ==\"baseline-rent\":\n",
    "        avg_price, mae, mse, r2 = baseline_rent(X_val, val_y)\n",
    "    else:\n",
    "        print(\"Model not found. Model_name must be 'lasso', 'ridge', 'rf', 'xgb', 'elasticnet' or 'linear'\")\n",
    "    print(\"Done with train\")\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Different Models On Same Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/11 19:17:57 INFO mlflow.tracking.fluent: Experiment with name 'model_comparison' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with model:  lasso\n",
      "Done with preprocessing\n",
      "Done with data split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michi\\AppData\\Local\\Temp\\ipykernel_11488\\1051100805.py:18: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  important_num_cols = list(df.corr()[\"Object_price\"][(df.corr()[\"Object_price\"]>0.20) | (df.corr()[\"Object_price\"]<-0.20)].index)\n",
      "2023/07/11 19:18:04 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [88, 28]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m model_name \u001b[39min\u001b[39;00m model_names:\n\u001b[0;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStarting with model: \u001b[39m\u001b[39m\"\u001b[39m, model_name)\n\u001b[1;32m----> 7\u001b[0m     pipeline_from_extracted(df, model_name\u001b[39m=\u001b[39;49mmodel_name)\n",
      "Cell \u001b[1;32mIn[22], line 8\u001b[0m, in \u001b[0;36mpipeline_from_extracted\u001b[1;34m(df, model_name)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone with data split\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[39mif\u001b[39;00m model_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlasso\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m----> 8\u001b[0m     model, mae, mse, r2, mae_train, mse_train, r2_train \u001b[39m=\u001b[39m train_and_eval_lasso(train_X, train_y, val_X, val_y)\n\u001b[0;32m      9\u001b[0m \u001b[39melif\u001b[39;00m model_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mridge\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     10\u001b[0m     model, mae, mse, r2, mae_train, mse_train, r2_train \u001b[39m=\u001b[39m train_and_eval_ridge(train_X, train_y, val_X, val_y)\n",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m, in \u001b[0;36mtrain_and_eval_lasso\u001b[1;34m(X_train, y_train, X_val, y_val, runname)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m mlflow\u001b[39m.\u001b[39mstart_run(run_name\u001b[39m=\u001b[39mrunname):\n\u001b[0;32m      4\u001b[0m     model \u001b[39m=\u001b[39m Lasso()\n\u001b[1;32m----> 5\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      7\u001b[0m     pred_train \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_train)\n\u001b[0;32m      8\u001b[0m     mae_train \u001b[39m=\u001b[39m mean_absolute_error(y_train, pred_train)\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:554\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    552\u001b[0m     patch_function\u001b[39m.\u001b[39mcall(call_original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    553\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 554\u001b[0m     patch_function(call_original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    556\u001b[0m session\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msucceeded\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    558\u001b[0m try_log_autologging_event(\n\u001b[0;32m    559\u001b[0m     AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_patch_function_success,\n\u001b[0;32m    560\u001b[0m     session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    564\u001b[0m     kwargs,\n\u001b[0;32m    565\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:254\u001b[0m, in \u001b[0;36mwith_managed_run.<locals>.patch_with_managed_run\u001b[1;34m(original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m     managed_run \u001b[39m=\u001b[39m create_managed_run()\n\u001b[0;32m    253\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 254\u001b[0m     result \u001b[39m=\u001b[39m patch_function(original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    255\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m):\n\u001b[0;32m    256\u001b[0m     \u001b[39m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[39;00m\n\u001b[0;32m    257\u001b[0m     \u001b[39m# that runs are terminated if a user prematurely interrupts training execution\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     \u001b[39m# (e.g. via sigint / ctrl-c)\u001b[39;00m\n\u001b[0;32m    259\u001b[0m     \u001b[39mif\u001b[39;00m managed_run:\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:1612\u001b[0m, in \u001b[0;36m_autolog.<locals>.patched_fit\u001b[1;34m(fit_impl, allow_children_patch, original, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1608\u001b[0m \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mshould_log():\n\u001b[0;32m   1609\u001b[0m     \u001b[39m# In `fit_mlflow` call, it will also call metric API for computing training metrics\u001b[39;00m\n\u001b[0;32m   1610\u001b[0m     \u001b[39m# so we need temporarily disable the post_training_metrics patching.\u001b[39;00m\n\u001b[0;32m   1611\u001b[0m     \u001b[39mwith\u001b[39;00m _AUTOLOGGING_METRICS_MANAGER\u001b[39m.\u001b[39mdisable_log_post_training_metrics():\n\u001b[1;32m-> 1612\u001b[0m         result \u001b[39m=\u001b[39m fit_impl(original, \u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1613\u001b[0m     \u001b[39mif\u001b[39;00m should_log_post_training_metrics:\n\u001b[0;32m   1614\u001b[0m         _AUTOLOGGING_METRICS_MANAGER\u001b[39m.\u001b[39mregister_model(\n\u001b[0;32m   1615\u001b[0m             \u001b[39mself\u001b[39m, mlflow\u001b[39m.\u001b[39mactive_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[0;32m   1616\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:1385\u001b[0m, in \u001b[0;36m_autolog.<locals>.fit_mlflow\u001b[1;34m(original, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1383\u001b[0m _log_pretraining_metadata(autologging_client, \u001b[39mself\u001b[39m, X, y_true)\n\u001b[0;32m   1384\u001b[0m params_logging_future \u001b[39m=\u001b[39m autologging_client\u001b[39m.\u001b[39mflush(synchronous\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1385\u001b[0m fit_output \u001b[39m=\u001b[39m original(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1386\u001b[0m _log_posttraining_metadata(autologging_client, \u001b[39mself\u001b[39m, X, y_true, sample_weight)\n\u001b[0;32m   1387\u001b[0m autologging_client\u001b[39m.\u001b[39mflush(synchronous\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:535\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[1;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[0;32m    532\u001b[0m         original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39m_og_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_og_kwargs)\n\u001b[0;32m    533\u001b[0m         \u001b[39mreturn\u001b[39;00m original_result\n\u001b[1;32m--> 535\u001b[0m \u001b[39mreturn\u001b[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:470\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[1;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    463\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_start,\n\u001b[0;32m    464\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    468\u001b[0m         og_kwargs,\n\u001b[0;32m    469\u001b[0m     )\n\u001b[1;32m--> 470\u001b[0m     original_fn_result \u001b[39m=\u001b[39m original_fn(\u001b[39m*\u001b[39;49mog_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mog_kwargs)\n\u001b[0;32m    472\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    473\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_success,\n\u001b[0;32m    474\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    478\u001b[0m         og_kwargs,\n\u001b[0;32m    479\u001b[0m     )\n\u001b[0;32m    480\u001b[0m     \u001b[39mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:532\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[1;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[39m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[39m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \u001b[39m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[39m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[39mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[0;32m    529\u001b[0m     disable_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    530\u001b[0m     reroute_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    531\u001b[0m ):\n\u001b[1;32m--> 532\u001b[0m     original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39;49m_og_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_og_kwargs)\n\u001b[0;32m    533\u001b[0m     \u001b[39mreturn\u001b[39;00m original_result\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:908\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[0;32m    907\u001b[0m     X_copied \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy_X \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_intercept\n\u001b[1;32m--> 908\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    909\u001b[0m         X,\n\u001b[0;32m    910\u001b[0m         y,\n\u001b[0;32m    911\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    912\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mF\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    913\u001b[0m         dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[0;32m    914\u001b[0m         copy\u001b[39m=\u001b[39;49mX_copied,\n\u001b[0;32m    915\u001b[0m         multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    916\u001b[0m         y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    917\u001b[0m     )\n\u001b[0;32m    918\u001b[0m     y \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    919\u001b[0m         y, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    920\u001b[0m     )\n\u001b[0;32m    922\u001b[0m n_samples, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\sklearn\\utils\\validation.py:1124\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m-> 1124\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1126\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [88, 28]"
     ]
    }
   ],
   "source": [
    "model_names = ['lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear']\n",
    "mlflow.set_experiment(\"model_comparison\")\n",
    "\n",
    "df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_0407.xlsx')\n",
    "for model_name in model_names:\n",
    "    print(\"Starting with model: \", model_name)\n",
    "    pipeline_from_extracted(df, model_name=model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
