{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\numba\\core\\decorators.py:262: NumbaDeprecationWarning: \u001b[1mnumba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\u001b[0m\n",
      "  warnings.warn(msg, NumbaDeprecationWarning)\n",
      "C:\\Users\\michi\\AppData\\Roaming\\Python\\Python38\\site-packages\\visions\\backends\\shared\\nan_handling.py:51: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def hasna(x: np.ndarray) -> bool:\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "from preprocessing_methods import *\n",
    "from apify_scrap import *\n",
    "import datetime\n",
    "import mlflow\n",
    "import pickle\n",
    "from model_functions import *\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImmoWeltUrls(Enum):\n",
    "    BUY_FLATS_WUE_10km = \"https://www.immowelt.de/liste/wuerzburg/wohnungen/kaufen?d=true&r=10&sd=DESC&sf=RELEVANCE&sp=1\"\n",
    "    # add price range to avoid \"consulting\"-offers without named price\n",
    "    BUY_HOUSES_WUE_10km = \"https://www.immowelt.de/liste/wuerzburg/haeuser/kaufen?d=true&pma=10000000&pmi=10&r=10&sd=DESC&sf=RELEVANCE&sp=1\"\n",
    "    RENT_FLATS_WUE_10km = \"https://www.immowelt.de/liste/wuerzburg/wohnungen/mieten?d=true&r=10&sd=DESC&sf=RELEVANCE&sp=1\"\n",
    "    RENT_HOUSES_WUE_10km = \"https://www.immowelt.de/liste/wuerzburg/haeuser/mieten?d=true&r=10&sd=DESC&sf=RELEVANCE&sp=1\"\n",
    "\n",
    "\n",
    "def getFeatureSetApp():\n",
    "    return [\n",
    "        \"Object_price\",\n",
    "        \"LivingSpace\",\n",
    "        \"ZipCode\",\n",
    "        \"Rooms\",\n",
    "        \"altbau_(bis_1945)\",\n",
    "        \"balkon\",\n",
    "        \"barriefrei\",\n",
    "        \"dachgeschoss\",\n",
    "        \"einbaukueche\",\n",
    "        \"neubau\",\n",
    "        \"parkett\",\n",
    "        \"stellplatz\",\n",
    "        \"bad/wc_getrennt\",\n",
    "        \"personenaufzug\",\n",
    "        \"garten\",\n",
    "        \"garage\",\n",
    "        \"renoviert\",\n",
    "        \"terrasse\",\n",
    "        \"wanne\",\n",
    "        \"zentralheizung\",\n",
    "        \"abstellraum\",\n",
    "        \"ferne\",\n",
    "        \"fussbodenheizung\",\n",
    "        \"gartennutzung\",\n",
    "        \"kelleranteil\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.immowelt.de/liste/wuerzburg/wohnungen/mieten?d=true&r=10&sd=DESC&sf=RELEVANCE&sp=1\n",
      "Retraining data successfully scraped.\n",
      "Retraining data successfully written to excel.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Rooms'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Rooms'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 164\u001b[0m\n\u001b[0;32m    161\u001b[0m         mlflow\u001b[39m.\u001b[39mend_run()\n\u001b[0;32m    162\u001b[0m         \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 164\u001b[0m trigger_retraining_with_added_data(url\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mhttps://www.immowelt.de/liste/wuerzburg/wohnungen/mieten?d=true&r=10&sd=DESC&sf=RELEVANCE&sp=1\u001b[39;49m\u001b[39m\"\u001b[39;49m, feature_set \u001b[39m=\u001b[39;49m getFeatureSetApp())\n",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m, in \u001b[0;36mtrigger_retraining_with_added_data\u001b[1;34m(url, feature_set, limit, model_list)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRetraining data successfully written to excel.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m new_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/retrain_train_data.xlsx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m new_df \u001b[39m=\u001b[39m preprocess_data(new_df)\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone with raw preprocessing.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[39m###################################\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\michi\\enterpriseAI_michi\\enterprise-ai-project\\immowelt_price_guide\\preprocessing_methods.py:12\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     10\u001b[0m df \u001b[39m=\u001b[39m extract_zipcode(df)\n\u001b[0;32m     11\u001b[0m df \u001b[39m=\u001b[39m extract_EstateDistribution_columns(df)\n\u001b[1;32m---> 12\u001b[0m df \u001b[39m=\u001b[39m compute_rooms_if_missing(df)\n\u001b[0;32m     13\u001b[0m df \u001b[39m=\u001b[39m binarize_columns(df, \u001b[39m'\u001b[39m\u001b[39mObject_features\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m df \u001b[39m=\u001b[39m drop_columns(df)\n",
      "File \u001b[1;32mc:\\Users\\michi\\enterpriseAI_michi\\enterprise-ai-project\\immowelt_price_guide\\preprocessing_methods.py:20\u001b[0m, in \u001b[0;36mcompute_rooms_if_missing\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_rooms_if_missing\u001b[39m(df):\n\u001b[0;32m     19\u001b[0m     df[\u001b[39m\"\u001b[39m\u001b[39mLivingSpace\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_numeric(df[\u001b[39m\"\u001b[39m\u001b[39mLivingSpace\u001b[39m\u001b[39m\"\u001b[39m], errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcoerce\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m     df[\u001b[39m\"\u001b[39m\u001b[39mRooms\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_numeric(df[\u001b[39m\"\u001b[39;49m\u001b[39mRooms\u001b[39;49m\u001b[39m\"\u001b[39;49m], errors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcoerce\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m     df\u001b[39m.\u001b[39mdropna(subset\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mLivingSpace\u001b[39m\u001b[39m\"\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m     df[\u001b[39m\"\u001b[39m\u001b[39mRooms\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mfillna((df[\u001b[39m\"\u001b[39m\u001b[39mLivingSpace\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m/\u001b[39m \u001b[39m15\u001b[39m)\u001b[39m.\u001b[39mround()\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m), inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Rooms'"
     ]
    }
   ],
   "source": [
    "def trigger_retraining_with_added_data(\n",
    "    url,\n",
    "    feature_set,\n",
    "    limit=3,\n",
    "    model_list=[\"xgb\", \"lasso\", \"ridge\", \"rf\", \"elasticnet\", \"linear\"],\n",
    "):\n",
    "    print(url)\n",
    "    #retrain_data = get_dataset_items(url, limit)\n",
    "    print(\"Retraining data successfully scraped.\")\n",
    "    # write_data_to_excel(retrain_data, \"data/retrain_train_data.xlsx\")\n",
    "    print(\"Retraining data successfully written to excel.\")\n",
    "\n",
    "    \n",
    "    new_df = pd.read_excel(r\"data/retrain_train_data.xlsx\")\n",
    "    new_df = preprocess_data(new_df)\n",
    "    print(\"Done with raw preprocessing.\")\n",
    "\n",
    "\n",
    "    #############################FELIX##################################\n",
    "    \n",
    "    new_df.to_excel(\"data/retrain_train_data_preprocessed.xlsx\", index=False)\n",
    "    df_new = preprocess_data_for_model(new_df, feature_set)\n",
    "\n",
    "    X_train_recent = pd.read_excel(\"data/X_train_recent.xlsx\")\n",
    "    y_train_recent = pd.read_excel(\"data/y_train_recent.xlsx\")\n",
    "    X_val = pd.read_excel(\"data/X_val.xlsx\")\n",
    "    y_val = pd.read_excel(\"data/y_val.xlsx\")\n",
    "    X_test = pd.read_excel(\"data/X_test.xlsx\")\n",
    "    y_test = pd.read_excel(\"data/X_test.xlsx\")\n",
    "\n",
    "    train_recent = pd.concat([X_train_recent, y_train_recent], axis=1)\n",
    "    train_recent = pd.concat([train_recent, df_new], axis=0)\n",
    "    train_recent = train_recent.reset_index(drop=True)\n",
    "    train_recent = train_recent.drop_duplicates()\n",
    "    X_train_recent = train_recent.drop([\"Object_price\"], axis=1)\n",
    "    y_train_recent = train_recent[\"Object_price\"]\n",
    "    X_train_recent.to_excel(\"data/X_train_recent.xlsx\", index=False)\n",
    "    y_train_recent.to_excel(\"data/y_train_recent.xlsx\", index=False)\n",
    "    print(\"Retraining data successfully added to training data.\")\n",
    "\n",
    "    now = datetime.now()\n",
    "    mlflow_set_experiment(f\"retrain-{now.strftime('%m-%d-%H-%M-%S')}\")\n",
    "\n",
    "    \n",
    "    results = pd.DataFrame(\n",
    "        columns=[\"model\", \"mae\", \"mse\", \"r2\", \"r2_test\", \"mae_test\", \"mse_test\"]\n",
    "    )\n",
    "\n",
    "\n",
    "    model = None\n",
    "\n",
    "    for model_name in model_list:\n",
    "        \n",
    "        if model_name == \"xgb\":\n",
    "            mlflow.xgboost.autolog()\n",
    "        else:\n",
    "            mlflow.sklearn.autolog()\n",
    "\n",
    "        if model_name == \"lasso\":\n",
    "            model = train_and_eval_lasso(X_train_recent, y_train_recent, X_val, y_val)\n",
    "        elif model_name == \"ridge\":\n",
    "            model = train_and_eval_ridge(X_train_recent, y_train_recent, X_val, y_val)\n",
    "        elif model_name == \"rf\":\n",
    "            model = train_and_eval_rf(X_train, y_train, X_val, y_val)\n",
    "        elif model_name == \"xgb\":\n",
    "            model = train_and_eval_xgb(X_train, y_train, X_val, y_val)\n",
    "        elif model_name == \"elasticnet\":\n",
    "            model = train_and_eval_elasticnet(X_train, y_train, X_val, y_val)\n",
    "        elif model_name == \"linear\":\n",
    "            model = train_and_eval_linear(X_train, y_train, X_val, y_val)\n",
    "        elif model_name == \"baseline-rent\":\n",
    "            avg_price = baseline_rent(X_val, y_val)\n",
    "            baseline_preds = X_val[\"LivingSpace\"] * avg_price\n",
    "            baseline_preds_test = X_test[\"LivingSpace\"] * avg_price\n",
    "\n",
    "            mae = mean_absolute_error(y_val, baseline_preds)\n",
    "            mse = mean_squared_error(y_val, baseline_preds)\n",
    "            r2 = r2_score(y_val, baseline_preds)\n",
    "            mae_train = mean_absolute_error(y_train, baseline_preds)\n",
    "            mse_train = mean_squared_error(y_train, baseline_preds)\n",
    "            r2_train = r2_score(y_train, baseline_preds)\n",
    "            mae = mean_absolute_error(y_val, baseline_preds)\n",
    "            mse = mean_squared_error(y_val, baseline_preds)\n",
    "            r2 = r2_score(y_val, baseline_preds)\n",
    "            \n",
    "\n",
    "            mlflow.log_metric(\"mae\", mae)\n",
    "            mlflow.log_metric(\"mse\", mse)\n",
    "            mlflow.log_metric(\"r2\", r2)\n",
    "            mlflow.log_metric(\"mae_train\", mae_train)\n",
    "            mlflow.log_metric(\"mse_train\", mse_train)\n",
    "            mlflow.log_metric(\"r2_train\", r2_train)\n",
    "            mlflow.log_metric(\"mae_test\", mean_absolute_error(y_test, baseline_preds_test))\n",
    "            mlflow.log_metric(\"mse_test\", mean_squared_error(y_test, baseline_preds_test))\n",
    "            mlflow.log_metric(\"r2_test\", r2_score(y_test, baseline_preds_test))\n",
    "\n",
    "            mlflow.log_metric(\n",
    "                \"mae_test\", mean_absolute_error(y_test, baseline_preds_test)\n",
    "            )\n",
    "            mlflow.log_metric(\n",
    "                \"mse_test\", mean_squared_error(y_test, baseline_preds_test)\n",
    "            )\n",
    "            mlflow.log_metric(\"r2_test\", r2_score(y_test, baseline_preds_test))\n",
    "            return model, mae, mse, r2, mae_train, mse_train, r2_train\n",
    "        else:\n",
    "            print(\n",
    "                \"Model not found. Model_name must be 'lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline_buy' or 'baseline_rent' or conigure the pipeline manually.\"\n",
    "            )\n",
    "\n",
    "        print(f\"Training {model_name} model done...\")\n",
    "        print(f\"Evaluating and Logging {model_name} model to MLFlow...\")\n",
    "\n",
    "        pred_train = model.predict(X_train_recent)\n",
    "        preds = model.predict(X_val)\n",
    "        pred_test = model.predict(X_test)\n",
    "\n",
    "        mae_train = mean_absolute_error(y_train_recent, pred_train)\n",
    "        mse_train = mean_squared_error(y_train_recent, pred_train)\n",
    "        r2_train = r2_score(y_train_recent, pred_train)\n",
    "\n",
    "        mae_test = mean_absolute_error(y_test, pred_test)\n",
    "        mse_test = mean_squared_error(y_test, pred_test)\n",
    "        r2_test = r2_score(y_test, pred_test)\n",
    "\n",
    "        mae_val = mean_absolute_error(y_val, preds)\n",
    "        mse_val = mean_squared_error(y_val, preds)\n",
    "        r2_val = r2_score(y_val, preds)\n",
    "\n",
    "        mlflow.log_metric(\"mae_test\", mae_test)\n",
    "        mlflow.log_metric(\"mse_test\", mse_test)\n",
    "        mlflow.log_metric(\"r2_test\", r2_test)\n",
    "        mlflow.log_metric(\"mae_train\", mae_train)\n",
    "        mlflow.log_metric(\"mse_train\", mae_train)\n",
    "        mlflow.log_metric(\"r2_train\", mae_train)\n",
    "        mlflow.log_metric(\"mae\", mae_val)\n",
    "        mlflow.log_metric(\"mse\", mse_val)\n",
    "        mlflow.log_metric(\"r2\", r2_val)\n",
    "\n",
    "        results = results.append(\n",
    "            {\n",
    "                \"model\": model_name,\n",
    "                \"mae\": mae_val,\n",
    "                \"mse\": mse_val,\n",
    "                \"r2\": r2_val,\n",
    "                \"mae_test\": mae_test,\n",
    "                \"mse_test\": mse_test,\n",
    "                \"r2_test\": r2_test,\n",
    "                \"mae_train\": mae_train,\n",
    "                \"mse_train\": mse_train,\n",
    "                \"r2_train\": r2_train,\n",
    "            },\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "        with open(f\"models/{model_name}.pkl\", \"wb\") as file:\n",
    "            pickle.dump(model, file)\n",
    "        print(f\"Model {model_name} saved locally as pickle file.\")\n",
    "        print(\"Done with train\")\n",
    "        mlflow.end_run()\n",
    "        return results\n",
    "    \n",
    "trigger_retraining_with_added_data(url=\"https://www.immowelt.de/liste/wuerzburg/wohnungen/mieten?d=true&r=10&sd=DESC&sf=RELEVANCE&sp=1\", feature_set = getFeatureSetApp())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enterpriseai2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
