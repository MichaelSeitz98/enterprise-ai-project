{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\numba\\core\\decorators.py:262: NumbaDeprecationWarning: \u001b[1mnumba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\u001b[0m\n",
      "  warnings.warn(msg, NumbaDeprecationWarning)\n",
      "C:\\Users\\michi\\AppData\\Roaming\\Python\\Python38\\site-packages\\visions\\backends\\shared\\nan_handling.py:51: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def hasna(x: np.ndarray) -> bool:\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import mlflow.pyfunc\n",
    "import xgboost as xgb\n",
    "import mlflow.xgboost\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from model_functions import *\n",
    "import html\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_of_model_from_mlflow(\n",
    "    model_name=\"wue-rent-feature-set-app\", stage=\"production\", progress=gr.Progress()\n",
    "):\n",
    "    progress(0.05, desc=\"Connect to MLFlow\")\n",
    "    time.sleep(0.3)\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    progress(0.10, desc=\"Connect to MLFlow\")\n",
    "    model_name = model_name\n",
    "    stage = stage\n",
    "    progress(0.15, desc=\"Load latest productive model from MLFlow...\")\n",
    "    model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{stage}\")\n",
    "    progress(0.65, desc=\"Extract metrics for overview...\")\n",
    "    time.sleep(0.2)\n",
    "    run_id = model.metadata.run_id\n",
    "    run = client.get_run(run_id)\n",
    "    mae = round(run.data.metrics[\"mae\"], 2)\n",
    "    mse = round(run.data.metrics[\"mse\"], 2)\n",
    "    rmse = round(np.sqrt(mse), 2)\n",
    "    r2 = round(run.data.metrics[\"r2\"], 2)\n",
    "    mae_test = round(run.data.metrics[\"mae_test\"], 2)\n",
    "    mse_test = round(run.data.metrics[\"mse_test\"], 2)\n",
    "    rmse_test = round(np.sqrt(mse_test), 2)\n",
    "\n",
    "    r2_test = round(run.data.metrics[\"r2_test\"], 2)\n",
    "    mae_train = round(run.data.metrics[\"mae_train\"], 2)\n",
    "    mse_train = round(run.data.metrics[\"mse_train\"], 2)\n",
    "    r2_train = round(run.data.metrics[\"r2_train\"], 2)\n",
    "\n",
    "    progress(0.70, desc=\"Extract metrics for overview...\")\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    run_name = run.data.tags[\"mlflow.runName\"]\n",
    "    model_version = run.data.tags[\"mlflow.source.name\"]\n",
    "\n",
    "    # calculate a currrent benchmark\n",
    "    progress(0.75, desc=\"Calculate current benchmark for comparison\")\n",
    "    X_val = pd.read_excel(\"data/X_val.xlsx\")\n",
    "    X_val = X_val.drop(\"Unnamed: 0\", axis=1)\n",
    "    y_val = pd.read_excel(\"data/y_val.xlsx\")\n",
    "    y_val = y_val.drop(\"Unnamed: 0\", axis=1)\n",
    "    X_test = pd.read_excel(\"data/X_test.xlsx\")\n",
    "    X_test = X_test.drop(\"Unnamed: 0\", axis=1)\n",
    "    y_test = pd.read_excel(\"data/y_test.xlsx\")\n",
    "    y_test = y_test.drop(\"Unnamed: 0\", axis=1)\n",
    "    progress(0.80, desc=\"Calculate current benchmark for comparison\")\n",
    "    baseline_mae, baseline_mse, baseline_r2, baseline_rmse = apply_benchmark_rent(\n",
    "        X_val, y_val\n",
    "    )\n",
    "    (\n",
    "        baseline_mae_test,\n",
    "        baseline_mse_test,\n",
    "        baseline_r2_test,\n",
    "        baseline_rmse_test,\n",
    "    ) = apply_benchmark_rent(X_test, y_test)\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"model_name\": [\"Current used model\", \"Baseline\"],\n",
    "        \"mae_val\": [mae, baseline_mae],\n",
    "        \"rmse_val\": [rmse, baseline_rmse],\n",
    "        \"mae_test\": [mae_test, baseline_mae_test],\n",
    "        \"rmse_test\": [rmse_test, baseline_rmse_test],\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(df_metrics)\n",
    "    df_metrics_melted = df_metrics.melt(\n",
    "        id_vars=\"model_name\", var_name=\"metric\", value_name=\"value\"\n",
    "    )\n",
    "\n",
    "    plot = px.bar(\n",
    "        df_metrics_melted,\n",
    "        x=\"metric\",\n",
    "        y=\"value\",\n",
    "        title=\"Current Model vs Benchmark (MAE, RMSE))\",\n",
    "        color=\"model_name\",\n",
    "        barmode=\"group\",\n",
    "        color_discrete_map={\n",
    "            \"Current used\": \"blue\",\n",
    "            \"Baseline\": \"grey\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    progress(0.85, desc=\"Generate plot\")\n",
    "    html_string = f\"\"\"\n",
    "    <h2>Basic Information:</h2>\n",
    "    <ul><li>Model: {model_name}</li><li>Stage: {stage}</li><li>Run Name: {run_name}</li><li>MLFlow Run id: {run_id}</li></ul>\n",
    "    <h2>Metrics:</h2>\n",
    "    <ul><li>MAE Val: {mae}</li><li>MSE Val: {mse}</li><li>R2 Val: {r2}</li></ul>\n",
    "    <ul><li>MAE Test: {mae_test}</li><li>MSE Test: {mse_test}</li><li>R2 Test: {r2_test}</li></ul>\n",
    "    \"\"\"\n",
    "    return html_string, gr.update(value=plot, visible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Tab(label=\"Admin\"):\n",
    "        gr.Markdown(\"## Overview\")\n",
    "        link = \"https://michaelseitz98.github.io/enterprise-ai-project/eda-wue-rent-all.html\"\n",
    "        description = \"Explorative Data Analyis (EDA) for flats to rent in WÃ¼rzburg\"\n",
    "        html_code = f'Explorative Data Analysis of data foundation: <a href=\"{html.escape(link)}\" font-size: 16px;\">{html.escape(description)}</a>'\n",
    "        gr.HTML(html_code)\n",
    "\n",
    "        with gr.Row():\n",
    "            data_overview = gr.HTML(\"\")\n",
    "            plot_overview = gr.Plot(visible=False)\n",
    "\n",
    "        btn = gr.Button(f\"Get stats of productive model\")\n",
    "        btn.click(\n",
    "            get_stats_of_model_from_mlflow, outputs=[data_overview, plot_overview]\n",
    "        )\n",
    "        gr.HTML(\"<hr>\")\n",
    "        gr.Markdown(\"## Retrain models with new data\")\n",
    "        gr.Markdown(\"Select the models you want to retrain.\")\n",
    "\n",
    "        with gr.Row():\n",
    "            xgb = gr.Checkbox(label=\"xgb\")\n",
    "            rf = gr.Checkbox(label=\"rf\")\n",
    "            linear = gr.Checkbox(label=\"linear\", value=True)\n",
    "            lasso = gr.Checkbox(label=\"lasso\")\n",
    "            ridge = gr.Checkbox(label=\"ridge\")\n",
    "            elasticnet = gr.Checkbox(label=\"elasticnet\")\n",
    "            baseline = gr.Checkbox(label=\"baseline-rent\", value=True)\n",
    "\n",
    "        model_list = []\n",
    "        if xgb:\n",
    "            model_list.append(\"xgb\")\n",
    "        if rf:\n",
    "            model_list.append(\"rf\")\n",
    "        if lasso:\n",
    "            model_list.append(\"lasso\")\n",
    "        if ridge:\n",
    "            model_list.append(\"ridge\")\n",
    "        if elasticnet:\n",
    "            model_list.append(\"elasticnet\")\n",
    "        if baseline:\n",
    "            model_list.append(\"baseline-rent\")\n",
    "\n",
    "        limit = gr.Slider(\n",
    "            label=\"Amount of scraped pages of Immowelt\", minimum=1, maximum=10, step=1\n",
    "        )\n",
    "        nachtraining = gr.Button(\"Scrape new data, retrain and evaluate models\")\n",
    "        gr.HTML(\"<hr>\")\n",
    "\n",
    "        df_results = gr.HTML(\"\")\n",
    "        output_plot = gr.Plot(visible=False)\n",
    "\n",
    "        nachtraining.click(\n",
    "            fn=gradio_retrain_with_added_data,\n",
    "            inputs=[xgb, ridge, rf, elasticnet, linear, lasso, baseline, limit],\n",
    "            outputs=[df_results, output_plot],\n",
    "        )\n",
    "\n",
    "demo.queue(concurrency_count=10).launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
