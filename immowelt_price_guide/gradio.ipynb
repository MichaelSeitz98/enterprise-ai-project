{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\numba\\core\\decorators.py:262: NumbaDeprecationWarning: \u001b[1mnumba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\u001b[0m\n",
      "  warnings.warn(msg, NumbaDeprecationWarning)\n",
      "C:\\Users\\michi\\AppData\\Roaming\\Python\\Python38\\site-packages\\visions\\backends\\shared\\nan_handling.py:51: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def hasna(x: np.ndarray) -> bool:\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import mlflow.pyfunc\n",
    "import xgboost as xgb\n",
    "import mlflow.xgboost\n",
    "import pickle\n",
    "from gradio_functions import *\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from model_functions import *\n",
    "import html\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_of_model_from_mlflow(\n",
    "    model_name=\"wue-rent-feature-set-app\", stage=\"production\", progress=gr.Progress()\n",
    "):\n",
    "    progress(0.05, desc=\"Connect to MLFlow\")\n",
    "    time.sleep(0.3)\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    progress(0.10, desc=\"Connect to MLFlow\")\n",
    "    model_name = model_name\n",
    "    stage = stage\n",
    "    progress(0.15, desc=\"Load latest productive model from MLFlow...\")\n",
    "    model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{stage}\")\n",
    "    progress(0.73, desc=\"Prepare metrics for overview...\")\n",
    "    time.sleep(0.2)\n",
    "    run_id = model.metadata.run_id\n",
    "    run = client.get_run(run_id)\n",
    "    mae = round(run.data.metrics[\"mae\"], 2)\n",
    "    mse = round(run.data.metrics[\"mse\"], 2)\n",
    "    r2 = round(run.data.metrics[\"r2\"], 2)\n",
    "    mae_test = round(run.data.metrics[\"mae_test\"], 2)\n",
    "    mse_test = round(run.data.metrics[\"mse_test\"], 2)\n",
    "    r2_test = round(run.data.metrics[\"r2_test\"], 2)\n",
    "    mae_train = round(run.data.metrics[\"mae_train\"], 2)\n",
    "    mse_train = round(run.data.metrics[\"mse_train\"], 2)\n",
    "    r2_train = round(run.data.metrics[\"r2_train\"], 2)\n",
    "\n",
    "    progress(0.80, desc=\"Prepare metrics for overview...\")\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    run_name = run.data.tags[\"mlflow.runName\"]\n",
    "    model_version = run.data.tags[\"mlflow.source.name\"]\n",
    "\n",
    "    # calculate a currrent benchmark\n",
    "    progress(0.65, desc=\"Calculate current benchmark for comparison\")\n",
    "    X_val = pd.read_excel(\"data/X_val.xlsx\")\n",
    "    X_val = X_val.drop(\"Unnamed: 0\", axis=1)\n",
    "    y_val = pd.read_excel(\"data/y_val.xlsx\")\n",
    "    y_val = y_val.drop(\"Unnamed: 0\", axis=1)\n",
    "    baseline_mae, baseline_mse, baseline_r2 = apply_benchmark_rent(X_val, y_val)\n",
    "    progress(0.9, desc=\"Dynamic benchmark calculated.\")\n",
    "\n",
    "    metrics_dict = {\n",
    "        \"model_name\": [model_name, \"baseline-rent\"],\n",
    "        \"mae\": [mae, round(baseline_mae, 2)],\n",
    "        \"mse\": [mse, baseline_mse],\n",
    "        \"r2\": [r2, baseline_r2],\n",
    "    }\n",
    "    df_metrics = pd.DataFrame(metrics_dict, index=[0, 1])\n",
    "    progress(0.95, desc=\"Prepare metrics for overview...\")\n",
    "    html_string = f\"\"\"\n",
    "    <h2>Basic Information:</h2>\n",
    "    <ul><li>Model: {model_name}</li><li>Stage: {stage}</li><li>Run Name: {run_name}</li><li>MLFlow Run id: {run_id}</li></ul>\n",
    "    <h2>Metrics:</h2>\n",
    "    <ul><li>MAE: {mae}</li><li>MSE: {mse}</li><li>R2: {r2}</li></ul>\n",
    "    \"\"\"\n",
    "\n",
    "    progress(0.99, desc=\"Prepare metrics for overview...\")\n",
    "\n",
    "    # Create a bar chart\n",
    "    plot = px.bar(\n",
    "        df_metrics,\n",
    "        x=\"model_name\",\n",
    "        y=\"mae\",\n",
    "        title=\"Modellperformance mit aktuellen Trainingsdaten\",\n",
    "        color=\"mae\",\n",
    "    )\n",
    "\n",
    "    print(html_string)\n",
    "    return html_string, gr.update(value=plot, visible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/16 21:40:28 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - mlflow (current: 2.4.1, required: mlflow==2.4)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrcated rental price per square meter via scraper: 11.21\n",
      "Average rental price per sqm: 11.21\n",
      "\n",
      "    <h2>Basic Information:</h2>\n",
      "    <ul><li>Model: wue-rent-feature-set-app</li><li>Stage: production</li><li>Run Name: rf</li><li>MLFlow Run id: 55f2b0b8200f494687c7b07d48d241df</li></ul>\n",
      "    <h2>Metrics:</h2>\n",
      "    <ul><li>MAE: 194.38</li><li>MSE: 85140.64</li><li>R2: 0.75</li></ul>\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Tab(label=\"Admin\"):\n",
    "        gr.Markdown(\n",
    "            \"## Overview\"\n",
    "        )\n",
    "        link = \"https://michaelseitz98.github.io/enterprise-ai-project/eda-wue-rent-all.html\"\n",
    "        description = \"Explorative Data Analyis for Flats to rent\"\n",
    "        html_code = f'Explorative Data Analysis of data foundation: <a href=\"{html.escape(link)}\" font-size: 16px;\">{html.escape(description)}</a>'\n",
    "        gr.HTML(html_code)\n",
    "        \n",
    "        with gr.Row():\n",
    "            data_overview = gr.HTML(\"\")\n",
    "            plot_overview = gr.Plot(visible=False)\n",
    "        \n",
    "        btn = gr.Button(f\"Get stats of productive model\")\n",
    "        btn.click(get_stats_of_model_from_mlflow, outputs=[data_overview, plot_overview])\n",
    "        gr.HTML(\"<hr>\")\n",
    "        gr.Markdown(\"## Retrain models with new data\")\n",
    "        gr.Markdown(\"Select the models you want to retrain.\")\n",
    "\n",
    "        with gr.Row():\n",
    "            xgb = gr.Checkbox(label=\"xgb\")\n",
    "            rf = gr.Checkbox(label=\"rf\")\n",
    "            linear = gr.Checkbox(label=\"linear\", value=True)\n",
    "            lasso = gr.Checkbox(label=\"lasso\")\n",
    "            ridge = gr.Checkbox(label=\"ridge\")\n",
    "            elasticnet = gr.Checkbox(label=\"elasticnet\")\n",
    "            baseline = gr.Checkbox(label=\"baseline-rent\", value=True)\n",
    "\n",
    "        model_list = []\n",
    "        if xgb:\n",
    "            model_list.append(\"xgb\")\n",
    "        if rf:\n",
    "            model_list.append(\"rf\")\n",
    "        if lasso:\n",
    "            model_list.append(\"lasso\")\n",
    "        if ridge:\n",
    "            model_list.append(\"ridge\")\n",
    "        if elasticnet:\n",
    "            model_list.append(\"elasticnet\")\n",
    "        if baseline:\n",
    "            model_list.append(\"baseline-rent\")\n",
    "\n",
    "        limit = gr.Slider(label=\"Amount of scraped pages of Immowelt\", minimum=1, maximum=10, step=1)\n",
    "        nachtraining = gr.Button(\"Scrape new data, retrain and evaluate models\")\n",
    "        gr.HTML(\"<hr>\")\n",
    "\n",
    "        df_results = gr.HTML(\"\")\n",
    "        output_plot = gr.Plot(visible=False)\n",
    "\n",
    "        nachtraining.click(\n",
    "            fn=gradio_retrain_with_added_data,\n",
    "            inputs=[xgb, ridge, rf, elasticnet, linear, lasso, baseline, limit],\n",
    "            outputs=[df_results, output_plot],\n",
    "        )\n",
    "\n",
    "demo.queue(concurrency_count=10).launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def slowly_reverse(word, progress=gr.Progress()):\n",
    "    progress(0, desc=\"Starting\")\n",
    "    time.sleep(1)\n",
    "    progress(0.5, desc=\"Halfway\")\n",
    "    time.sleep(1)\n",
    "    new_string = \"\"\n",
    "    for letter in progress.tqdm(word, desc=\"Reversing\"):\n",
    "        time.sleep(0.25)\n",
    "        new_string = letter + new_string\n",
    "    return new_string\n",
    "\n",
    "demo = gr.Interface(slowly_reverse, gr.Text(), gr.Text())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.queue(concurrency_count=10).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
