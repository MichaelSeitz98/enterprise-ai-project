{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\numba\\core\\decorators.py:262: NumbaDeprecationWarning: \u001b[1mnumba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\u001b[0m\n",
      "  warnings.warn(msg, NumbaDeprecationWarning)\n",
      "C:\\Users\\michi\\AppData\\Roaming\\Python\\Python38\\site-packages\\visions\\backends\\shared\\nan_handling.py:51: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def hasna(x: np.ndarray) -> bool:\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import mlflow.pyfunc\n",
    "import xgboost as xgb\n",
    "import mlflow.xgboost\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from model_functions import *\n",
    "import html\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_of_model_from_mlflow(\n",
    "    model_name=\"wue-rent-feature-set-app\", stage=\"production\", progress=gr.Progress()\n",
    "):\n",
    "    progress(0.05, desc=\"Connect to MLFlow\")\n",
    "    time.sleep(0.3)\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    progress(0.10, desc=\"Connect to MLFlow\")\n",
    "    model_name = model_name\n",
    "    stage = stage\n",
    "    progress(0.15, desc=\"Load latest productive model from MLFlow...\")\n",
    "    model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{stage}\")\n",
    "    progress(0.65, desc=\"Extract metrics for overview...\")\n",
    "    time.sleep(0.2)\n",
    "    run_id = model.metadata.run_id\n",
    "    run = client.get_run(run_id)\n",
    "    mae = round(run.data.metrics[\"mae\"], 2)\n",
    "    mse = round(run.data.metrics[\"mse\"], 2)\n",
    "    rmse = round(np.sqrt(mse), 2)\n",
    "    r2 = round(run.data.metrics[\"r2\"], 2)\n",
    "    mae_test = round(run.data.metrics[\"mae_test\"], 2)\n",
    "    mse_test = round(run.data.metrics[\"mse_test\"], 2)\n",
    "    rmse_test = round(np.sqrt(mse_test), 2)\n",
    "    \n",
    "\n",
    "\n",
    "    r2_test = round(run.data.metrics[\"r2_test\"], 2)\n",
    "    mae_train = round(run.data.metrics[\"mae_train\"], 2)\n",
    "    mse_train = round(run.data.metrics[\"mse_train\"], 2)\n",
    "    r2_train = round(run.data.metrics[\"r2_train\"], 2)\n",
    "\n",
    "    progress(0.70, desc=\"Extract metrics for overview...\")\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    run_name = run.data.tags[\"mlflow.runName\"]\n",
    "    model_version = run.data.tags[\"mlflow.source.name\"]\n",
    "\n",
    "    # calculate a currrent benchmark\n",
    "    progress(0.75, desc=\"Calculate current benchmark for comparison\")\n",
    "    X_val = pd.read_excel(\"data/X_val.xlsx\")\n",
    "    X_val = X_val.drop(\"Unnamed: 0\", axis=1)\n",
    "    y_val = pd.read_excel(\"data/y_val.xlsx\")\n",
    "    y_val = y_val.drop(\"Unnamed: 0\", axis=1)\n",
    "    X_test = pd.read_excel(\"data/X_test.xlsx\")\n",
    "    X_test = X_test.drop(\"Unnamed: 0\", axis=1)\n",
    "    y_test = pd.read_excel(\"data/y_test.xlsx\")\n",
    "    y_test = y_test.drop(\"Unnamed: 0\", axis=1)\n",
    "    progress(0.80, desc=\"Calculate current benchmark for comparison\")\n",
    "    baseline_mae, baseline_mse, baseline_r2, baseline_rmse = apply_benchmark_rent(X_val, y_val)\n",
    "    baseline_mae_test, baseline_mse_test, baseline_r2_test, baseline_rmse_test= apply_benchmark_rent(X_test, y_test)\n",
    "    \n",
    "\n",
    "    metrics_dict = {\n",
    "        \"model_name\": [\"Current used model\", \"Baseline\"],\n",
    "        \"mae_val\": [mae, baseline_mae],\n",
    "        \"rmse_val\": [rmse, baseline_rmse],\n",
    "        \"mae_test\": [mae_test, baseline_mae_test],\n",
    "        \"rmse_test\": [rmse_test, baseline_rmse_test],\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_dict)\n",
    "    print(df_metrics)\n",
    "    df_metrics_melted = df_metrics.melt(id_vars='model_name', var_name='metric', value_name='value')\n",
    "\n",
    "    plot = px.bar(\n",
    "        df_metrics_melted,\n",
    "        x='metric',\n",
    "        y='value',\n",
    "        title='Current Model vs Benchmark',\n",
    "        color='model_name',\n",
    "        barmode='group',\n",
    "        color_discrete_map={\n",
    "            'My Model': 'blue',\n",
    "            'baseline-rent': 'grey',\n",
    "        },\n",
    "    )\n",
    "\n",
    "    progress(0.85, desc=\"Generate plot\")\n",
    "    html_string = f\"\"\"\n",
    "    <h2>Basic Information:</h2>\n",
    "    <ul><li>Model: {model_name}</li><li>Stage: {stage}</li><li>Run Name: {run_name}</li><li>MLFlow Run id: {run_id}</li></ul>\n",
    "    <h2>Metrics:</h2>\n",
    "    <ul><li>MAE Val: {mae}</li><li>MSE Val: {mse}</li><li>R2 Val: {r2}</li></ul>\n",
    "    <ul><li>MAE Test: {mae_test}</li><li>MSE Test: {mse_test}</li><li>R2 Test: {r2_test}</li></ul>\n",
    "    \"\"\"\n",
    "    return html_string, gr.update(value=plot, visible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in retraining_results.xlsx\n",
    "retraining_results = pd.read_excel('retraining_results.xlsx', index_col=0)\n",
    "\n",
    "# convert to html   \n",
    "retraining_results_html = retraining_results.to_html()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/17 09:57:42 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - mlflow (current: 2.4.1, required: mlflow==2.4)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrcated rental price per square meter via scraper: 11.21\n",
      "Average rental price per sqm: 11.21\n",
      "Baseline Mae: 285.5564\n",
      "Baseline R2: 0.5802888162379594\n",
      "Baseline MSE: 140135.41872988813\n",
      "Extrcated rental price per square meter via scraper: 11.21\n",
      "Average rental price per sqm: 11.21\n",
      "Baseline Mae: 237.83265\n",
      "Baseline R2: 0.6862148619059796\n",
      "Baseline MSE: 92491.55243031321\n",
      "           model_name   mae_val    rmse_val   mae_test   rmse_test\n",
      "0  Current used model  194.3800  291.790000  145.56000  193.340000\n",
      "1            Baseline  285.5564  374.346656  237.83265  304.124238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\gradio\\routes.py\", line 437, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\gradio\\blocks.py\", line 1355, in process_api\n",
      "    data = self.postprocess_data(fn_index, result[\"prediction\"], state)\n",
      "  File \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\gradio\\blocks.py\", line 1289, in postprocess_data\n",
      "    prediction_value = block.postprocess(prediction_value)\n",
      "  File \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\gradio\\components\\dataframe.py\", line 227, in postprocess\n",
      "    dataframe = pd.read_csv(y)\n",
      "  File \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\util\\_decorators.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\util\\_decorators.py\", line 331, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 950, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 605, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1442, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1735, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\pandas\\io\\common.py\", line 856, in get_handle\n",
      "    handle = open(\n",
      "OSError: [Errno 22] Invalid argument: '\\n    <h2>Basic Information:</h2>\\n    <ul><li>Model: wue-rent-feature-set-app</li><li>Stage: production</li><li>Run Name: rf</li><li>MLFlow Run id: 55f2b0b8200f494687c7b07d48d241df</li></ul>\\n    <h2>Metrics:</h2>\\n    <ul><li>MAE Val: 194.38</li><li>MSE Val: 85140.64</li><li>R2 Val: 0.75</li></ul>\\n    <ul><li>MAE Test: 145.56</li><li>MSE Test: 37380.17</li><li>R2 Test: 0.87</li></ul>\\n    '\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Tab(label=\"Admin\"):\n",
    "        gr.Markdown(\"## Overview\")\n",
    "        link = \"https://michaelseitz98.github.io/enterprise-ai-project/eda-wue-rent-all.html\"\n",
    "        description = \"Explorative Data Analyis (EDA) for flats to rent in Würzburg\"\n",
    "        html_code = f'Explorative Data Analysis of data foundation: <a href=\"{html.escape(link)}\" font-size: 16px;\">{html.escape(description)}</a>'\n",
    "        gr.HTML(html_code)\n",
    "\n",
    "        with gr.Row():\n",
    "            data_overview = gr.HTML(\"\")\n",
    "            plot_overview = gr.Plot(visible=False)\n",
    "\n",
    "        btn = gr.Button(f\"Get stats of productive model\")\n",
    "        btn.click(\n",
    "            get_stats_of_model_from_mlflow, outputs=[data_overview, plot_overview]\n",
    "        )\n",
    "        gr.HTML(\"<hr>\")\n",
    "        gr.Markdown(\"## Retrain models with new data\")\n",
    "        gr.Markdown(\"Select the models you want to retrain.\")\n",
    "\n",
    "        with gr.Row():\n",
    "            xgb = gr.Checkbox(label=\"xgb\")\n",
    "            rf = gr.Checkbox(label=\"rf\")\n",
    "            linear = gr.Checkbox(label=\"linear\", value=True)\n",
    "            lasso = gr.Checkbox(label=\"lasso\")\n",
    "            ridge = gr.Checkbox(label=\"ridge\")\n",
    "            elasticnet = gr.Checkbox(label=\"elasticnet\")\n",
    "            baseline = gr.Checkbox(label=\"baseline-rent\", value=True)\n",
    "\n",
    "        model_list = []\n",
    "        if xgb:\n",
    "            model_list.append(\"xgb\")\n",
    "        if rf:\n",
    "            model_list.append(\"rf\")\n",
    "        if lasso:\n",
    "            model_list.append(\"lasso\")\n",
    "        if ridge:\n",
    "            model_list.append(\"ridge\")\n",
    "        if elasticnet:\n",
    "            model_list.append(\"elasticnet\")\n",
    "        if baseline:\n",
    "            model_list.append(\"baseline-rent\")\n",
    "\n",
    "        limit = gr.Slider(\n",
    "            label=\"Amount of scraped pages of Immowelt\", minimum=1, maximum=10, step=1\n",
    "        )\n",
    "        nachtraining = gr.Button(\"Scrape new data, retrain and evaluate models\")\n",
    "        gr.HTML(\"<hr>\")\n",
    "\n",
    "        df_results = gr.Dataframe()\n",
    "        output_plot = gr.HTML(retraining_results_html)\n",
    "\n",
    "        nachtraining.click(\n",
    "            fn=gradio_retrain_with_added_data,\n",
    "            inputs=[xgb, ridge, rf, elasticnet, linear, lasso, baseline, limit],\n",
    "            outputs=[df_results, output_plot],\n",
    "        )\n",
    "\n",
    "demo.queue(concurrency_count=10).launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
