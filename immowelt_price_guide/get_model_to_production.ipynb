{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the model running in production \n",
    "Replace the constante MODEL_NAME with the name of the model from MLflow you want to run in production.\n",
    "-> Therefore the model has to be set on stage production in MLflow.\n",
    "Then run the cell and the model will be stored to the backend folder.\n",
    "It also copies the specific requirements of the model to the container requirements.\n",
    "\n",
    "Next you can push the changes to the git repo & heroku, what starts an automatic deployment on the heroku cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/17 17:56:15 WARNING mlflow.pyfunc: Encountered an unexpected error (AttributeError(\"module 'configparser' has no attribute '__version__'\")) while detecting model dependency mismatches. Set logging level to DEBUG to see the full traceback.\n",
      "c:\\Users\\FelixNeubauer\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\base.py:299: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\FelixNeubauer\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\base.py:299: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 1.2.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from to_prod_functions import get_model_details_path, set_model_details_to_prod, set_model_to_prod, get_model_req_path, set_model_requirements_to_prod, get_model_env_path\n",
    "\n",
    "# Set model name here\n",
    "MODEL_NAME = \"wue-rent-feature-set-app\"\n",
    "\n",
    "details_path = get_model_details_path(MODEL_NAME)\n",
    "requirements_path = get_model_req_path(MODEL_NAME)\n",
    "yaml_path = get_model_env_path(MODEL_NAME)\n",
    "\n",
    "# Get model + its information from mlflow and place it to the BE \n",
    "set_model_details_to_prod(details_path)\n",
    "set_model_to_prod(MODEL_NAME)\n",
    "\n",
    "# Set the python version and lib requirements to the Dockerfile\n",
    "set_model_requirements_to_prod(requirements_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Das System kann den angegebenen Pfad nicht finden.\n",
      "warning: LF will be replaced by CRLF in immowelt_price_guide/get_model_to_production.ipynb.\n",
      "The file will have its original line endings in your working directory\n",
      "error: pathspec 'git' did not match any file(s) known to git\n",
      "error: pathspec 'push' did not match any file(s) known to git\n",
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "# Next you can run these commands to trigger the new deployment: (when you are in the root directory of the project)\n",
    "\n",
    "#! cd immowelt_price_guide/backend\n",
    "#! git add . \n",
    "#! git commit -m \"Update model to production\"; git push\n",
    "#! git push heroku main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture and Model Deployment\n",
    "\n",
    "This technical documentation provides an overview of the architecture and model deployment process for our ML application. The application leverages MLFlow for model training, management, and versioning, while the frontend is built using Gradio. The backend application is developed with FastAPI and hosted on Heroku, allowing for easy deployment of new models to the cloud.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "![Architecture]()\n",
    "\n",
    "The architecture of our ML application can be described as follows:\n",
    "\n",
    "1. **MLFlow**: MLFlow is used for model training, tracking, and versioning. It runs on a local server, and all artifacts are stored in our repository. This enables every team member with access to the repository to create models, train them, and store different versions using MLFlow.\n",
    "\n",
    "2. **Frontend (Gradio)**: The frontend of our application is built using Gradio. It collects the necessary data for the model to create predictions. Once the data is collected, the Gradio app sends a POST request to our FastAPI backend application.\n",
    "\n",
    "3. **Backend (FastAPI)**: The FastAPI backend application provides various endpoints.. When a request is received at the `/predict` endpoint, the desired model is loaded and ready to make predictions. The dedicted folder is located under `/immowelt_price_guide/backend`. [Also find here](https://github.com/MichaelSeitz98/enterprise-ai-project/tree/main/immowelt_price_guide/backend). \n",
    "\n",
    "The `main.py` includes the FastAPI app and the following endpoints:\n",
    "   -  `/predict` endpoint: This endpoint is used to make predictions. It receives a POST request from the frontend application, loads the desired model, and returns the prediction.\n",
    "   - `/model-info` endpoint: This endpoint is used to retrieve information about the model. It receives a GET request from the frontend application and returns the model's input and output parameters as well as the name and some infos about the version. \n",
    "   - `/` root: This endpoint is used to check the health of the application. It receives a GET request from the frontend application and returns a status code of 200 if the application is running.\n",
    "\n",
    "\n",
    "4. **Cloud Deployment (Heroku)**: The backend application is hosted on Heroku, making the endpoint permanently publicly available for everyone. The frontend and backend are designed to run independently of each other.\n",
    "\n",
    "## Model Deployment Process\n",
    "\n",
    "Deploying a new model to the cloud follows the following steps:\n",
    "\n",
    "1. Set the new model in production using MLFlow. This ensures that the model is available and can be accessed by name.\n",
    "\n",
    "2. Prepare the deployment cell: We have a preconfigured cell that performs the necessary steps for deployment. By simply setting a new name, the following actions are automated:\n",
    "\n",
    "   1. Load the model by its name from the MLFlow server.\n",
    "   2. Gather all the necessary information about the model, including input and output parameters, required Python version, and the required packages with their specific versions.\n",
    "   3. Set the model, its details, and requirements to the backend folder of our repository. This folder serves as the foundation for the deployed model in the cloud.\n",
    "\n",
    "3. Commit the changes to the main branch of our repository. Since Heroku is set up with our Git repository, pushing the changes triggers a new deployment on the cloud. The command `git push heroku main` is used for this purpose.\n",
    "\n",
    "4. Heroku deployment: The deployment process is possible because we have a `heroku.yml` file placed in our root directory, which directs to the Dockerfile located in our backend folder. The Dockerfile defines the image to be built for the model in production. Once the container is built, it runs on the Heroku cloud.\n",
    "\n",
    "By following these steps, a new model can be easily deployed to the cloud, ensuring that the latest version is available for use as well as all the required dependencies. This makes sure to not run into version or dependency issues when deploying a new model.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The architecture and model deployment process described in this documentation provide a clear and readable overview of how our ML application is structured and how new models can be deployed to the cloud using MLFlow, Gradio, FastAPI, and Heroku."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
