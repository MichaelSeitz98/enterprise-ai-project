{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "import shap\n",
    "from ctgan import CTGAN\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression, ElasticNet\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import optuna\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "profile = ProfileReport(df, title=\"Flats -  Würzburg - Rent - Overview\", explorative=True)\n",
    "profile.to_file(\"eda-wue-rent-all.html\")\n",
    "\n",
    "df = pd.read_excel(r'data\\houses_to_buy_wue_preprocessed_1207.xlsx')\n",
    "profile = ProfileReport(df, title=\"Houses -  Würzburg - Buy - Overview\", explorative=True)\n",
    "profile.to_file(\"eda-wue-houses.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineHighCorrCols(df):\n",
    "    df.columns = [\n",
    "        re.sub(r\"\\\\u([0-9a-fA-F]{4})\", lambda m: chr(int(m.group(1), 16)), col)\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    df.columns = [\n",
    "        col.replace(\"ö\", \"oe\").replace(\"ä\", \"ae\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\")\n",
    "        for col in df.columns\n",
    "    ]\n",
    " \n",
    "    important_num_cols = list(\n",
    "        df.corr()[\"Object_price\"][\n",
    "            (df.corr()[\"Object_price\"] > 0.20) | (df.corr()[\"Object_price\"] < -0.20)\n",
    "        ].index\n",
    "    )\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == \"object\"]\n",
    "    important_cols = important_num_cols + cat_cols + [\"ConstructionYear\"] + [\"ZipCode\"]\n",
    "    print(important_cols)\n",
    "    return important_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, feature_set):\n",
    "    print(f\"Used feature set for preprocessing:{feature_set}\")\n",
    "    df.columns = [\n",
    "        re.sub(r\"\\\\u([0-9a-fA-F]{4})\", lambda m: chr(int(m.group(1), 16)), col)\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    df.columns = [\n",
    "        col.replace(\"ö\", \"oe\").replace(\"ä\", \"ae\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\")\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    df = df.replace('\"\"', np.nan)\n",
    "    df = df.dropna()\n",
    "    df[\"LivingSpace\"] = df[\"LivingSpace\"].astype(float)\n",
    "    df[\"Rooms\"] = df[\"Rooms\"].astype(float)\n",
    "    df[\"ZipCode\"] = df[\"ZipCode\"].astype(str)\n",
    "    df[\"LivingSpace\"] = df[\"LivingSpace\"].astype(float)\n",
    "    df = df[feature_set]\n",
    "    df = df.reindex()\n",
    "    df = df.reset_index(drop=True)\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == \"object\"]\n",
    "    df = pd.get_dummies(df, columns=cat_cols)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df, train_size=0.8, random_state=42):\n",
    "    y = df[\"Object_price\"]\n",
    "    X = df.drop(\"Object_price\", axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=train_size, random_state=random_state\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, train_size=train_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # X_train.to_excel(\"data/X_train.xlsx\")\n",
    "    # X_val.to_excel(\"data/X_val.xlsx\")\n",
    "    # X_test.to_excel(\"data/X_test.xlsx\")\n",
    "    # y_train.to_excel(\"data/y_train.xlsx\")\n",
    "    # y_val.to_excel(\"data/y_val.xlsx\")\n",
    "    # y_test.to_excel(\"data/y_test.xlsx\")\n",
    "\n",
    "    df_train = pd.concat([X_train, y_train], axis=1)\n",
    "    df_val = pd.concat([X_val, y_val], axis=1)\n",
    "    df_test = pd.concat([X_test, y_test], axis=1)\n",
    "    df_train.to_excel(\"data/df_train.xlsx\")\n",
    "    df_val.to_excel(\"data/df_val.xlsx\")\n",
    "    df_test.to_excel(\"data/df_test.xlsx\")\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with OPTUNA Framework\n",
    "\n",
    "Because of long calculation times (especially with enable autolog for mlflow) not included in pipeline, but are saved to json file. Might make sense to re-executed when major data changes were incoming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (108, 46)\n",
      "y_train shape:  (108, 1)\n",
      "X_val shape:  (27, 46)\n",
      "y_val shape:  (27, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_excel(r\"data\\X_train.xlsx\")\n",
    "X_train = X_train.drop(columns=[\"Unnamed: 0\"])\n",
    "y_train = pd.read_excel(r\"data\\y_train.xlsx\")\n",
    "y_train = y_train.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "X_val = pd.read_excel(r\"data\\X_val.xlsx\")\n",
    "X_val = X_val.drop(columns=[\"Unnamed: 0\"])\n",
    "y_val = pd.read_excel(r\"data\\y_val.xlsx\")\n",
    "y_val = y_val.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_val shape: \", X_val.shape)\n",
    "print(\"y_val shape: \", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 0.01, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.01, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.01, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 1.0),\n",
    "        'random_state': trial.suggest_int('random_state', 1, 1000)\n",
    "    }\n",
    "    model = xgb.XGBRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    return mean_squared_error(y_val, y_pred)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize', study_name='regression')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print('Best params:', best_params)\n",
    "\n",
    "with open(r'hyperparameter_tuned/best_params_xgb.json', 'w') as f:\n",
    "    json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 10)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    random_state = trial.suggest_int('random_state', 1, 1000)\n",
    "    \n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    return mean_squared_error(y_val, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction='minimize', study_name='random_forest_regression')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print('Best params:', best_params)\n",
    "\n",
    "with open(r'hyperparameter_tuned/best_params_rf.json', 'w') as f:\n",
    "    json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 0.01, 1.0)\n",
    "    random_state = trial.suggest_int('random_state', 1, 1000)\n",
    "    \n",
    "    model = Lasso(alpha=alpha, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    return mean_squared_error(y_val, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction='minimize', study_name='lasso_regression')\n",
    "study.optimize(objective, n_trials=1)\n",
    "\n",
    "best_params = study.best_params\n",
    "print('Best params:', best_params)\n",
    "\n",
    "with open(r'hyperparameter_tuned/best_params_lasso.json', 'w') as f:\n",
    "    json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 0.01, 1.0)\n",
    "    random_state = trial.suggest_int('random_state', 1, 1000)\n",
    "    \n",
    "    model = Ridge(alpha=alpha, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    return mean_squared_error(y_val, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction='minimize', study_name='ridge_regression')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print('Best params:', best_params)\n",
    "\n",
    "with open(r'hyperparameter_tuned/best_params_ridge.json', 'w') as f:\n",
    "    json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 0.01, 1.0)\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0.01, 1.0)\n",
    "    random_state = trial.suggest_int('random_state', 1, 1000)\n",
    "    model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    return mean_squared_error(y_val, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction='minimize', study_name='elasticnet_regression')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print('Best params:', best_params)\n",
    "\n",
    "\n",
    "with open(r'hyperparameter_tuned/best_params_elasticnet.json', 'w') as f:\n",
    "    json.dump(best_params, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Evaluation and Logging Of Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_avg_rental_prices():\n",
    "    url = \"https://www.wohnungsboerse.net/mietspiegel-Wuerzburg/2772\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    script_tag = soup.find(\"script\", string=lambda text: \"pdfData\" in text)\n",
    "    rental_price = 0\n",
    "    if script_tag:\n",
    "        script_content = script_tag.string\n",
    "        start_index = script_content.find(\"avg_rent_price: \") + len(\"avg_rent_price: '\")\n",
    "        end_index = script_content.find(\"',\", start_index)\n",
    "        rental_price = script_content[start_index:end_index]\n",
    "        rental_price = (\n",
    "            rental_price.replace(\"€/m2\", \"\").replace(\".\", \"\").replace(\",\", \".\")\n",
    "        )\n",
    "        rental_price = rental_price.strip()\n",
    "        rental_price = float(rental_price)\n",
    "        print(f\"Extrcated rental price per square meter via scraper: {rental_price}\")\n",
    "    else:\n",
    "        print(\"The script tag containing the rental price was not found.\")\n",
    "    return rental_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_avg_buy_prices():\n",
    "    url = \"https://www.wohnungsboerse.net/immobilienpreise-Wuerzburg/2772\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status(\n",
    "    )\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    p_element = soup.find(\"p\", class_=\"mb-8\")\n",
    "    buy_price = 0\n",
    "    if p_element:\n",
    "        pattern = r\"\\d{1,3}(?:\\.\\d{3})*(?:,\\d{2})?€/m²\"\n",
    "        match = re.search(pattern, p_element.text)\n",
    "        if match:\n",
    "            buy_price = match.group()\n",
    "            buy_price = buy_price.replace(\"€/m²\", \"\").replace(\".\", \"\").replace(\",\", \".\")\n",
    "            print(f\"Extrcated buy price per square meter via scraper: {buy_price}\")\n",
    "        else:\n",
    "            print(\"Price not found\")\n",
    "    else:\n",
    "        print(\"The element ontaining the buy price was not found.\")\n",
    "    return buy_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_rent(val_X, val_y, runname=\"baseline_rent\"):\n",
    "    avg_price_per_sqm_rent = scrape_avg_rental_prices()\n",
    "    print(f\"Average rental price per sqm: {avg_price_per_sqm_rent}\")\n",
    "    return avg_price_per_sqm_rent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_buy(X_val, y_val, runname=\"baseline_buy\"):\n",
    "    avg_price_per_sqm_buy = scrape_avg_buy_prices()\n",
    "    print(f\"Average rental price per sqm: {avg_price_per_sqm_buy}\")\n",
    "\n",
    "    baseline_preds = X_val[\"LivingSpace\"] * avg_price_per_sqm_buy\n",
    "    baseline_mae = mean_absolute_error(y_val, baseline_preds)\n",
    "    baseline_r2 = r2_score(y_val, baseline_preds)\n",
    "    baseline_mse = mean_squared_error(y_val, baseline_preds)\n",
    "\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        mlflow.log_metric(\"mse\", baseline_mse)\n",
    "        mlflow.log_metric(\"mae\", baseline_mae)\n",
    "        mlflow.log_metric(\"r2\", baseline_r2)\n",
    "\n",
    "    print(f\"Baseline Mae: {baseline_mae}\")\n",
    "    print(f\"Baseline MSE: {baseline_mse}\")\n",
    "    print(f\"Baseline R2 Score: {baseline_r2}\")\n",
    "\n",
    "    return avg_price_per_sqm_buy, baseline_mae, baseline_mse, baseline_r2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression (Linear, Lasso, Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear(\n",
    "    X_train,\n",
    "    y_train,\n",
    "):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_lasso(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    hyperparameter_tuning=True,\n",
    "):\n",
    "    if hyperparameter_tuning:\n",
    "        with open(r\"hyperparameter_tuned/best_params_lasso.json\") as f:\n",
    "            best_params = json.load(f)\n",
    "        model = Lasso(**best_params)\n",
    "    else:\n",
    "        model = Lasso()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_ridge(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    hyperparameter_tuning=True,\n",
    "):\n",
    "    if hyperparameter_tuning:\n",
    "        with open(r\"hyperparameter_tuned/best_params_ridge.json\") as f:\n",
    "            best_params = json.load(f)\n",
    "        model = Ridge(**best_params)\n",
    "    else:\n",
    "        model = Ridge()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    hyperparameter_tuning=True,\n",
    "):\n",
    "    if hyperparameter_tuning:\n",
    "        with open(r\"hyperparameter_tuned/best_params_rf.json\") as f:\n",
    "            best_params = json.load(f)\n",
    "        model = RandomForestRegressor(**best_params)\n",
    "    else:\n",
    "        model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    early_stopping_rounds=30,\n",
    "    max_depth=6,\n",
    "    n_estimators=100,\n",
    "    hyperparameter_tuning=True,\n",
    "):\n",
    "    if hyperparameter_tuning:\n",
    "        with open(r\"hyperparameter_tuned/best_params_xgb.json\") as f:\n",
    "            best_params = json.load(f)\n",
    "        model = xgb.XGBRegressor(**best_params)\n",
    "    else:\n",
    "        model = xgb.XGBRegressor(\n",
    "            eval_metric=[\"rmse\", \"mae\"],\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            random_state=42,\n",
    "            max_depth=max_depth,\n",
    "            n_estimators=n_estimators,\n",
    "        )\n",
    "    model.fit(X=X_train, y=y_train, eval_set=[(X_val, y_val)], verbose=True)\n",
    "    ## Example of shap values, due to calculation time in retraining process outcommented\n",
    "    explainer = shap.Explainer(model)\n",
    "    shap_values = explainer(X_train)\n",
    "    shap.plots.waterfall(shap_values[6])\n",
    "    shap.plots.waterfall(shap_values[5])\n",
    "    shap.plots.waterfall(shap_values[9])\n",
    "    shap.plots.waterfall(shap_values[10])\n",
    "    shap.plots.beeswarm(shap_values)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_elasticnet(\n",
    "    X_train, y_train, hyperparameter_tuning=True\n",
    "):\n",
    "    if hyperparameter_tuning:\n",
    "        with open(r\"hyperparameter_tuned/best_params_elasticnet.json\") as f:\n",
    "            best_params = json.load(f)\n",
    "        model = ElasticNet(**best_params)\n",
    "    else:\n",
    "        model = ElasticNet()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_from_extracted(df, feature_set, model_name=\"lasso\", hpt=True):\n",
    "    mlflow.end_run()\n",
    "    model = None\n",
    "    df = preprocess_data(df, feature_set)\n",
    "    print(\"Done with preprocessing\")\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = data_split(df)\n",
    "    print(\"Done with data split\")\n",
    "\n",
    "    if model_name == \"xgb\":\n",
    "        mlflow.xgboost.autolog()\n",
    "    else:\n",
    "        mlflow.sklearn.autolog()\n",
    "\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = (\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "        if model_name == \"lasso\":\n",
    "            model = train_lasso(X_train, y_train, hyperparameter_tuning=hpt)\n",
    "        elif model_name == \"ridge\":\n",
    "            model = train_ridge(X_train, y_train, hyperparameter_tuning=hpt)\n",
    "        elif model_name == \"rf\":\n",
    "            model = train_rf(\n",
    "                X_train,\n",
    "                y_train,\n",
    "                hyperparameter_tuning=hpt,\n",
    "            )\n",
    "        elif model_name == \"xgb\":\n",
    "            model = train_xgb(X_train, y_train,X_val, y_val, hyperparameter_tuning=hpt)\n",
    "        elif model_name == \"elasticnet\":\n",
    "            model = train_elasticnet(X_train, y_train, hyperparameter_tuning=hpt)\n",
    "        elif model_name == \"linear\":\n",
    "            model = train_linear(X_train, y_train)\n",
    "        elif model_name == \"baseline-rent\":\n",
    "            avg_price = baseline_rent(X_val, y_val)\n",
    "            baseline_preds = X_val[\"LivingSpace\"] * avg_price\n",
    "            baseline_preds_test = X_test[\"LivingSpace\"] * avg_price\n",
    "            mlflow.log_metric(\"mae\", mean_absolute_error(y_val, baseline_preds))\n",
    "            mlflow.log_metric(\"r2\", r2_score(y_val, baseline_preds))\n",
    "            mlflow.log_metric(\"mse\", mean_squared_error(y_val, baseline_preds))\n",
    "            mlflow.log_metric(\n",
    "                \"rmse\", mean_squared_error(y_val, baseline_preds, squared=False)\n",
    "            )\n",
    "\n",
    "            mlflow.log_metric(\n",
    "                \"mae_test\", mean_absolute_error(y_test, baseline_preds_test)\n",
    "            )\n",
    "            mlflow.log_metric(\n",
    "                \"mse_test\", mean_squared_error(y_test, baseline_preds_test)\n",
    "            )\n",
    "            mlflow.log_metric(\n",
    "                \"rmse_test\",\n",
    "                mean_squared_error(y_test, baseline_preds_test, squared=False),\n",
    "            )\n",
    "            mlflow.log_metric(\"r2_test\", r2_score(y_test, baseline_preds_test))\n",
    "            return model, mae, mse, r2, mae_train, mse_train, r2_train\n",
    "        else:\n",
    "            print(\n",
    "                \"Model not found. Model_name must be 'lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline_buy' or 'baseline_rent' or conigure the pipeline manually.\"\n",
    "            )\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        preds = model.predict(X_val)\n",
    "        pred_test = model.predict(X_test)\n",
    "\n",
    "        mlflow.log_metric(\"mae_test\", mean_absolute_error(y_test, pred_test))\n",
    "        mlflow.log_metric(\"r2_test\", r2_score(y_test, pred_test))\n",
    "        mlflow.log_metric(\"mse_test\", mean_squared_error(y_test, pred_test))\n",
    "        mlflow.log_metric(\n",
    "            \"rmse_test\", mean_squared_error(y_test, pred_test, squared=False)\n",
    "        )\n",
    "\n",
    "        mlflow.log_metric(\"mae_train\", mean_absolute_error(y_train, pred_train))\n",
    "        mlflow.log_metric(\"mse_train\", mean_squared_error(y_train, pred_train))\n",
    "        mlflow.log_metric(\n",
    "            \"rmse_train\", mean_squared_error(y_train, pred_train, squared=False)\n",
    "        )\n",
    "        mlflow.log_metric(\"r2_train\", r2_score(y_train, pred_train))\n",
    "\n",
    "        mlflow.log_metric(\"mae\", mean_absolute_error(y_val, preds))\n",
    "        mlflow.log_metric(\"mse\", mean_squared_error(y_val, preds))\n",
    "        mlflow.log_metric(\n",
    "            \"rmse\", mean_squared_error(y_val, preds, squared=False)\n",
    "        )\n",
    "        mlflow.log_metric(\"r2\", r2_score(y_val, preds))\n",
    "\n",
    "    print(\"Done with train\")\n",
    "    mlflow.end_run()\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Data Approach with CTGan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_from_extracted_with_augemented_training_data(\n",
    "    df,\n",
    "    feature_set,\n",
    "    model_name,\n",
    "    augmentation_epochs=30,\n",
    "    n_added_fake_train_data=1000,\n",
    "):\n",
    "    df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "\n",
    "    df = df.replace('\"\"', np.nan)\n",
    "    df = df.dropna()\n",
    "    df[\"LivingSpace\"] = df[\"LivingSpace\"].astype(float)\n",
    "    df[\"Rooms\"] = df[\"Rooms\"].astype(float)\n",
    "    df[\"ZipCode\"] = df[\"ZipCode\"].astype(str)\n",
    "    df = df[feature_set]\n",
    "    df = df.reindex()\n",
    "    df = df.reset_index(drop=True)\n",
    "    X = df.drop(columns=[\"Object_price\"])\n",
    "    y = df[\"Object_price\"]\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = data_split(X, y)\n",
    "\n",
    "    train = pd.concat([X_train, y_train], axis=1)\n",
    "    val = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "    df_cttrain = train.copy()\n",
    "    df_cttrain = df_cttrain.dropna()\n",
    "\n",
    "    numerical_features = [\"Rooms\", \"LivingSpace\", \"Object_price\"]\n",
    "\n",
    "    df_cttrain[numerical_features] = df_cttrain[numerical_features].astype(\"int64\")\n",
    "    categorical_features = [\n",
    "        col for col in df_cttrain.columns if col not in numerical_features\n",
    "    ]\n",
    "    ctgan = CTGAN(verbose=True)\n",
    "    ctgan.fit(df_cttrain, categorical_features, epochs=augmentation_epochs)\n",
    "\n",
    "    samples = ctgan.sample(n_added_fake_train_data * 3)\n",
    "    samples[\"Object_price\"] = samples[\"Object_price\"].clip(lower=0)\n",
    "    samples = samples[samples[\"LivingSpace\"] > 20]\n",
    "    samples = samples[samples[\"Object_price\"] > 120]\n",
    "    samples = samples.head(n_added_fake_train_data)\n",
    "\n",
    "    X_sample_train = samples.drop(columns=[\"Object_price\"])\n",
    "    y_sample_train = samples[\"Object_price\"]\n",
    "    X_train = pd.concat([X_train, X_sample_train])\n",
    "    y_train = pd.concat([y_train, y_sample_train])\n",
    "\n",
    "    X_train_cat_cols = [\n",
    "        col for col in X_train.columns if X_train[col].dtype == \"object\"\n",
    "    ]\n",
    "    X_train = pd.get_dummies(X_train, columns=X_train_cat_cols)\n",
    "\n",
    "    X_val_cat_cols = [col for col in X_val.columns if X_val[col].dtype == \"object\"]\n",
    "    X_val = pd.get_dummies(X_val, columns=X_val_cat_cols)\n",
    "\n",
    "    print(f\"X_val shape: {X_val.shape}\")\n",
    "    print(f\"val shape: {val.shape}\")\n",
    "    print(f\"X_val head: {X_train.head()}\")\n",
    "    print(f\"val head: {val.head()}\")\n",
    "\n",
    "    X_train, X_val = X_train.align(X_val, join=\"outer\", axis=1, fill_value=0)\n",
    "\n",
    "    model, mae, mse, r2, mae_train, mse_train, r2_train = (\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "\n",
    "    if model_name == \"lasso\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_lasso(\n",
    "            X_train, y_train\n",
    "        )\n",
    "    elif model_name == \"ridge\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_ridge(\n",
    "            X_train,\n",
    "            y_train\n",
    "        )\n",
    "    elif model_name == \"rf\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_rf(X_train, y_train)\n",
    "    elif model_name == \"xgb\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_xgb(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"elasticnet\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_elasticnet(\n",
    "            X_train, y_train\n",
    "        )\n",
    "    elif model_name == \"linear\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_linear(\n",
    "            X_train, y_train\n",
    "        )\n",
    "    elif model_name == \"baseline-rent\":\n",
    "        avg_price, mae, mse, r2 = baseline_rent(X_val, y_val)\n",
    "    else:\n",
    "        print(\n",
    "            \"Model not found. Model_name must be 'lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline_buy' or 'baseline_rent'\"\n",
    "        )\n",
    "    print(\"Done with train\")\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_selected = [\n",
    "    \"Object_price\",\n",
    "    \"LivingSpace\",\n",
    "    \"ZipCode\",\n",
    "    \"Rooms\",\n",
    "    \"altbau_(bis_1945)\",\n",
    "    \"balkon\",\n",
    "    \"barriefrei\",\n",
    "    \"dachgeschoss\",\n",
    "    \"einbaukueche\",\n",
    "    \"neubau\",\n",
    "    \"parkett\",\n",
    "    \"stellplatz\",\n",
    "    \"bad/wc_getrennt\",\n",
    "    \"personenaufzug\",\n",
    "    \"garten\",\n",
    "    \"garage\",\n",
    "    \"renoviert\",\n",
    "    \"terrasse\",\n",
    "    \"wanne\",\n",
    "    \"zentralheizung\",\n",
    "    \"abstellraum\",\n",
    "    \"ferne\",\n",
    "    \"fussbodenheizung\",\n",
    "    \"gartennutzung\",\n",
    "    \"kelleranteil\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with model:  rf\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Done with preprocessing\n",
      "Done with data split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/17 03:53:59 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 03:54:03 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 03:54:23 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 03:54:25 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 03:54:27 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with train\n",
      "Done with model:  rf\n",
      "---------------------------------------------------------------------------\n",
      "Starting with model:  ridge\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Done with preprocessing\n",
      "Done with data split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/17 03:55:49 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 03:55:54 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 03:56:13 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 03:56:15 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 03:56:17 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with train\n",
      "Done with model:  ridge\n",
      "---------------------------------------------------------------------------\n",
      "Starting with model:  xgb\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Done with preprocessing\n",
      "Done with data split\n",
      "[0]\tvalidation_0-rmse:975.49976\tvalidation_0-mae:845.57492\n",
      "[1]\tvalidation_0-rmse:749.26720\tvalidation_0-mae:618.15297\n",
      "[2]\tvalidation_0-rmse:599.25921\tvalidation_0-mae:474.74173\n",
      "[3]\tvalidation_0-rmse:482.26499\tvalidation_0-mae:358.96303\n",
      "[4]\tvalidation_0-rmse:414.90881\tvalidation_0-mae:302.03719\n",
      "[5]\tvalidation_0-rmse:366.23603\tvalidation_0-mae:264.90933\n",
      "[6]\tvalidation_0-rmse:336.23308\tvalidation_0-mae:243.57824\n",
      "[7]\tvalidation_0-rmse:321.89904\tvalidation_0-mae:236.56959\n",
      "[8]\tvalidation_0-rmse:312.15522\tvalidation_0-mae:230.97248\n",
      "[9]\tvalidation_0-rmse:302.71719\tvalidation_0-mae:220.81605\n",
      "[10]\tvalidation_0-rmse:302.37378\tvalidation_0-mae:219.08114\n",
      "[11]\tvalidation_0-rmse:301.19848\tvalidation_0-mae:215.47096\n",
      "[12]\tvalidation_0-rmse:300.98607\tvalidation_0-mae:214.23821\n",
      "[13]\tvalidation_0-rmse:300.68700\tvalidation_0-mae:215.83069\n",
      "[14]\tvalidation_0-rmse:300.60023\tvalidation_0-mae:214.33558\n",
      "[15]\tvalidation_0-rmse:298.72058\tvalidation_0-mae:213.57458\n",
      "[16]\tvalidation_0-rmse:300.63768\tvalidation_0-mae:214.54960\n",
      "[17]\tvalidation_0-rmse:299.77855\tvalidation_0-mae:213.73020\n",
      "[18]\tvalidation_0-rmse:298.84305\tvalidation_0-mae:212.43375\n",
      "[19]\tvalidation_0-rmse:299.62278\tvalidation_0-mae:213.21636\n",
      "[20]\tvalidation_0-rmse:300.52219\tvalidation_0-mae:213.89842\n",
      "[21]\tvalidation_0-rmse:301.12555\tvalidation_0-mae:214.46124\n",
      "[22]\tvalidation_0-rmse:300.33574\tvalidation_0-mae:213.98888\n",
      "[23]\tvalidation_0-rmse:299.59947\tvalidation_0-mae:212.78353\n",
      "[24]\tvalidation_0-rmse:298.95962\tvalidation_0-mae:212.34964\n",
      "[25]\tvalidation_0-rmse:299.49164\tvalidation_0-mae:212.74266\n",
      "[26]\tvalidation_0-rmse:299.95165\tvalidation_0-mae:213.23041\n",
      "[27]\tvalidation_0-rmse:299.61491\tvalidation_0-mae:212.86610\n",
      "[28]\tvalidation_0-rmse:299.84094\tvalidation_0-mae:212.86891\n",
      "[29]\tvalidation_0-rmse:299.85948\tvalidation_0-mae:212.81730\n",
      "[30]\tvalidation_0-rmse:300.34849\tvalidation_0-mae:213.42054\n",
      "[31]\tvalidation_0-rmse:299.95470\tvalidation_0-mae:213.02817\n",
      "[32]\tvalidation_0-rmse:300.24999\tvalidation_0-mae:213.31605\n",
      "[33]\tvalidation_0-rmse:300.47735\tvalidation_0-mae:212.81778\n",
      "[34]\tvalidation_0-rmse:300.68162\tvalidation_0-mae:212.68500\n",
      "[35]\tvalidation_0-rmse:301.16007\tvalidation_0-mae:213.03295\n",
      "[36]\tvalidation_0-rmse:301.36990\tvalidation_0-mae:213.31229\n",
      "[37]\tvalidation_0-rmse:301.35297\tvalidation_0-mae:213.34408\n",
      "[38]\tvalidation_0-rmse:302.06210\tvalidation_0-mae:213.67348\n",
      "[39]\tvalidation_0-rmse:301.95259\tvalidation_0-mae:213.64622\n",
      "[40]\tvalidation_0-rmse:302.12926\tvalidation_0-mae:213.57770\n",
      "[41]\tvalidation_0-rmse:302.31191\tvalidation_0-mae:213.89206\n",
      "[42]\tvalidation_0-rmse:302.33543\tvalidation_0-mae:213.93963\n",
      "[43]\tvalidation_0-rmse:302.34259\tvalidation_0-mae:214.02197\n",
      "[44]\tvalidation_0-rmse:302.35161\tvalidation_0-mae:213.91532\n",
      "[45]\tvalidation_0-rmse:302.43946\tvalidation_0-mae:213.78312\n",
      "[46]\tvalidation_0-rmse:302.40648\tvalidation_0-mae:213.88548\n",
      "[47]\tvalidation_0-rmse:302.51699\tvalidation_0-mae:213.94866\n",
      "[48]\tvalidation_0-rmse:302.47536\tvalidation_0-mae:213.79265\n",
      "[49]\tvalidation_0-rmse:302.75906\tvalidation_0-mae:213.92898\n",
      "[50]\tvalidation_0-rmse:302.78360\tvalidation_0-mae:213.85070\n",
      "[51]\tvalidation_0-rmse:302.78948\tvalidation_0-mae:213.91216\n",
      "[52]\tvalidation_0-rmse:302.93520\tvalidation_0-mae:214.06255\n",
      "[53]\tvalidation_0-rmse:303.16752\tvalidation_0-mae:214.25080\n",
      "[54]\tvalidation_0-rmse:303.21217\tvalidation_0-mae:214.35887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/17 03:57:52 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 03:58:10 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 03:58:12 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 03:58:14 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with train\n",
      "Done with model:  xgb\n",
      "---------------------------------------------------------------------------\n",
      "Starting with model:  elasticnet\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Done with preprocessing\n",
      "Done with data split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/17 03:59:36 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 03:59:40 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 04:00:00 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 04:00:02 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 04:00:05 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with train\n",
      "Done with model:  elasticnet\n",
      "---------------------------------------------------------------------------\n",
      "Starting with model:  linear\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Done with preprocessing\n",
      "Done with data split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/17 04:01:27 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 04:01:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 04:01:50 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 04:01:52 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 04:01:54 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with train\n",
      "Done with model:  linear\n",
      "---------------------------------------------------------------------------\n",
      "Starting with model:  baseline-rent\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Done with preprocessing\n",
      "Done with data split\n",
      "Extrcated rental price per square meter via scraper: 11.21\n",
      "Average rental price per sqm: 11.21\n",
      "Done with model:  baseline-rent\n",
      "---------------------------------------------------------------------------\n",
      "Starting with model:  lasso\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Done with preprocessing\n",
      "Done with data split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/17 04:03:38 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 04:03:43 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 04:04:02 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 04:04:04 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/17 04:04:06 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with train\n",
      "Done with model:  lasso\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "# mlflow.autolog(disable=False)\n",
    "mlflow.set_experiment(\"wue-rent-fs-app-no-hpt\")\n",
    "model_names =[\"rf\",  \"ridge\", \"xgb\", \"elasticnet\", \"linear\", \"baseline-rent\", \"lasso\",]\n",
    "\n",
    "for model_name in model_names:\n",
    "    mlflow.end_run()\n",
    "    df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "    print(\"Starting with model: \", model_name)\n",
    "    pipeline_from_extracted(df, model_name=model_name, feature_set=feature_set_selected, hpt=False)\n",
    "    print(\"Done with model: \", model_name)\n",
    "    print(\"---------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution of Pipeline with synthetic data added to training base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "mlflow.set_experiment(\"wue-rent-selected-features-aug\")\n",
    "model_names = [\"baseline-rent\", \"lasso\", \"ridge\", \"xgb\", \"rf\", \"elasticnet\", \"linear\"]\n",
    "\n",
    "for model_name in model_names:\n",
    "    mlflow.end_run()\n",
    "    df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "    print(\"Starting with model: \", model_name)\n",
    "    complete_from_extracted_with_augemented_training_data(df, model_name=model_name, feature_set=feature_set_selected, n_added_fake_train_data=120, augmentation_epochs=170)\n",
    "    print(\"Done with model: \", model_name)\n",
    "    print(\"---------------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
