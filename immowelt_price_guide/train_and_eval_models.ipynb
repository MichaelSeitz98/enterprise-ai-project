{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\numba\\core\\decorators.py:262: NumbaDeprecationWarning: \u001b[1mnumba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\u001b[0m\n",
      "  warnings.warn(msg, NumbaDeprecationWarning)\n",
      "C:\\Users\\michi\\AppData\\Roaming\\Python\\Python38\\site-packages\\visions\\backends\\shared\\nan_handling.py:51: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def hasna(x: np.ndarray) -> bool:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "import shap\n",
    "from ctgan import CTGAN\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression, ElasticNet\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "# profile = ProfileReport(df, title=\"Flats -  Würzburg - Rent - Overview\", explorative=True)\n",
    "# profile.to_file(\"eda-wue-rent-all.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(r'data\\houses_to_buy_wue_preprocessed_1207.xlsx')\n",
    "# profile = ProfileReport(df, title=\"Houses -  Würzburg - Buy - Overview\", explorative=True)\n",
    "# profile.to_file(\"eda-wue-houses.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing & Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineHighCorrCols(df):\n",
    "    df.columns = [\n",
    "        re.sub(r\"\\\\u([0-9a-fA-F]{4})\", lambda m: chr(int(m.group(1), 16)), col)\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    df.columns = [\n",
    "        col.replace(\"ö\", \"oe\").replace(\"ä\", \"ae\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\")\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    important_num_cols = list(\n",
    "        df.corr()[\"Object_price\"][\n",
    "            (df.corr()[\"Object_price\"] > 0.20) | (df.corr()[\"Object_price\"] < -0.20)\n",
    "        ].index\n",
    "    )\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == \"object\"]\n",
    "    important_cols = important_num_cols + cat_cols + [\"ConstructionYear\"] + [\"ZipCode\"]\n",
    "    print(important_cols)\n",
    "    return important_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, feature_set):\n",
    "    print(f\"Used feature set for preprocessing:{feature_set}\")\n",
    "    df.columns = [\n",
    "        re.sub(r\"\\\\u([0-9a-fA-F]{4})\", lambda m: chr(int(m.group(1), 16)), col)\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    df.columns = [\n",
    "        col.replace(\"ö\", \"oe\").replace(\"ä\", \"ae\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\")\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    df = df.replace('\"\"', np.nan)\n",
    "    df = df.dropna()\n",
    "    df[\"LivingSpace\"] = df[\"LivingSpace\"].astype(float)\n",
    "    df[\"Rooms\"] = df[\"Rooms\"].astype(float)\n",
    "    df[\"ZipCode\"] = df[\"ZipCode\"].astype(str)\n",
    "    df[\"LivingSpace\"] = df[\"LivingSpace\"].astype(float)\n",
    "    df = df[feature_set]\n",
    "    df = df.reindex()\n",
    "    df = df.reset_index(drop=True)\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == \"object\"]\n",
    "    df = pd.get_dummies(df, columns=cat_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_data(df, feature_set):\n",
    "#     print(f\"Used feature set for preprocessing:{feature_set}\")\n",
    "#     df.columns = [\n",
    "#         re.sub(r\"\\\\u([0-9a-fA-F]{4})\", lambda m: chr(int(m.group(1), 16)), col)\n",
    "#         for col in df.columns\n",
    "#     ]\n",
    "#     df.columns = [\n",
    "#         col.replace(\"ö\", \"oe\").replace(\"ä\", \"ae\").replace(\"ü\", \"ue\").replace(\"ß\", \"ss\")\n",
    "#         for col in df.columns\n",
    "#     ]\n",
    "#     df = df.replace('\"\"', np.nan)\n",
    "#     df = df.dropna()\n",
    "#     df[\"LivingSpace\"] = df[\"LivingSpace\"].astype(float)\n",
    "#     df[\"Rooms\"] = df[\"Rooms\"].astype(float)\n",
    "#     df[\"ZipCode\"] = df[\"ZipCode\"].astype(str)\n",
    "#     df[\"LivingSpace\"] = df[\"LivingSpace\"].astype(float)\n",
    "#     df = df[feature_set]\n",
    "#     df = df.reindex()\n",
    "#     df = df.reset_index(drop=True)\n",
    "#     cat_cols = [col for col in df.columns if df[col].dtype == \"object\"]\n",
    "#     y = df[\"Object_price\"]\n",
    "#     X = df.drop(\"Object_price\", axis=1)\n",
    "#     X = pd.get_dummies(X, columns=cat_cols)\n",
    "\n",
    "#     return X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df, train_size=0.8, random_state=42):\n",
    "    y = df[\"Object_price\"]\n",
    "    X = df.drop(\"Object_price\", axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=train_size, random_state=random_state\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, train_size=train_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    X_train.to_excel(\"data/X_train.xlsx\")\n",
    "    X_val.to_excel(\"data/X_val.xlsx\")\n",
    "    X_test.to_excel(\"data/X_test.xlsx\")\n",
    "    y_train.to_excel(\"data/y_train.xlsx\")\n",
    "    y_val.to_excel(\"data/y_val.xlsx\")\n",
    "    y_test.to_excel(\"data/y_test.xlsx\")\n",
    "\n",
    "    df_train = pd.concat([X_train, y_train], axis=1)\n",
    "    df_val = pd.concat([X_val, y_val], axis=1)\n",
    "    df_test = pd.concat([X_test, y_test], axis=1)\n",
    "    df_train.to_excel(\"data/df_train.xlsx\")\n",
    "    df_val.to_excel(\"data/df_val.xlsx\")\n",
    "    df_test.to_excel(\"data/df_test.xlsx\")\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Evaluation and Logging Of Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_avg_rental_prices():\n",
    "    url = \"https://www.wohnungsboerse.net/mietspiegel-Wuerzburg/2772\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    script_tag = soup.find(\"script\", string=lambda text: \"pdfData\" in text)\n",
    "    rental_price = 0\n",
    "    if script_tag:\n",
    "        script_content = script_tag.string\n",
    "        start_index = script_content.find(\"avg_rent_price: \") + len(\"avg_rent_price: '\")\n",
    "        end_index = script_content.find(\"',\", start_index)\n",
    "        rental_price = script_content[start_index:end_index]\n",
    "        rental_price = (\n",
    "            rental_price.replace(\"€/m2\", \"\").replace(\".\", \"\").replace(\",\", \".\")\n",
    "        )\n",
    "        rental_price = rental_price.strip()\n",
    "        rental_price = float(rental_price)\n",
    "        print(f\"Extrcated rental price per square meter via scraper: {rental_price}\")\n",
    "    else:\n",
    "        print(\"The script tag containing the rental price was not found.\")\n",
    "    return rental_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_avg_buy_prices():\n",
    "    url = \"https://www.wohnungsboerse.net/immobilienpreise-Wuerzburg/2772\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status(\n",
    "    )\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    p_element = soup.find(\"p\", class_=\"mb-8\")\n",
    "    buy_price = 0\n",
    "    if p_element:\n",
    "        pattern = r\"\\d{1,3}(?:\\.\\d{3})*(?:,\\d{2})?€/m²\"\n",
    "        match = re.search(pattern, p_element.text)\n",
    "        if match:\n",
    "            buy_price = match.group()\n",
    "            buy_price = buy_price.replace(\"€/m²\", \"\").replace(\".\", \"\").replace(\",\", \".\")\n",
    "            print(f\"Extrcated buy price per square meter via scraper: {buy_price}\")\n",
    "        else:\n",
    "            print(\"Price not found\")\n",
    "    else:\n",
    "        print(\"The element ontaining the buy price was not found.\")\n",
    "    return buy_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_rent(val_X, val_y, runname=\"baseline_rent\"):\n",
    "    avg_price_per_sqm_rent = scrape_avg_rental_prices()\n",
    "    print(f\"Average rental price per sqm: {avg_price_per_sqm_rent}\")\n",
    "    return avg_price_per_sqm_rent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_buy(X_val, y_val, runname=\"baseline_buy\"):\n",
    "    avg_price_per_sqm_buy = scrape_avg_buy_prices()\n",
    "    print(f\"Average rental price per sqm: {avg_price_per_sqm_buy}\")\n",
    "\n",
    "    baseline_preds = X_val[\"LivingSpace\"] * avg_price_per_sqm_buy\n",
    "    baseline_mae = mean_absolute_error(y_val, baseline_preds)\n",
    "    baseline_r2 = r2_score(y_val, baseline_preds)\n",
    "    baseline_mse = mean_squared_error(y_val, baseline_preds)\n",
    "\n",
    "    with mlflow.start_run(run_name=runname):\n",
    "        mlflow.log_metric(\"mse\", baseline_mse)\n",
    "        mlflow.log_metric(\"mae\", baseline_mae)\n",
    "        mlflow.log_metric(\"r2\", baseline_r2)\n",
    "\n",
    "    print(f\"Baseline Mae: {baseline_mae}\")\n",
    "    print(f\"Baseline MSE: {baseline_mse}\")\n",
    "    print(f\"Baseline R2 Score: {baseline_r2}\")\n",
    "\n",
    "    return avg_price_per_sqm_buy, baseline_mae, baseline_mse, baseline_r2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression (Linear, Lasso, Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_linear(X_train, y_train, X_val, y_val, runname=\"linear-regression\"):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_and_eval_lasso(X_train, y_train, X_val, y_val, runname=\"lasso-regression\"):\n",
    "    model = Lasso()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_and_eval_ridge(X_train, y_train, X_val, y_val, runname=\"ridge-regression\"):\n",
    "    model = Ridge()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_rf(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    n_estimators=50,\n",
    "    random_state=0,\n",
    "    run_name=\"random-forest\",\n",
    "):\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_xgb(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    run_name=\"xgb\",\n",
    "    early_stopping_rounds=30,\n",
    "    max_depth=6,\n",
    "    n_estimators=1000,\n",
    "):\n",
    "    model = xgb.XGBRegressor(\n",
    "        eval_metric=[\"rmse\", \"mae\"],\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        random_state=42,\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "    )\n",
    "    model.fit(X=X_train, y=y_train, eval_set=[(X_val, y_val)], verbose=True)\n",
    "    # explainer = shap.Explainer(model)\n",
    "    # shap_values = explainer(X_train)\n",
    "    # shap.plots.waterfall(shap_values[6])\n",
    "    # plt.savefig(\"waterfall_0.png\", bbox_inches=\"tight\")\n",
    "    # shap.plots.waterfall(shap_values[5])\n",
    "    # plt.savefig(\"waterfall_1.png\", bbox_inches=\"tight\")\n",
    "    # shap.plots.waterfall(shap_values[9])\n",
    "    # plt.savefig(\"waterfall_2.png\", bbox_inches=\"tight\")\n",
    "    # shap.plots.waterfall(shap_values[10])\n",
    "    # plt.savefig(\"waterfall_3.png\", bbox_inches=\"tight\")\n",
    "    # shap.plots.beeswarm(shap_values)\n",
    "    # plt.savefig(\"beeswarm.png\", bbox_inches=\"tight\")\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_elasticnet(X_train, y_train, X_val, y_val, runname=\"elasticNet\"):\n",
    "    model = ElasticNet()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_from_extracted(df, feature_set, model_name=\"lasso\"):\n",
    "    mlflow.end_run()\n",
    "    model = None\n",
    "    df = preprocess_data(df, feature_set)\n",
    "    print(\"Done with preprocessing\")\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = data_split(df)\n",
    "    print(\"Done with data split\")\n",
    "\n",
    "    if model_name == \"xgb\":\n",
    "        mlflow.xgboost.autolog()\n",
    "    else:\n",
    "        mlflow.sklearn.autolog()\n",
    "\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = (\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "        if model_name == \"lasso\":\n",
    "            model = train_and_eval_lasso(X_train, y_train, X_val, y_val)\n",
    "        elif model_name == \"ridge\":\n",
    "            model = train_and_eval_ridge(X_train, y_train, X_val, y_val)\n",
    "        elif model_name == \"rf\":\n",
    "            model = train_and_eval_rf(X_train, y_train, X_val, y_val)\n",
    "        elif model_name == \"xgb\":\n",
    "            model = train_and_eval_xgb(X_train, y_train, X_val, y_val)\n",
    "        elif model_name == \"elasticnet\":\n",
    "            model = train_and_eval_elasticnet(X_train, y_train, X_val, y_val)\n",
    "        elif model_name == \"linear\":\n",
    "            model = train_and_eval_linear(X_train, y_train, X_val, y_val)\n",
    "        elif model_name == \"baseline-rent\":\n",
    "            avg_price = baseline_rent(X_val, y_val)\n",
    "            baseline_preds = X_val[\"LivingSpace\"] * avg_price\n",
    "            baseline_preds_test = X_test[\"LivingSpace\"] * avg_price\n",
    "            mlflow.log_metric(\"mae\", mean_absolute_error(y_val, baseline_preds))\n",
    "            mlflow.log_metric(\"mse\", mean_squared_error(y_val, baseline_preds))\n",
    "            mlflow.log_metric(\"r2\", r2_score(y_val, baseline_preds))\n",
    "            mlflow.log_metric(\n",
    "                \"mae_test\", mean_absolute_error(y_test, baseline_preds_test)\n",
    "            )\n",
    "            mlflow.log_metric(\n",
    "                \"mse_test\", mean_squared_error(y_test, baseline_preds_test)\n",
    "            )\n",
    "            mlflow.log_metric(\"r2_test\", r2_score(y_test, baseline_preds_test))\n",
    "            return model, mae, mse, r2, mae_train, mse_train, r2_train\n",
    "        else:\n",
    "            print(\n",
    "                \"Model not found. Model_name must be 'lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline_buy' or 'baseline_rent' or conigure the pipeline manually.\"\n",
    "            )\n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        preds = model.predict(X_val)\n",
    "        pred_test = model.predict(X_test)\n",
    "\n",
    "        mlflow.log_metric(\"mae_test\", mean_absolute_error(y_test, pred_test))\n",
    "        mlflow.log_metric(\"mse_test\", mean_squared_error(y_test, pred_test))\n",
    "        mlflow.log_metric(\"r2_test\", r2_score(y_test, pred_test))\n",
    "\n",
    "        mlflow.log_metric(\"mae_train\", mean_absolute_error(y_train, pred_train))\n",
    "        mlflow.log_metric(\"mse_train\", mean_squared_error(y_train, pred_train))\n",
    "        mlflow.log_metric(\"r2_train\", r2_score(y_train, pred_train))\n",
    "\n",
    "        mlflow.log_metric(\"mae\", mean_absolute_error(y_val, preds))\n",
    "        mlflow.log_metric(\"mse\", mean_squared_error(y_val, preds))\n",
    "        mlflow.log_metric(\"r2\", r2_score(y_val, preds))\n",
    "\n",
    "    print(\"Done with train\")\n",
    "    mlflow.end_run()\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Data Approach with CTGan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.autolog(disable=True)\n",
    "\n",
    "\n",
    "def complete_from_extracted_with_augemented_training_data(\n",
    "    df,\n",
    "    feature_set,\n",
    "    model_name,\n",
    "    augmentation_epochs=30,\n",
    "    n_added_fake_train_data=1000,\n",
    "):\n",
    "    df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "\n",
    "    df = df.replace('\"\"', np.nan)\n",
    "    df = df.dropna()\n",
    "    df[\"LivingSpace\"] = df[\"LivingSpace\"].astype(float)\n",
    "    df[\"Rooms\"] = df[\"Rooms\"].astype(float)\n",
    "    # df = df.dropna(subset=[\"ConstructionYear\"])\n",
    "    # df = df.dropna(subset=[\"Object_price\"])\n",
    "    # df = df.dropna(subset=[\"Rooms\"])\n",
    "    # df = df.dropna(subset=[\"LivingSpace\"])\n",
    "    df[\"ZipCode\"] = df[\"ZipCode\"].astype(str)\n",
    "    df[\"LivingSpace\"] = df[\"LivingSpace\"].astype(float)\n",
    "    df = df[feature_set]\n",
    "    df = df.reindex()\n",
    "    df = df.reset_index(drop=True)\n",
    "    X = df.drop(columns=[\"Object_price\"])\n",
    "    y = df[\"Object_price\"]\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = data_split(X, y)\n",
    "\n",
    "    train = pd.concat([X_train, y_train], axis=1)\n",
    "    val = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "    df_cttrain = train.copy()\n",
    "    df_cttrain = df_cttrain.dropna()\n",
    "\n",
    "    numerical_features = [\"Rooms\", \"LivingSpace\", \"Object_price\"]\n",
    "\n",
    "    df_cttrain[numerical_features] = df_cttrain[numerical_features].astype(\"int64\")\n",
    "    categorical_features = [\n",
    "        col for col in df_cttrain.columns if col not in numerical_features\n",
    "    ]\n",
    "    ctgan = CTGAN(verbose=True)\n",
    "    ctgan.fit(df_cttrain, categorical_features, epochs=augmentation_epochs)\n",
    "\n",
    "    samples = ctgan.sample(n_added_fake_train_data * 3)\n",
    "    samples[\"Object_price\"] = samples[\"Object_price\"].clip(lower=0)\n",
    "    samples = samples[samples[\"LivingSpace\"] > 20]\n",
    "    samples = samples[samples[\"Object_price\"] > 120]\n",
    "    samples = samples.head(n_added_fake_train_data)\n",
    "\n",
    "    X_sample_train = samples.drop(columns=[\"Object_price\"])\n",
    "    y_sample_train = samples[\"Object_price\"]\n",
    "    X_train = pd.concat([X_train, X_sample_train])\n",
    "    y_train = pd.concat([y_train, y_sample_train])\n",
    "\n",
    "    # train_extended = pd.concat(\n",
    "    #     [X_train, y_train], axis=1\n",
    "    # )\n",
    "\n",
    "    # X_train, y_train = preprocess_data(train_extended, feature_set_selected)\n",
    "    # X_val, y_val = preprocess_data(val, feature_set_selected)\n",
    "\n",
    "    X_train_cat_cols = [\n",
    "        col for col in X_train.columns if X_train[col].dtype == \"object\"\n",
    "    ]\n",
    "    X_train = pd.get_dummies(X_train, columns=X_train_cat_cols)\n",
    "\n",
    "    X_val_cat_cols = [col for col in X_val.columns if X_val[col].dtype == \"object\"]\n",
    "    X_val = pd.get_dummies(X_val, columns=X_val_cat_cols)\n",
    "\n",
    "    print(f\"X_val shape: {X_val.shape}\")\n",
    "    print(f\"val shape: {val.shape}\")\n",
    "    print(f\"X_val head: {X_train.head()}\")\n",
    "    print(f\"val head: {val.head()}\")\n",
    "\n",
    "    X_train, X_val = X_train.align(X_val, join=\"outer\", axis=1, fill_value=0)\n",
    "\n",
    "    model, mae, mse, r2, mae_train, mse_train, r2_train = (\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "\n",
    "    if model_name == \"lasso\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_lasso(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"ridge\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_ridge(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_val,\n",
    "            y_val,\n",
    "        )\n",
    "    elif model_name == \"rf\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_rf(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"xgb\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_xgb(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"elasticnet\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_elasticnet(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"linear\":\n",
    "        model, mae, mse, r2, mae_train, mse_train, r2_train = train_and_eval_linear(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "    elif model_name == \"baseline-rent\":\n",
    "        avg_price, mae, mse, r2 = baseline_rent(X_val, y_val)\n",
    "    else:\n",
    "        print(\n",
    "            \"Model not found. Model_name must be 'lasso', 'ridge', 'rf', 'xgb', 'elasticnet', 'linear', 'baseline_buy' or 'baseline_rent'\"\n",
    "        )\n",
    "    print(\"Done with train\")\n",
    "    return model, mae, mse, r2, mae_train, mse_train, r2_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with model:  baseline-rent\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Done with preprocessing\n",
      "Done with data split\n",
      "Extrcated rental price per square meter via scraper: 11.21\n",
      "Average rental price per sqm: 11.21\n",
      "Done with model:  baseline-rent\n",
      "---------------------------------------------------------------------------\n",
      "Starting with model:  lasso\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Done with preprocessing\n",
      "Done with data split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/14 20:42:26 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:42:30 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:42:36 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "2023/07/14 20:42:50 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:42:52 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:42:55 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with train\n",
      "Done with model:  lasso\n",
      "---------------------------------------------------------------------------\n",
      "Starting with model:  ridge\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Done with preprocessing\n",
      "Done with data split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/14 20:43:20 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:43:25 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:43:44 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:43:46 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:43:48 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with train\n",
      "Done with model:  ridge\n",
      "---------------------------------------------------------------------------\n",
      "Starting with model:  xgb\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Done with preprocessing\n",
      "Done with data split\n",
      "[0]\tvalidation_0-rmse:975.49976\tvalidation_0-mae:845.57492\n",
      "[1]\tvalidation_0-rmse:749.26720\tvalidation_0-mae:618.15297\n",
      "[2]\tvalidation_0-rmse:599.25921\tvalidation_0-mae:474.74173\n",
      "[3]\tvalidation_0-rmse:482.26499\tvalidation_0-mae:358.96303\n",
      "[4]\tvalidation_0-rmse:414.90881\tvalidation_0-mae:302.03719\n",
      "[5]\tvalidation_0-rmse:366.23603\tvalidation_0-mae:264.90933\n",
      "[6]\tvalidation_0-rmse:336.23308\tvalidation_0-mae:243.57824\n",
      "[7]\tvalidation_0-rmse:321.89904\tvalidation_0-mae:236.56959\n",
      "[8]\tvalidation_0-rmse:312.15522\tvalidation_0-mae:230.97248\n",
      "[9]\tvalidation_0-rmse:302.71719\tvalidation_0-mae:220.81605\n",
      "[10]\tvalidation_0-rmse:302.37378\tvalidation_0-mae:219.08114\n",
      "[11]\tvalidation_0-rmse:301.19848\tvalidation_0-mae:215.47096\n",
      "[12]\tvalidation_0-rmse:300.98607\tvalidation_0-mae:214.23821\n",
      "[13]\tvalidation_0-rmse:300.68700\tvalidation_0-mae:215.83069\n",
      "[14]\tvalidation_0-rmse:300.60023\tvalidation_0-mae:214.33558\n",
      "[15]\tvalidation_0-rmse:298.72058\tvalidation_0-mae:213.57458\n",
      "[16]\tvalidation_0-rmse:300.63768\tvalidation_0-mae:214.54960\n",
      "[17]\tvalidation_0-rmse:299.77855\tvalidation_0-mae:213.73020\n",
      "[18]\tvalidation_0-rmse:298.84305\tvalidation_0-mae:212.43375\n",
      "[19]\tvalidation_0-rmse:299.62278\tvalidation_0-mae:213.21636\n",
      "[20]\tvalidation_0-rmse:300.52219\tvalidation_0-mae:213.89842\n",
      "[21]\tvalidation_0-rmse:301.12555\tvalidation_0-mae:214.46124\n",
      "[22]\tvalidation_0-rmse:300.33574\tvalidation_0-mae:213.98888\n",
      "[23]\tvalidation_0-rmse:299.59947\tvalidation_0-mae:212.78353\n",
      "[24]\tvalidation_0-rmse:298.95962\tvalidation_0-mae:212.34964\n",
      "[25]\tvalidation_0-rmse:299.49164\tvalidation_0-mae:212.74266\n",
      "[26]\tvalidation_0-rmse:299.95165\tvalidation_0-mae:213.23041\n",
      "[27]\tvalidation_0-rmse:299.61491\tvalidation_0-mae:212.86610\n",
      "[28]\tvalidation_0-rmse:299.84094\tvalidation_0-mae:212.86891\n",
      "[29]\tvalidation_0-rmse:299.85948\tvalidation_0-mae:212.81730\n",
      "[30]\tvalidation_0-rmse:300.34849\tvalidation_0-mae:213.42054\n",
      "[31]\tvalidation_0-rmse:299.95470\tvalidation_0-mae:213.02817\n",
      "[32]\tvalidation_0-rmse:300.24999\tvalidation_0-mae:213.31605\n",
      "[33]\tvalidation_0-rmse:300.47735\tvalidation_0-mae:212.81778\n",
      "[34]\tvalidation_0-rmse:300.68162\tvalidation_0-mae:212.68500\n",
      "[35]\tvalidation_0-rmse:301.16007\tvalidation_0-mae:213.03295\n",
      "[36]\tvalidation_0-rmse:301.36990\tvalidation_0-mae:213.31229\n",
      "[37]\tvalidation_0-rmse:301.35297\tvalidation_0-mae:213.34408\n",
      "[38]\tvalidation_0-rmse:302.06210\tvalidation_0-mae:213.67348\n",
      "[39]\tvalidation_0-rmse:301.95259\tvalidation_0-mae:213.64622\n",
      "[40]\tvalidation_0-rmse:302.12926\tvalidation_0-mae:213.57770\n",
      "[41]\tvalidation_0-rmse:302.31191\tvalidation_0-mae:213.89206\n",
      "[42]\tvalidation_0-rmse:302.33543\tvalidation_0-mae:213.93963\n",
      "[43]\tvalidation_0-rmse:302.34259\tvalidation_0-mae:214.02197\n",
      "[44]\tvalidation_0-rmse:302.35161\tvalidation_0-mae:213.91532\n",
      "[45]\tvalidation_0-rmse:302.43946\tvalidation_0-mae:213.78312\n",
      "[46]\tvalidation_0-rmse:302.40648\tvalidation_0-mae:213.88548\n",
      "[47]\tvalidation_0-rmse:302.51699\tvalidation_0-mae:213.94866\n",
      "[48]\tvalidation_0-rmse:302.47536\tvalidation_0-mae:213.79265\n",
      "[49]\tvalidation_0-rmse:302.75906\tvalidation_0-mae:213.92898\n",
      "[50]\tvalidation_0-rmse:302.78360\tvalidation_0-mae:213.85070\n",
      "[51]\tvalidation_0-rmse:302.78948\tvalidation_0-mae:213.91216\n",
      "[52]\tvalidation_0-rmse:302.93520\tvalidation_0-mae:214.06255\n",
      "[53]\tvalidation_0-rmse:303.16752\tvalidation_0-mae:214.25080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/14 20:44:27 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:44:44 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:44:46 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:44:48 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with train\n",
      "Done with model:  xgb\n",
      "---------------------------------------------------------------------------\n",
      "Starting with model:  rf\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Done with preprocessing\n",
      "Done with data split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/14 20:45:14 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:45:19 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:45:38 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:45:40 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:45:42 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with train\n",
      "Done with model:  rf\n",
      "---------------------------------------------------------------------------\n",
      "Starting with model:  elasticnet\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Done with preprocessing\n",
      "Done with data split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/14 20:46:08 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:46:12 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:46:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:46:33 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:46:35 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with train\n",
      "Done with model:  elasticnet\n",
      "---------------------------------------------------------------------------\n",
      "Starting with model:  linear\n",
      "Used feature set for preprocessing:['Object_price', 'LivingSpace', 'ZipCode', 'Rooms', 'altbau_(bis_1945)', 'balkon', 'barriefrei', 'dachgeschoss', 'einbaukueche', 'neubau', 'parkett', 'stellplatz', 'bad/wc_getrennt', 'personenaufzug', 'garten', 'garage', 'renoviert', 'terrasse', 'wanne', 'zentralheizung', 'abstellraum', 'ferne', 'fussbodenheizung', 'gartennutzung', 'kelleranteil']\n",
      "Done with preprocessing\n",
      "Done with data split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/14 20:47:01 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:47:05 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\models\\signature.py:144: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:47:24 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:47:26 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2023/07/14 20:47:29 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\michi\\Anaconda3\\envs\\enterpriseai2\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with train\n",
      "Done with model:  linear\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "mlflow.set_experiment(\"wue-rent-selected-features-14-07-org\")\n",
    "model_names = [\"baseline-rent\", \"lasso\", \"ridge\", \"xgb\", \"rf\", \"elasticnet\", \"linear\"]\n",
    "\n",
    "feature_set_selected = [\n",
    "    \"Object_price\",\n",
    "    \"LivingSpace\",\n",
    "    \"ZipCode\",\n",
    "    \"Rooms\",\n",
    "    \"altbau_(bis_1945)\",\n",
    "    \"balkon\",\n",
    "    \"barriefrei\",\n",
    "    \"dachgeschoss\",\n",
    "    \"einbaukueche\",\n",
    "    \"neubau\",\n",
    "    \"parkett\",\n",
    "    \"stellplatz\",\n",
    "    \"bad/wc_getrennt\",\n",
    "    \"personenaufzug\",\n",
    "    \"garten\",\n",
    "    \"garage\",\n",
    "    \"renoviert\",\n",
    "    \"terrasse\",\n",
    "    \"wanne\",\n",
    "    \"zentralheizung\",\n",
    "    \"abstellraum\",\n",
    "    \"ferne\",\n",
    "    \"fussbodenheizung\",\n",
    "    \"gartennutzung\",\n",
    "    \"kelleranteil\",\n",
    "]\n",
    "\n",
    "for model_name in model_names:\n",
    "    mlflow.end_run()\n",
    "    df = pd.read_excel(r\"data\\flats_to_rent_wue_preprocessed_combined.xlsx\")\n",
    "    print(\"Starting with model: \", model_name)\n",
    "    pipeline_from_extracted(df, model_name=model_name, feature_set=feature_set_selected)\n",
    "    print(\"Done with model: \", model_name)\n",
    "    print(\"---------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## With Data Augementation\n",
    "# for model_name in model_names:\n",
    "#     df = pd.read_excel(r'data\\flats_to_rent_wue_preprocessed_combined.xlsx')\n",
    "#     print(\"Starting with model: \", model_name)\n",
    "#     complete_from_extracted_with_augemented_training_data(df, model_name=model_name, feature_set=feature_set_selected, n_added_fake_train_data=0)\n",
    "#     print(\"Done with model: \", model_name)\n",
    "#     print(\"-------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Experiments Information From MLFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tags.mlflow.runName  metrics.mae  metrics.r2                  experiment\n",
      "6       baseline-rent   285.556400    0.580289  wue-rent-selected-features\n",
      "0              linear   269.628615    0.639057  wue-rent-selected-features\n",
      "5               lasso   239.379006    0.726555  wue-rent-selected-features\n",
      "4               ridge   237.547989    0.734597  wue-rent-selected-features\n",
      "1          elasticnet   231.958821    0.724565  wue-rent-selected-features\n",
      "3                 xgb   212.349642    0.732313  wue-rent-selected-features\n",
      "2                  rf   194.380348    0.745000  wue-rent-selected-features\n"
     ]
    }
   ],
   "source": [
    "results_selected_features = mlflow.search_runs(experiment_names=[\"wue-rent-fs-app\"])\n",
    "results_selected_features = results_selected_features[\n",
    "    [\"tags.mlflow.runName\", \"metrics.mae\", \"metrics.r2\"]\n",
    "]\n",
    "results_selected_features = results_selected_features.sort_values(\n",
    "    by=\"metrics.mae\", ascending=False\n",
    ")\n",
    "results_selected_features[\"experiment\"] = \"wue-rent-selected-features\"\n",
    "\n",
    "\n",
    "results_selected_features_aug_50 = mlflow.search_runs(\n",
    "    experiment_names=[\"wue-rent-selected-features-aug-50\"]\n",
    ")\n",
    "results_selected_features_aug_50 = results_selected_features_aug_50[\n",
    "    [\"tags.mlflow.runName\", \"metrics.mae\", \"metrics.r2\"]\n",
    "]\n",
    "results_selected_features_aug_50 = results_selected_features_aug_50.sort_values(\n",
    "    by=\"metrics.mae\", ascending=False\n",
    ")\n",
    "results_selected_features_aug_50[\"experiment\"] = \"wue-rent-selected-features-aug-50\"\n",
    "\n",
    "results_selected_features_aug_120 = mlflow.search_runs(\n",
    "    experiment_names=[\"wue-rent-selected-features-aug-120\"]\n",
    ")\n",
    "results_selected_features_aug_120 = results_selected_features_aug_120[\n",
    "    [\"tags.mlflow.runName\", \"metrics.mae\", \"metrics.r2\"]\n",
    "]\n",
    "results_selected_features_aug_120 = results_selected_features_aug_120.sort_values(\n",
    "    by=\"metrics.mae\", ascending=False\n",
    ")\n",
    "results_selected_features_aug_120[\"experiment\"] = \"wue-rent-selected-features-aug-120\"\n",
    "\n",
    "results_selected_features_aug_1000 = mlflow.search_runs(\n",
    "    experiment_names=[\"wue-rent-selected-features-aug-1000\"]\n",
    ")\n",
    "results_selected_features_aug_1000 = results_selected_features_aug_1000[\n",
    "    [\"tags.mlflow.runName\", \"metrics.mae\", \"metrics.r2\"]\n",
    "]\n",
    "results_selected_features_aug_1000 = results_selected_features_aug_1000.sort_values(\n",
    "    by=\"metrics.mae\", ascending=False\n",
    ")\n",
    "results_selected_features_aug_1000[\"experiment\"] = \"results-selected-features-aug-1000\"\n",
    "\n",
    "results_selected_features_aug_comparison = pd.concat([results_selected_features])\n",
    "results_selected_features_aug_comparison.to_excel(\n",
    "    \"results-selected-features-aug.xlsx\", index=False\n",
    ")\n",
    "print(results_selected_features_aug_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot: Impact Of Syntetic Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"results-selected-features-aug.xlsx\")\n",
    "\n",
    "linear_regression_data = df[df[\"tags.mlflow.runName\"] == \"linear-regression\"]\n",
    "lasso_regression_data = df[df[\"tags.mlflow.runName\"] == \"lasso-regression\"]\n",
    "ridge_regression_data = df[df[\"tags.mlflow.runName\"] == \"ridge-regression\"]\n",
    "xgb_data = df[df[\"tags.mlflow.runName\"] == \"xgb\"]\n",
    "random_forest_data = df[df[\"tags.mlflow.runName\"] == \"random-forest\"]\n",
    "elasticnet_data = df[df[\"tags.mlflow.runName\"] == \"elasticNet\"]\n",
    "\n",
    "linear_setups = linear_regression_data[\"experiment\"]\n",
    "linear_mae_values = linear_regression_data[\"metrics.mae\"]\n",
    "lasso_setups = lasso_regression_data[\"experiment\"]\n",
    "lasso_mae_values = lasso_regression_data[\"metrics.mae\"]\n",
    "ridge_setups = ridge_regression_data[\"experiment\"]\n",
    "ridge_mae_values = ridge_regression_data[\"metrics.mae\"]\n",
    "xgb_setups = xgb_data[\"experiment\"]\n",
    "xgb_mae_values = xgb_data[\"metrics.mae\"]\n",
    "random_forest_setups = random_forest_data[\"experiment\"]\n",
    "random_forest_mae_values = random_forest_data[\"metrics.mae\"]\n",
    "elasticnet_setups = elasticnet_data[\"experiment\"]\n",
    "elasticnet_mae_values = elasticnet_data[\"metrics.mae\"]\n",
    "\n",
    "linear_labels = [str(setup).split(\"-\")[-1] for setup in linear_setups]\n",
    "linear_labels = [\n",
    "    \"no augm.\" if label == \"features\" else label for label in linear_labels\n",
    "]\n",
    "lasso_labels = [str(setup).split(\"-\")[-1] for setup in lasso_setups]\n",
    "lasso_labels = [\"no augm.\" if label == \"features\" else label for label in lasso_labels]\n",
    "ridge_labels = [str(setup).split(\"-\")[-1] for setup in ridge_setups]\n",
    "ridge_labels = [\"no augm.\" if label == \"features\" else label for label in ridge_labels]\n",
    "xgb_labels = [str(setup).split(\"-\")[-1] for setup in xgb_setups]\n",
    "xgb_labels = [\"no augm.\" if label == \"features\" else label for label in xgb_labels]\n",
    "random_forest_labels = [str(setup).split(\"-\")[-1] for setup in random_forest_setups]\n",
    "random_forest_labels = [\n",
    "    \"no augm.\" if label == \"features\" else label for label in random_forest_labels\n",
    "]\n",
    "elasticnet_labels = [str(setup).split(\"-\")[-1] for setup in elasticnet_setups]\n",
    "elasticnet_labels = [\n",
    "    \"no augm.\" if label == \"features\" else label for label in elasticnet_labels\n",
    "]\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(1, 6, figsize=(20, 6))\n",
    "\n",
    "ax1.bar(linear_labels, linear_mae_values)\n",
    "ax1.set_ylabel(\"MAE\")\n",
    "ax1.set_xlabel(\"n_augmented_data\")\n",
    "ax1.set_title(\"Linear Regression\")\n",
    "ax1.tick_params(axis=\"x\", labelrotation=90)\n",
    "\n",
    "ax2.bar(lasso_labels, lasso_mae_values)\n",
    "ax2.set_ylabel(\"MAE\")\n",
    "ax2.set_xlabel(\"n_augmented_data\")\n",
    "ax2.set_title(\"Lasso Regression\")\n",
    "ax2.tick_params(axis=\"x\", labelrotation=90)\n",
    "\n",
    "ax3.bar(ridge_labels, ridge_mae_values)\n",
    "ax3.set_ylabel(\"MAE\")\n",
    "ax3.set_xlabel(\"n_augmented_data\")\n",
    "ax3.set_title(\"Ridge Regression\")\n",
    "ax3.tick_params(axis=\"x\", labelrotation=90)\n",
    "\n",
    "ax4.bar(xgb_labels, xgb_mae_values)\n",
    "ax4.set_ylabel(\"MAE\")\n",
    "ax4.set_xlabel(\"n_augmented_data\")\n",
    "ax4.set_title(\"XGBoost\")\n",
    "ax4.tick_params(axis=\"x\", labelrotation=90)\n",
    "\n",
    "ax5.bar(random_forest_labels, random_forest_mae_values)\n",
    "ax5.set_ylabel(\"MAE\")\n",
    "ax5.set_xlabel(\"n_augmented_data\")\n",
    "ax5.set_title(\"Random Forest\")\n",
    "ax5.tick_params(axis=\"x\", labelrotation=90)\n",
    "\n",
    "ax6.bar(elasticnet_labels, elasticnet_mae_values)\n",
    "ax6.set_ylabel(\"MAE\")\n",
    "ax6.set_xlabel(\"n_augmented_data\")\n",
    "ax6.set_title(\"ElasticNet\")\n",
    "ax6.tick_params(axis=\"x\", labelrotation=90)\n",
    "\n",
    "plt.suptitle(\"Data Augmentation with CTGAN has a negative impact on MAE\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"regression_results.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
